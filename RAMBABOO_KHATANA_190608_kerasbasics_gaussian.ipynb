{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RAMBABOO KHATANA - 190608_kerasbasics_gaussian-assignment_f.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajkhatana/Khatana/blob/master/RAMBABOO_KHATANA_190608_kerasbasics_gaussian.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QrZqmW-YtUKw"
      },
      "source": [
        "# Keras Basics\n",
        "We will learn about\n",
        "* Dense layers\n",
        "* Categorical cross-entropy\n",
        "\n",
        "A toy example to show how to train a classifier with Keras and use it. The data comes from three gaussian distributions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eWyR310TtUKy",
        "colab": {}
      },
      "source": [
        "## DATA GENERATION\n",
        "import numpy as np\n",
        "np.random.seed(10)\n",
        "def generateX(cls):\n",
        "    '''\n",
        "    Inputs:\n",
        "        cls: class {0, 1, 2}\n",
        "    Outputs:\n",
        "        x: a sample from cls; a np array of shape (2,)\n",
        "    '''\n",
        "    assert cls in [0,1,2]\n",
        "    if cls==0:\n",
        "        x = np.random.normal(np.array([0,0]),100)\n",
        "    elif cls==1:\n",
        "        x = np.random.normal(np.array([200,200]),100)\n",
        "    elif cls==2:\n",
        "      x = np.random.normal(np.array([-200,200]),100)\n",
        "    return x\n",
        "Nx = 2 # shape of a sample is (2,)\n",
        "Ny = 3 # 3 classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "24sOXTIttUK2"
      },
      "source": [
        "Could you write a function to generate N samples from class 0 and N samples from class 1?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "id": "9W3ccvYYtUK4",
        "nbgrader": {
          "checksum": "71c5837a9d68fac4398e11bcb87c3bd2",
          "grade": false,
          "grade_id": "cell-6ee804e3860f2ff6",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "colab": {}
      },
      "source": [
        "def generateXY(N):\n",
        "    '''\n",
        "    Inputs:\n",
        "        N: no. of samples of each class\n",
        "    Outputs:\n",
        "        X: np array of samples; shape = (3*N, 2)\n",
        "        Y: np array of samples; shape = (3*N, 1)\n",
        "    '''\n",
        "    # YOUR CODE HERE\n",
        "    Y = np.random.randint(0, 3, size=(3*N,1))\n",
        "    X = np.zeros((3*N,2))\n",
        "    for i in range(3*N):\n",
        "      X[i,:] = generateX(Y[i])\n",
        "    return X, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "sUqeO_NWtUK7",
        "nbgrader": {
          "checksum": "c0183471e369c049b734441886caaff4",
          "grade": true,
          "grade_id": "cell-ad908829419fd089",
          "locked": true,
          "points": 1,
          "schema_version": 1,
          "solution": false
        },
        "outputId": "3ca7fce8-caa0-4a7d-acba-6e6208a1cd8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def test_generateXY():\n",
        "    X_train, Y_train = generateXY(50)\n",
        "    assert X_train.shape==(150,2)\n",
        "    assert Y_train.shape==(150,1)\n",
        "    print('Test passed', '\\U0001F44D')\n",
        "test_generateXY()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test passed ðŸ‘\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YJ3TNcj-tULI"
      },
      "source": [
        "### One-hot encoding\n",
        "\n",
        "Now our Y is in the form [0], [1] and [2]. We want to convert them to [1,0,0], [0,1,0] and [0,0,1], respectively. \n",
        "Could you write a code to convert Y (with one column) into one-hot encoded Y (with 3 columns)?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "id": "_n4fYMC0tULJ",
        "nbgrader": {
          "checksum": "2920fc139021b2f772982b2e16731703",
          "grade": false,
          "grade_id": "cell-db496b9b86c28424",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "colab": {}
      },
      "source": [
        "\n",
        "def oneHot(y, Ny):\n",
        "    '''\n",
        "    Input:\n",
        "        y: an int in {0, 1, 2}\n",
        "        Ny: Number of classes, e.g., 3 here.\n",
        "    Output:\n",
        "        Y: a vector of Ny (=3) tuples\n",
        "    '''\n",
        "    # YOUR CODE HERe\n",
        "    from keras.utils import to_categorical\n",
        "\n",
        "    return to_categorical(y, num_classes = Ny)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "fq8OZ0cxtULM",
        "nbgrader": {
          "checksum": "8612cec704a627b66ff552899569f828",
          "grade": true,
          "grade_id": "cell-24fb717c7ea66826",
          "locked": true,
          "points": 2,
          "schema_version": 1,
          "solution": false
        },
        "outputId": "9a245bd5-d9e3-4e55-9225-386914138328",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "def test_oneHot():\n",
        "    assert np.all(oneHot(0,3)==np.array([1,0,0]))\n",
        "    assert np.all(oneHot(1,3)==np.array([0,1,0]))\n",
        "    assert np.all(oneHot(2,3)==np.array([0,0,1]))\n",
        "    print('Test passed', '\\U0001F44D')\n",
        "test_oneHot()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test passed ðŸ‘\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EzQywDiStULR"
      },
      "source": [
        "### Input Normalization\n",
        "X can lie in any unbounded range. We need to curtail to a narrow range close to zero. This helps in enhancing the stability of training and hyper-parameter tuning.\n",
        "This is normally achieved by scaling the X to have zero mean and unit standard deviation (std).\n",
        "\n",
        "$X \\leftarrow \\frac{X-mean(X)}{std(X)}$, where this is element wise division\n",
        "\n",
        "Could you use training samples to find mean and std, and normalize your X_train with that?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "id": "_v_HEe10tULS",
        "nbgrader": {
          "checksum": "4d88f9abc4004f238b182e54336e76e2",
          "grade": false,
          "grade_id": "cell-8564364c76ddcdc7",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "colab": {}
      },
      "source": [
        "def findMeanStddev(X):\n",
        "    '''\n",
        "    Input: \n",
        "        X: a matrix of size (no. of samples, dimension of each sample)\n",
        "    Output:\n",
        "        mean: mean of samples in X; shape is (dimension of each sample,)\n",
        "        stddev: element-wise std dev of sample in X; shape is (dimension of each sample,)\n",
        "    '''\n",
        "    # YOUR CODE HERE\n",
        "    mean = np.mean(X,axis=0)\n",
        "    stddev = np.std(X,axis=0)\n",
        "    return mean, stddev"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "qYUioNiqxRyi",
        "nbgrader": {
          "checksum": "5d5ccf5b778b190a8607fe045aebce74",
          "grade": true,
          "grade_id": "cell-c060c271af9064e7",
          "locked": true,
          "points": 2,
          "schema_version": 1,
          "solution": false
        },
        "outputId": "dfd76828-cb1f-4379-c121-1063401a2d00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def test_findMeanStddev():\n",
        "    X = np.array([[3,2,6],[7,4,2],[3,5,1]])\n",
        "    mean, stddev = findMeanStddev(X)\n",
        "    assert np.isclose(mean, np.array([4.33, 3.66, 3.]), atol=0.1).all()\n",
        "    assert np.isclose(stddev, np.array([1.88, 1.24, 2.16]), atol=0.1).all()\n",
        "    print('Test passed', '\\U0001F44D')\n",
        "test_findMeanStddev()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test passed ðŸ‘\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "id": "gG4sm2WfwRqu",
        "nbgrader": {
          "checksum": "6c5fc8807584cce426d6dd8fd10dfc7c",
          "grade": false,
          "grade_id": "cell-80ad17d9f5962f88",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "colab": {}
      },
      "source": [
        "def normalizeX(X, mean, stddev):\n",
        "    '''\n",
        "    Input:\n",
        "        X: a matrix of size (no. of samples, dimension of each sample)\n",
        "        mean: mean of samples in X (same size as X)\n",
        "        stddev: element-wise std dev of sample in X (same size as X) \n",
        "    Output:\n",
        "        Xn: X modified to have 0 mean and 1 std dev\n",
        "    '''\n",
        "    # YOUR CODE HERE\n",
        "    if stddev.all()==0:\n",
        "      Xn = np.zeros(X.shape)\n",
        "    else:\n",
        "      \n",
        "      Xn = (X-mean)/stddev\n",
        "    return Xn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "t4JdFDb7tULZ",
        "nbgrader": {
          "checksum": "cb4af2655a94d3e991efe9c64ba57a8c",
          "grade": true,
          "grade_id": "cell-0880b9b53201680b",
          "locked": true,
          "points": 2,
          "schema_version": 1,
          "solution": false
        },
        "outputId": "220eae53-7aef-449c-e6eb-9bc8fdea17af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def test_normalizeX():\n",
        "    X = np.ones((3,3))\n",
        "    m,s = findMeanStddev(X)\n",
        "    assert np.all(m==np.ones(3))\n",
        "    assert np.all(s==np.zeros(3))\n",
        "    assert np.all(normalizeX(X,m,s)==0*X)\n",
        "    # test on random X\n",
        "    X = np.random.random((5,3))\n",
        "    m,s = findMeanStddev(X)\n",
        "    Xn = normalizeX(X,m,s)\n",
        "    mn, sn = findMeanStddev(Xn)\n",
        "    assert np.allclose(mn, np.zeros(3))\n",
        "    assert np.allclose(sn, np.ones(3))\n",
        "    print('Test passed', '\\U0001F44D')\n",
        "test_normalizeX()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test passed ðŸ‘\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1zpEX8EEtULe"
      },
      "source": [
        "### Plotting\n",
        "Could you plot all the samples in X_train with different colors for different classes?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JfkkWGWZtULf",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k']\n",
        "def plotXY(X, Y):\n",
        "    '''\n",
        "    Inputs:\n",
        "        X: a matrix of size (no. of samples, dimension of each sample)\n",
        "        Y: a matrix of size (no. of samples, no. of classes) - these are one-hot vectors\n",
        "    Action:\n",
        "        Plots the samples in X, their color depends on Y\n",
        "    '''\n",
        "    Ny = Y.shape[1]\n",
        "    for cls in range(Ny):\n",
        "        idx = np.where(Y[:,cls]==1)[0]\n",
        "        plt.plot(X[idx,0], X[idx,1], colors[cls]+'.')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyMwU_fANVzn",
        "colab_type": "code",
        "outputId": "e81d7943-2cf3-4112-d236-bf1019d9cc9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''''def Train_Test_Split(X,Y,per=.2):\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.10, random_state = 1)\n",
        "  return X_train, X_test, y_train, y_test'''"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"''def Train_Test_Split(X,Y,per=.2):\\n  from sklearn.model_selection import train_test_split\\n  X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.10, random_state = 1)\\n  return X_train, X_test, y_train, y_test\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kB3jK6IrtULk"
      },
      "source": [
        "## Creating the Network\n",
        "We now create the network with dense layers: \n",
        "$y = f(Wx)$\n",
        "\n",
        "ReLU activation: \n",
        "$f(h) = h, h>0; 0, h\\le 0$\n",
        "\n",
        "Softmax activation: \n",
        "$f(h_i) = \\frac{\\exp(h_i)}{\\sum_j \\exp(h_j)}$\n",
        "\n",
        "Categorical cross-entropy loss:\n",
        "$\\mathcal{L} = -\\sum_t y^d_t \\log y_t$\n",
        "\n",
        "Stochastic Gradient Descent:\n",
        "$w_{ij} \\leftarrow w_{ij} - \\eta \\frac{\\partial \\mathcal{L}}{\\partial w_{ij}}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "id": "g60Qem92tULl",
        "nbgrader": {
          "checksum": "1f332e46663382a71f1dfa333725d807",
          "grade": false,
          "grade_id": "cell-e18133df577f7820",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "from keras import optimizers\n",
        "\n",
        "def makeNN(Nx, Nh, Ny):\n",
        "    '''\n",
        "    Input:\n",
        "        Nx: int; no. of input nodes; shape of each sample; i.e., X.shape[1:] \n",
        "        Nh: int; no. of hidden neurons\n",
        "        Ny: int; no. of output nodes; shape of output; i.e., Y.shape[1]\n",
        "    Output:\n",
        "        model: keras NN model with Input layer, Dense layer with Nh neurons, \n",
        "                and Dense output layer with softmax non-linearity, loss function\n",
        "                categorical-crossentropy, optimizer SGD.\n",
        "    '''\n",
        "    # YOUR CODE HERE\n",
        "    model = Sequential()\n",
        "    \n",
        "    \n",
        "    model.add(Dense(10, input_dim = Nx, activation='relu'))\n",
        "    \n",
        "    \n",
        "    while(Nh!=0):\n",
        "      model.add(Dense(20, activation='relu'))\n",
        "      Nh=Nh-1\n",
        "    \n",
        "    \n",
        "    \n",
        "    model.add(Dense(Ny, activation='softmax'))\n",
        "    model.compile(loss = 'categorical_crossentropy', optimizer = 'sgd', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Q-Gf4DSltULt"
      },
      "source": [
        "### Plotting the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0qkPv1xptULu",
        "colab": {}
      },
      "source": [
        "def plotModel(model):\n",
        "    from keras.utils import plot_model\n",
        "    plot_model(model, show_shapes=True, show_layer_names=True, to_file='model.png')\n",
        "    from IPython.display import Image\n",
        "    Image(retina=True, filename='model.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XO26y8VZtULz"
      },
      "source": [
        "### Training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "id": "Yfvm6pH5tUL0",
        "nbgrader": {
          "checksum": "78b5d80f2ec4bcbc57d80a6bc475f285",
          "grade": false,
          "grade_id": "cell-8a4f621147d44a84",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "colab": {}
      },
      "source": [
        "def trainNN(model, X, Y, Nepochs):\n",
        "    '''\n",
        "    Action:\n",
        "        Train model with model.fit\n",
        "    '''\n",
        "    # YOUR CODE HERE\n",
        "    return  model.fit(X, Y, epochs=Nepochs, batch_size=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "id": "QZRghwIG2I5c",
        "nbgrader": {
          "checksum": "5d34ead5470a39daddbd54aa7f19ef1f",
          "grade": false,
          "grade_id": "cell-c45fc6de4c3fc4c9",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "colab": {}
      },
      "source": [
        "def trainModel(N, Nh, Nepochs):\n",
        "    '''\n",
        "    generateXY, normalizeX, oneHot, makeNN, trainNN\n",
        "    Input:\n",
        "        N: int; no. of training samples per class\n",
        "        Nh: int; no. of neurons in hidden layer\n",
        "    Output:\n",
        "        model: keras NN model trained with the training data\n",
        "        mean_train, stddev_train: mean and stddev of training data - you will \n",
        "                            need this for normalizing your test data\n",
        "    '''\n",
        "    # YOUR CODE HERE\n",
        "    X,Y = generateXY(N)\n",
        "\n",
        "    mean, stddev = findMeanStddev(X)\n",
        "    mean_train=mean\n",
        "    stddev_train=stddev\n",
        "    X = normalizeX(X, mean, stddev)\n",
        "    \n",
        "    Y = oneHot(Y, Ny=3)\n",
        "\n",
        "    Nx=X.shape[1:][0]\n",
        "    Ny=Y.shape[1:][0]\n",
        "    \n",
        "\n",
        "\n",
        "    model = makeNN(Nx, Nh, Ny)\n",
        "    plotModel(model)\n",
        "    trainNN(model, X, Y, Nepochs)\n",
        "    return model, mean_train, stddev_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y7a1LEcgtUL4"
      },
      "source": [
        "### Evaluation\n",
        "Could you:\n",
        "- Generate 20 samples from each class\n",
        "- Normalize them with mean_train and stddev_train\n",
        "- Get Y_test as one hot encoded labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_s_8pRJ60-6",
        "colab_type": "code",
        "outputId": "dd0fb7b2-5250-43c5-8355-b7449dc28148",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\"\"\"def generateXY1(Ntest):\n",
        "  Y_test = np.random.randint(0, 3, size=(Ntest,1))\n",
        "  X_test = np.zeros((Ntest,2))\n",
        "  for i in range(Ntest):\n",
        "    X_test[i,:] = generateX(Y_test[i])\n",
        "  return X_test, Y_test\"\"\""
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'def generateXY1(Ntest):\\n  Y_test = np.random.randint(0, 3, size=(Ntest,1))\\n  X_test = np.zeros((Ntest,2))\\n  for i in range(Ntest):\\n    X_test[i,:] = generateX(Y_test[i])\\n  return X_test, Y_test'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "id": "dkj4meV_tUL9",
        "nbgrader": {
          "checksum": "1c367e3d2d36a80eb1fffbb27eb32da8",
          "grade": false,
          "grade_id": "cell-02b3b15dc3f435fe",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "colab": {}
      },
      "source": [
        "def testModel(model, Ntest, mean_train, stddev_train):\n",
        "    '''\n",
        "    generateXY for test, normalize, onehot, evaluate the model\n",
        "    Inputs:\n",
        "        model: trained Keras NN model\n",
        "        Ntest: int; number of test samples per class\n",
        "    Output:\n",
        "        accuracy: float; accuracy on the test data\n",
        "        CM: confusion matrix on the test data\n",
        "    '''\n",
        "    # YOUR CODE HERE\n",
        "    X_test,Y_test = generateXY(Ntest)\n",
        "    \n",
        "\n",
        "    X_test = normalizeX(X_test, mean_train, stddev_train)\n",
        "    \n",
        "    Y_test = oneHot(Y_test, Ny)\n",
        "\n",
        "    scores = model.evaluate(X_test, Y_test)\n",
        "    accuracy = scores\n",
        "    print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "    from sklearn.metrics import classification_report, confusion_matrix  \n",
        "    predictions = np.argmax(model.predict(X_test), axis=1)\n",
        "    Y_test = np.argmax(Y_test,axis=1)\n",
        "    CM = confusion_matrix(Y_test,predictions)\n",
        "    print(CM)  \n",
        "    print(classification_report(Y_test,predictions))  \n",
        "    return accuracy, CM\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N9AKg5YBtUMB",
        "outputId": "9ab156e0-9dc4-4c59-d6c2-9e5639701f9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4392
        }
      },
      "source": [
        "model, mean_train, stddev_train = trainModel(500, 1, 100)\n",
        "accuracy, CM = testModel(model, 20, mean_train, stddev_train)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0614 20:15:44.191025 139766597957504 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0614 20:15:44.235343 139766597957504 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0614 20:15:44.241364 139766597957504 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0614 20:15:44.284044 139766597957504 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0614 20:15:44.307949 139766597957504 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 10)                30        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 20)                220       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 63        \n",
            "=================================================================\n",
            "Total params: 313\n",
            "Trainable params: 313\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0614 20:15:44.641940 139766597957504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0614 20:15:44.697600 139766597957504 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 1.1027 - acc: 0.3340\n",
            "Epoch 2/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 1.0341 - acc: 0.3707\n",
            "Epoch 3/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.9825 - acc: 0.4493\n",
            "Epoch 4/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.9409 - acc: 0.5160\n",
            "Epoch 5/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.9044 - acc: 0.5687\n",
            "Epoch 6/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.8722 - acc: 0.6307\n",
            "Epoch 7/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.8435 - acc: 0.7027\n",
            "Epoch 8/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.8177 - acc: 0.7807\n",
            "Epoch 9/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.7940 - acc: 0.8307\n",
            "Epoch 10/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.7719 - acc: 0.8533\n",
            "Epoch 11/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.7511 - acc: 0.8647\n",
            "Epoch 12/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.7312 - acc: 0.8700\n",
            "Epoch 13/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.7121 - acc: 0.8727\n",
            "Epoch 14/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.6936 - acc: 0.8773\n",
            "Epoch 15/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.6756 - acc: 0.8780\n",
            "Epoch 16/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.6580 - acc: 0.8793\n",
            "Epoch 17/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.6408 - acc: 0.8813\n",
            "Epoch 18/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.6240 - acc: 0.8807\n",
            "Epoch 19/100\n",
            "1500/1500 [==============================] - 0s 26us/step - loss: 0.6075 - acc: 0.8820\n",
            "Epoch 20/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.5914 - acc: 0.8807\n",
            "Epoch 21/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.5757 - acc: 0.8813\n",
            "Epoch 22/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.5603 - acc: 0.8820\n",
            "Epoch 23/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.5454 - acc: 0.8820\n",
            "Epoch 24/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.5309 - acc: 0.8840\n",
            "Epoch 25/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.5170 - acc: 0.8840\n",
            "Epoch 26/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.5036 - acc: 0.8847\n",
            "Epoch 27/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.4908 - acc: 0.8860\n",
            "Epoch 28/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.4786 - acc: 0.8867\n",
            "Epoch 29/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.4670 - acc: 0.8880\n",
            "Epoch 30/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.4560 - acc: 0.8873\n",
            "Epoch 31/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.4456 - acc: 0.8873\n",
            "Epoch 32/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.4359 - acc: 0.8867\n",
            "Epoch 33/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.4267 - acc: 0.8873\n",
            "Epoch 34/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.4180 - acc: 0.8860\n",
            "Epoch 35/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.4100 - acc: 0.8873\n",
            "Epoch 36/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.4024 - acc: 0.8880\n",
            "Epoch 37/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.3954 - acc: 0.8880\n",
            "Epoch 38/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.3889 - acc: 0.8893\n",
            "Epoch 39/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.3829 - acc: 0.8900\n",
            "Epoch 40/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.3772 - acc: 0.8900\n",
            "Epoch 41/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.3718 - acc: 0.8893\n",
            "Epoch 42/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.3670 - acc: 0.8900\n",
            "Epoch 43/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.3625 - acc: 0.8913\n",
            "Epoch 44/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.3583 - acc: 0.8913\n",
            "Epoch 45/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.3543 - acc: 0.8913\n",
            "Epoch 46/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.3507 - acc: 0.8907\n",
            "Epoch 47/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.3473 - acc: 0.8907\n",
            "Epoch 48/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.3442 - acc: 0.8913\n",
            "Epoch 49/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.3412 - acc: 0.8907\n",
            "Epoch 50/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.3384 - acc: 0.8907\n",
            "Epoch 51/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.3359 - acc: 0.8920\n",
            "Epoch 52/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.3335 - acc: 0.8927\n",
            "Epoch 53/100\n",
            "1500/1500 [==============================] - 0s 32us/step - loss: 0.3313 - acc: 0.8927\n",
            "Epoch 54/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.3293 - acc: 0.8927\n",
            "Epoch 55/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.3273 - acc: 0.8927\n",
            "Epoch 56/100\n",
            "1500/1500 [==============================] - 0s 26us/step - loss: 0.3255 - acc: 0.8933\n",
            "Epoch 57/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.3237 - acc: 0.8933\n",
            "Epoch 58/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.3221 - acc: 0.8933\n",
            "Epoch 59/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.3206 - acc: 0.8927\n",
            "Epoch 60/100\n",
            "1500/1500 [==============================] - 0s 26us/step - loss: 0.3192 - acc: 0.8933\n",
            "Epoch 61/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.3178 - acc: 0.8920\n",
            "Epoch 62/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.3166 - acc: 0.8920\n",
            "Epoch 63/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.3154 - acc: 0.8927\n",
            "Epoch 64/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.3143 - acc: 0.8920\n",
            "Epoch 65/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.3132 - acc: 0.8927\n",
            "Epoch 66/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.3123 - acc: 0.8933\n",
            "Epoch 67/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.3114 - acc: 0.8933\n",
            "Epoch 68/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.3104 - acc: 0.8933\n",
            "Epoch 69/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.3096 - acc: 0.8940\n",
            "Epoch 70/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.3088 - acc: 0.8933\n",
            "Epoch 71/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.3080 - acc: 0.8940\n",
            "Epoch 72/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.3073 - acc: 0.8940\n",
            "Epoch 73/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.3067 - acc: 0.8947\n",
            "Epoch 74/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.3060 - acc: 0.8940\n",
            "Epoch 75/100\n",
            "1500/1500 [==============================] - 0s 26us/step - loss: 0.3053 - acc: 0.8940\n",
            "Epoch 76/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.3048 - acc: 0.8947\n",
            "Epoch 77/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.3042 - acc: 0.8940\n",
            "Epoch 78/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.3037 - acc: 0.8947\n",
            "Epoch 79/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.3031 - acc: 0.8953\n",
            "Epoch 80/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.3026 - acc: 0.8960\n",
            "Epoch 81/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.3022 - acc: 0.8947\n",
            "Epoch 82/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.3017 - acc: 0.8960\n",
            "Epoch 83/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.3012 - acc: 0.8960\n",
            "Epoch 84/100\n",
            "1500/1500 [==============================] - 0s 26us/step - loss: 0.3008 - acc: 0.8953\n",
            "Epoch 85/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.3005 - acc: 0.8960\n",
            "Epoch 86/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.3000 - acc: 0.8953\n",
            "Epoch 87/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.2996 - acc: 0.8960\n",
            "Epoch 88/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.2993 - acc: 0.8960\n",
            "Epoch 89/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.2990 - acc: 0.8967\n",
            "Epoch 90/100\n",
            "1500/1500 [==============================] - 0s 30us/step - loss: 0.2986 - acc: 0.8967\n",
            "Epoch 91/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.2984 - acc: 0.8960\n",
            "Epoch 92/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.2981 - acc: 0.8960\n",
            "Epoch 93/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.2978 - acc: 0.8947\n",
            "Epoch 94/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2974 - acc: 0.8967\n",
            "Epoch 95/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.2972 - acc: 0.8953\n",
            "Epoch 96/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.2970 - acc: 0.8953\n",
            "Epoch 97/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.2967 - acc: 0.8953\n",
            "Epoch 98/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.2964 - acc: 0.8953\n",
            "Epoch 99/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.2962 - acc: 0.8953\n",
            "Epoch 100/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.2959 - acc: 0.8953\n",
            "60/60 [==============================] - 0s 490us/step\n",
            "\n",
            "acc: 88.33%\n",
            "[[12  1  3]\n",
            " [ 2 17  0]\n",
            " [ 1  0 24]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.75      0.77        16\n",
            "           1       0.94      0.89      0.92        19\n",
            "           2       0.89      0.96      0.92        25\n",
            "\n",
            "    accuracy                           0.88        60\n",
            "   macro avg       0.88      0.87      0.87        60\n",
            "weighted avg       0.88      0.88      0.88        60\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1WdkjiA2AZYj"
      },
      "source": [
        "# ADVANCED QUESTIONS\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OFBjZFLnA100"
      },
      "source": [
        "### Effect of changing Nh\n",
        "### Effect of changing Nepochs\n",
        "### Effect of changing N, no. of training samples\n",
        "\n",
        "Can you observe overfitting? \n",
        "\n",
        "Can you do hyperparameter tuning here? \n",
        "\n",
        "To normalize test data, why do we use the mean and stddev of training data?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCGp0F74rLXN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HUeAYeTHlxc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Nh=np.linspace(start=1, stop=10, num=10, endpoint=True, retstep=False, dtype=int)\n",
        "N=np.linspace(start=10, stop=100, num=10, endpoint=True, retstep=False, dtype=int)\n",
        "Nepochs =np.linspace(start=100, stop=1000, num=10, endpoint=True, retstep=False, dtype=int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKSoxOtGHvh-",
        "colab_type": "code",
        "outputId": "7568415a-9853-48a8-a61d-3d76199ea687",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 42505
        }
      },
      "source": [
        "Nh_acc=[]\n",
        "for element in Nh:\n",
        "  model, mean_train, stddev_train = trainModel(500, element, 100)\n",
        "  accuracy, CM = testModel(model, 20, mean_train, stddev_train)\n",
        "  print(accuracy)\n",
        "  Nh_acc.append(accuracy)\n",
        "  "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 10)                30        \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 20)                220       \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 3)                 63        \n",
            "=================================================================\n",
            "Total params: 313\n",
            "Trainable params: 313\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1500/1500 [==============================] - 0s 120us/step - loss: 1.2400 - acc: 0.1000\n",
            "Epoch 2/100\n",
            "1500/1500 [==============================] - 0s 30us/step - loss: 1.1624 - acc: 0.2240\n",
            "Epoch 3/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 1.0967 - acc: 0.3973\n",
            "Epoch 4/100\n",
            "1500/1500 [==============================] - 0s 30us/step - loss: 1.0399 - acc: 0.5273\n",
            "Epoch 5/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.9897 - acc: 0.6113\n",
            "Epoch 6/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.9448 - acc: 0.6480\n",
            "Epoch 7/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.9046 - acc: 0.6513\n",
            "Epoch 8/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.8686 - acc: 0.6560\n",
            "Epoch 9/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.8357 - acc: 0.6600\n",
            "Epoch 10/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.8055 - acc: 0.6700\n",
            "Epoch 11/100\n",
            "1500/1500 [==============================] - 0s 32us/step - loss: 0.7774 - acc: 0.6813\n",
            "Epoch 12/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.7515 - acc: 0.6953\n",
            "Epoch 13/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.7275 - acc: 0.7067\n",
            "Epoch 14/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.7054 - acc: 0.7187\n",
            "Epoch 15/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.6849 - acc: 0.7320\n",
            "Epoch 16/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.6657 - acc: 0.7427\n",
            "Epoch 17/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.6479 - acc: 0.7560\n",
            "Epoch 18/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.6313 - acc: 0.7707\n",
            "Epoch 19/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.6157 - acc: 0.7820\n",
            "Epoch 20/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.6010 - acc: 0.7933\n",
            "Epoch 21/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.5872 - acc: 0.8007\n",
            "Epoch 22/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.5742 - acc: 0.8113\n",
            "Epoch 23/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.5617 - acc: 0.8187\n",
            "Epoch 24/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.5498 - acc: 0.8280\n",
            "Epoch 25/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.5385 - acc: 0.8327\n",
            "Epoch 26/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.5276 - acc: 0.8380\n",
            "Epoch 27/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.5170 - acc: 0.8413\n",
            "Epoch 28/100\n",
            "1500/1500 [==============================] - 0s 32us/step - loss: 0.5068 - acc: 0.8453\n",
            "Epoch 29/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.4969 - acc: 0.8513\n",
            "Epoch 30/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.4872 - acc: 0.8547\n",
            "Epoch 31/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.4779 - acc: 0.8580\n",
            "Epoch 32/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.4687 - acc: 0.8613\n",
            "Epoch 33/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.4597 - acc: 0.8620\n",
            "Epoch 34/100\n",
            "1500/1500 [==============================] - 0s 32us/step - loss: 0.4510 - acc: 0.8653\n",
            "Epoch 35/100\n",
            "1500/1500 [==============================] - 0s 30us/step - loss: 0.4425 - acc: 0.8700\n",
            "Epoch 36/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.4341 - acc: 0.8753\n",
            "Epoch 37/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.4261 - acc: 0.8787\n",
            "Epoch 38/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.4183 - acc: 0.8813\n",
            "Epoch 39/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.4106 - acc: 0.8840\n",
            "Epoch 40/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.4031 - acc: 0.8873\n",
            "Epoch 41/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.3960 - acc: 0.8873\n",
            "Epoch 42/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.3890 - acc: 0.8887\n",
            "Epoch 43/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.3824 - acc: 0.8887\n",
            "Epoch 44/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.3760 - acc: 0.8927\n",
            "Epoch 45/100\n",
            "1500/1500 [==============================] - 0s 26us/step - loss: 0.3699 - acc: 0.8913\n",
            "Epoch 46/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.3640 - acc: 0.8933\n",
            "Epoch 47/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.3584 - acc: 0.8940\n",
            "Epoch 48/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.3530 - acc: 0.8940\n",
            "Epoch 49/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.3480 - acc: 0.8967\n",
            "Epoch 50/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.3431 - acc: 0.8967\n",
            "Epoch 51/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.3386 - acc: 0.8960\n",
            "Epoch 52/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.3343 - acc: 0.8960\n",
            "Epoch 53/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.3303 - acc: 0.8947\n",
            "Epoch 54/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.3264 - acc: 0.8940\n",
            "Epoch 55/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.3228 - acc: 0.8940\n",
            "Epoch 56/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.3194 - acc: 0.8940\n",
            "Epoch 57/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.3162 - acc: 0.8940\n",
            "Epoch 58/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.3131 - acc: 0.8933\n",
            "Epoch 59/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.3103 - acc: 0.8933\n",
            "Epoch 60/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.3077 - acc: 0.8927\n",
            "Epoch 61/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.3053 - acc: 0.8940\n",
            "Epoch 62/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.3029 - acc: 0.8940\n",
            "Epoch 63/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.3008 - acc: 0.8947\n",
            "Epoch 64/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.2988 - acc: 0.8960\n",
            "Epoch 65/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.2969 - acc: 0.8947\n",
            "Epoch 66/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.2952 - acc: 0.8953\n",
            "Epoch 67/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.2935 - acc: 0.8947\n",
            "Epoch 68/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.2920 - acc: 0.8960\n",
            "Epoch 69/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.2906 - acc: 0.8953\n",
            "Epoch 70/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.2893 - acc: 0.8960\n",
            "Epoch 71/100\n",
            "1500/1500 [==============================] - 0s 32us/step - loss: 0.2881 - acc: 0.8960\n",
            "Epoch 72/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.2869 - acc: 0.8967\n",
            "Epoch 73/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.2858 - acc: 0.8953\n",
            "Epoch 74/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.2848 - acc: 0.8960\n",
            "Epoch 75/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.2838 - acc: 0.8953\n",
            "Epoch 76/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.2829 - acc: 0.8953\n",
            "Epoch 77/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.2821 - acc: 0.8953\n",
            "Epoch 78/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.2813 - acc: 0.8953\n",
            "Epoch 79/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.2805 - acc: 0.8953\n",
            "Epoch 80/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.2799 - acc: 0.8953\n",
            "Epoch 81/100\n",
            "1500/1500 [==============================] - 0s 32us/step - loss: 0.2792 - acc: 0.8953\n",
            "Epoch 82/100\n",
            "1500/1500 [==============================] - 0s 32us/step - loss: 0.2786 - acc: 0.8960\n",
            "Epoch 83/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.2780 - acc: 0.8953\n",
            "Epoch 84/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.2775 - acc: 0.8953\n",
            "Epoch 85/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.2770 - acc: 0.8953\n",
            "Epoch 86/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.2765 - acc: 0.8953\n",
            "Epoch 87/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.2761 - acc: 0.8967\n",
            "Epoch 88/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.2757 - acc: 0.8953\n",
            "Epoch 89/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.2752 - acc: 0.8953\n",
            "Epoch 90/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.2749 - acc: 0.8953\n",
            "Epoch 91/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.2745 - acc: 0.8953\n",
            "Epoch 92/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.2742 - acc: 0.8947\n",
            "Epoch 93/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.2739 - acc: 0.8953\n",
            "Epoch 94/100\n",
            "1500/1500 [==============================] - 0s 30us/step - loss: 0.2736 - acc: 0.8953\n",
            "Epoch 95/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.2733 - acc: 0.8947\n",
            "Epoch 96/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.2730 - acc: 0.8947\n",
            "Epoch 97/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.2727 - acc: 0.8953\n",
            "Epoch 98/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.2725 - acc: 0.8953\n",
            "Epoch 99/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.2722 - acc: 0.8947\n",
            "Epoch 100/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.2721 - acc: 0.8947\n",
            "60/60 [==============================] - 0s 661us/step\n",
            "\n",
            "acc: 90.00%\n",
            "[[15  1  1]\n",
            " [ 1 19  0]\n",
            " [ 2  1 20]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.88      0.86        17\n",
            "           1       0.90      0.95      0.93        20\n",
            "           2       0.95      0.87      0.91        23\n",
            "\n",
            "    accuracy                           0.90        60\n",
            "   macro avg       0.90      0.90      0.90        60\n",
            "weighted avg       0.90      0.90      0.90        60\n",
            "\n",
            "[0.2987350920836131, 0.899999988079071]\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_7 (Dense)              (None, 10)                30        \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 20)                220       \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 3)                 63        \n",
            "=================================================================\n",
            "Total params: 733\n",
            "Trainable params: 733\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1500/1500 [==============================] - 0s 154us/step - loss: 1.0694 - acc: 0.5560\n",
            "Epoch 2/100\n",
            "1500/1500 [==============================] - 0s 30us/step - loss: 1.0127 - acc: 0.5913\n",
            "Epoch 3/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.9633 - acc: 0.6440\n",
            "Epoch 4/100\n",
            "1500/1500 [==============================] - 0s 46us/step - loss: 0.9193 - acc: 0.7607\n",
            "Epoch 5/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.8794 - acc: 0.8373\n",
            "Epoch 6/100\n",
            "1500/1500 [==============================] - 0s 30us/step - loss: 0.8430 - acc: 0.8507\n",
            "Epoch 7/100\n",
            "1500/1500 [==============================] - 0s 30us/step - loss: 0.8095 - acc: 0.8573\n",
            "Epoch 8/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.7785 - acc: 0.8647\n",
            "Epoch 9/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.7493 - acc: 0.8720\n",
            "Epoch 10/100\n",
            "1500/1500 [==============================] - 0s 30us/step - loss: 0.7216 - acc: 0.8773\n",
            "Epoch 11/100\n",
            "1500/1500 [==============================] - 0s 32us/step - loss: 0.6952 - acc: 0.8813\n",
            "Epoch 12/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.6699 - acc: 0.8833\n",
            "Epoch 13/100\n",
            "1500/1500 [==============================] - 0s 32us/step - loss: 0.6455 - acc: 0.8853\n",
            "Epoch 14/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.6220 - acc: 0.8847\n",
            "Epoch 15/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.5993 - acc: 0.8880\n",
            "Epoch 16/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.5775 - acc: 0.8887\n",
            "Epoch 17/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.5566 - acc: 0.8920\n",
            "Epoch 18/100\n",
            "1500/1500 [==============================] - 0s 32us/step - loss: 0.5366 - acc: 0.8933\n",
            "Epoch 19/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.5176 - acc: 0.8940\n",
            "Epoch 20/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.4996 - acc: 0.8960\n",
            "Epoch 21/100\n",
            "1500/1500 [==============================] - 0s 37us/step - loss: 0.4825 - acc: 0.8960\n",
            "Epoch 22/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.4665 - acc: 0.8967\n",
            "Epoch 23/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.4513 - acc: 0.8987\n",
            "Epoch 24/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.4370 - acc: 0.9007\n",
            "Epoch 25/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.4237 - acc: 0.9027\n",
            "Epoch 26/100\n",
            "1500/1500 [==============================] - 0s 32us/step - loss: 0.4111 - acc: 0.9020\n",
            "Epoch 27/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.3994 - acc: 0.9027\n",
            "Epoch 28/100\n",
            "1500/1500 [==============================] - 0s 30us/step - loss: 0.3886 - acc: 0.9033\n",
            "Epoch 29/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.3785 - acc: 0.9033\n",
            "Epoch 30/100\n",
            "1500/1500 [==============================] - 0s 30us/step - loss: 0.3691 - acc: 0.9033\n",
            "Epoch 31/100\n",
            "1500/1500 [==============================] - 0s 30us/step - loss: 0.3604 - acc: 0.9033\n",
            "Epoch 32/100\n",
            "1500/1500 [==============================] - 0s 30us/step - loss: 0.3524 - acc: 0.9027\n",
            "Epoch 33/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.3449 - acc: 0.9027\n",
            "Epoch 34/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.3380 - acc: 0.9027\n",
            "Epoch 35/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.3316 - acc: 0.9020\n",
            "Epoch 36/100\n",
            "1500/1500 [==============================] - 0s 30us/step - loss: 0.3258 - acc: 0.9020\n",
            "Epoch 37/100\n",
            "1500/1500 [==============================] - 0s 30us/step - loss: 0.3203 - acc: 0.9013\n",
            "Epoch 38/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.3154 - acc: 0.9020\n",
            "Epoch 39/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.3108 - acc: 0.9033\n",
            "Epoch 40/100\n",
            "1500/1500 [==============================] - 0s 30us/step - loss: 0.3066 - acc: 0.9027\n",
            "Epoch 41/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.3028 - acc: 0.9027\n",
            "Epoch 42/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.2993 - acc: 0.9020\n",
            "Epoch 43/100\n",
            "1500/1500 [==============================] - 0s 30us/step - loss: 0.2961 - acc: 0.9020\n",
            "Epoch 44/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.2932 - acc: 0.9020\n",
            "Epoch 45/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.2904 - acc: 0.9027\n",
            "Epoch 46/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.2880 - acc: 0.9020\n",
            "Epoch 47/100\n",
            "1500/1500 [==============================] - 0s 30us/step - loss: 0.2856 - acc: 0.9033\n",
            "Epoch 48/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.2836 - acc: 0.9027\n",
            "Epoch 49/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.2817 - acc: 0.9013\n",
            "Epoch 50/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.2799 - acc: 0.9027\n",
            "Epoch 51/100\n",
            "1500/1500 [==============================] - 0s 27us/step - loss: 0.2782 - acc: 0.9033\n",
            "Epoch 52/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.2768 - acc: 0.9027\n",
            "Epoch 53/100\n",
            "1500/1500 [==============================] - 0s 30us/step - loss: 0.2755 - acc: 0.9013\n",
            "Epoch 54/100\n",
            "1500/1500 [==============================] - 0s 30us/step - loss: 0.2742 - acc: 0.9027\n",
            "Epoch 55/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.2730 - acc: 0.9033\n",
            "Epoch 56/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.2720 - acc: 0.9033\n",
            "Epoch 57/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.2709 - acc: 0.9033\n",
            "Epoch 58/100\n",
            "1500/1500 [==============================] - 0s 32us/step - loss: 0.2700 - acc: 0.9027\n",
            "Epoch 59/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.2691 - acc: 0.9027\n",
            "Epoch 60/100\n",
            "1500/1500 [==============================] - 0s 32us/step - loss: 0.2684 - acc: 0.9033\n",
            "Epoch 61/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.2676 - acc: 0.9027\n",
            "Epoch 62/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.2669 - acc: 0.9033\n",
            "Epoch 63/100\n",
            "1500/1500 [==============================] - 0s 30us/step - loss: 0.2662 - acc: 0.9040\n",
            "Epoch 64/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.2657 - acc: 0.9027\n",
            "Epoch 65/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.2652 - acc: 0.9027\n",
            "Epoch 66/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.2646 - acc: 0.9040\n",
            "Epoch 67/100\n",
            "1500/1500 [==============================] - 0s 30us/step - loss: 0.2642 - acc: 0.9033\n",
            "Epoch 68/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.2636 - acc: 0.9027\n",
            "Epoch 69/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.2632 - acc: 0.9040\n",
            "Epoch 70/100\n",
            "1500/1500 [==============================] - 0s 30us/step - loss: 0.2629 - acc: 0.9020\n",
            "Epoch 71/100\n",
            "1500/1500 [==============================] - 0s 30us/step - loss: 0.2624 - acc: 0.9033\n",
            "Epoch 72/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.2620 - acc: 0.9040\n",
            "Epoch 73/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.2616 - acc: 0.9027\n",
            "Epoch 74/100\n",
            "1500/1500 [==============================] - 0s 30us/step - loss: 0.2614 - acc: 0.9040\n",
            "Epoch 75/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.2610 - acc: 0.9040\n",
            "Epoch 76/100\n",
            "1500/1500 [==============================] - 0s 32us/step - loss: 0.2607 - acc: 0.9040\n",
            "Epoch 77/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.2604 - acc: 0.9033\n",
            "Epoch 78/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2602 - acc: 0.9020\n",
            "Epoch 79/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.2598 - acc: 0.9033\n",
            "Epoch 80/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.2596 - acc: 0.9027\n",
            "Epoch 81/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.2593 - acc: 0.9040\n",
            "Epoch 82/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.2592 - acc: 0.9033\n",
            "Epoch 83/100\n",
            "1500/1500 [==============================] - 0s 30us/step - loss: 0.2589 - acc: 0.9033\n",
            "Epoch 84/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.2587 - acc: 0.9040\n",
            "Epoch 85/100\n",
            "1500/1500 [==============================] - 0s 30us/step - loss: 0.2585 - acc: 0.9033\n",
            "Epoch 86/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.2583 - acc: 0.9033\n",
            "Epoch 87/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.2582 - acc: 0.9033\n",
            "Epoch 88/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.2580 - acc: 0.9033\n",
            "Epoch 89/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.2577 - acc: 0.9040\n",
            "Epoch 90/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.2575 - acc: 0.9027\n",
            "Epoch 91/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.2574 - acc: 0.9027\n",
            "Epoch 92/100\n",
            "1500/1500 [==============================] - 0s 28us/step - loss: 0.2573 - acc: 0.9040\n",
            "Epoch 93/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.2572 - acc: 0.9033\n",
            "Epoch 94/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.2569 - acc: 0.9033\n",
            "Epoch 95/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.2569 - acc: 0.9027\n",
            "Epoch 96/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.2568 - acc: 0.9033\n",
            "Epoch 97/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.2567 - acc: 0.9033\n",
            "Epoch 98/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.2565 - acc: 0.9033\n",
            "Epoch 99/100\n",
            "1500/1500 [==============================] - 0s 29us/step - loss: 0.2564 - acc: 0.9033\n",
            "Epoch 100/100\n",
            "1500/1500 [==============================] - 0s 37us/step - loss: 0.2564 - acc: 0.9040\n",
            "60/60 [==============================] - 0s 955us/step\n",
            "\n",
            "acc: 86.67%\n",
            "[[17  3  1]\n",
            " [ 0 20  1]\n",
            " [ 3  0 15]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.81      0.83        21\n",
            "           1       0.87      0.95      0.91        21\n",
            "           2       0.88      0.83      0.86        18\n",
            "\n",
            "    accuracy                           0.87        60\n",
            "   macro avg       0.87      0.87      0.87        60\n",
            "weighted avg       0.87      0.87      0.87        60\n",
            "\n",
            "[0.26488136251767475, 0.8666666706403097]\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_11 (Dense)             (None, 10)                30        \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 20)                220       \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 3)                 63        \n",
            "=================================================================\n",
            "Total params: 1,153\n",
            "Trainable params: 1,153\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1500/1500 [==============================] - 0s 192us/step - loss: 1.0860 - acc: 0.5600\n",
            "Epoch 2/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 1.0635 - acc: 0.5807\n",
            "Epoch 3/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 1.0435 - acc: 0.5967\n",
            "Epoch 4/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 1.0249 - acc: 0.6000\n",
            "Epoch 5/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 1.0064 - acc: 0.6013\n",
            "Epoch 6/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.9876 - acc: 0.6047\n",
            "Epoch 7/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.9679 - acc: 0.6067\n",
            "Epoch 8/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.9473 - acc: 0.6073\n",
            "Epoch 9/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.9256 - acc: 0.6200\n",
            "Epoch 10/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.9027 - acc: 0.6560\n",
            "Epoch 11/100\n",
            "1500/1500 [==============================] - 0s 30us/step - loss: 0.8785 - acc: 0.6827\n",
            "Epoch 12/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.8533 - acc: 0.7073\n",
            "Epoch 13/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.8271 - acc: 0.7387\n",
            "Epoch 14/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.8007 - acc: 0.7533\n",
            "Epoch 15/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.7754 - acc: 0.7680\n",
            "Epoch 16/100\n",
            "1500/1500 [==============================] - 0s 32us/step - loss: 0.7514 - acc: 0.7800\n",
            "Epoch 17/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.7288 - acc: 0.7847\n",
            "Epoch 18/100\n",
            "1500/1500 [==============================] - 0s 32us/step - loss: 0.7079 - acc: 0.7900\n",
            "Epoch 19/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.6885 - acc: 0.7940\n",
            "Epoch 20/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.6708 - acc: 0.8047\n",
            "Epoch 21/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.6542 - acc: 0.8153\n",
            "Epoch 22/100\n",
            "1500/1500 [==============================] - 0s 40us/step - loss: 0.6389 - acc: 0.8213\n",
            "Epoch 23/100\n",
            "1500/1500 [==============================] - 0s 32us/step - loss: 0.6246 - acc: 0.8273\n",
            "Epoch 24/100\n",
            "1500/1500 [==============================] - 0s 32us/step - loss: 0.6111 - acc: 0.8340\n",
            "Epoch 25/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.5985 - acc: 0.8393\n",
            "Epoch 26/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.5866 - acc: 0.8420\n",
            "Epoch 27/100\n",
            "1500/1500 [==============================] - 0s 32us/step - loss: 0.5752 - acc: 0.8467\n",
            "Epoch 28/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.5643 - acc: 0.8500\n",
            "Epoch 29/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.5540 - acc: 0.8540\n",
            "Epoch 30/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.5439 - acc: 0.8553\n",
            "Epoch 31/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.5344 - acc: 0.8560\n",
            "Epoch 32/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.5250 - acc: 0.8573\n",
            "Epoch 33/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.5159 - acc: 0.8580\n",
            "Epoch 34/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.5068 - acc: 0.8607\n",
            "Epoch 35/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.4981 - acc: 0.8633\n",
            "Epoch 36/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.4895 - acc: 0.8667\n",
            "Epoch 37/100\n",
            "1500/1500 [==============================] - 0s 30us/step - loss: 0.4811 - acc: 0.8707\n",
            "Epoch 38/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.4728 - acc: 0.8727\n",
            "Epoch 39/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.4647 - acc: 0.8753\n",
            "Epoch 40/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.4566 - acc: 0.8780\n",
            "Epoch 41/100\n",
            "1500/1500 [==============================] - 0s 30us/step - loss: 0.4487 - acc: 0.8787\n",
            "Epoch 42/100\n",
            "1500/1500 [==============================] - 0s 32us/step - loss: 0.4408 - acc: 0.8800\n",
            "Epoch 43/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.4331 - acc: 0.8820\n",
            "Epoch 44/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.4255 - acc: 0.8827\n",
            "Epoch 45/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.4180 - acc: 0.8847\n",
            "Epoch 46/100\n",
            "1500/1500 [==============================] - 0s 30us/step - loss: 0.4108 - acc: 0.8853\n",
            "Epoch 47/100\n",
            "1500/1500 [==============================] - 0s 32us/step - loss: 0.4038 - acc: 0.8887\n",
            "Epoch 48/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.3968 - acc: 0.8900\n",
            "Epoch 49/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.3901 - acc: 0.8913\n",
            "Epoch 50/100\n",
            "1500/1500 [==============================] - 0s 32us/step - loss: 0.3835 - acc: 0.8920\n",
            "Epoch 51/100\n",
            "1500/1500 [==============================] - 0s 32us/step - loss: 0.3771 - acc: 0.8933\n",
            "Epoch 52/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.3710 - acc: 0.8927\n",
            "Epoch 53/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.3651 - acc: 0.8927\n",
            "Epoch 54/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.3593 - acc: 0.8920\n",
            "Epoch 55/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.3541 - acc: 0.8920\n",
            "Epoch 56/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.3488 - acc: 0.8920\n",
            "Epoch 57/100\n",
            "1500/1500 [==============================] - 0s 32us/step - loss: 0.3439 - acc: 0.8900\n",
            "Epoch 58/100\n",
            "1500/1500 [==============================] - 0s 32us/step - loss: 0.3393 - acc: 0.8913\n",
            "Epoch 59/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.3349 - acc: 0.8920\n",
            "Epoch 60/100\n",
            "1500/1500 [==============================] - 0s 32us/step - loss: 0.3307 - acc: 0.8913\n",
            "Epoch 61/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.3269 - acc: 0.8893\n",
            "Epoch 62/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.3232 - acc: 0.8900\n",
            "Epoch 63/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.3198 - acc: 0.8893\n",
            "Epoch 64/100\n",
            "1500/1500 [==============================] - 0s 40us/step - loss: 0.3166 - acc: 0.8900\n",
            "Epoch 65/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.3136 - acc: 0.8907\n",
            "Epoch 66/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.3108 - acc: 0.8893\n",
            "Epoch 67/100\n",
            "1500/1500 [==============================] - 0s 32us/step - loss: 0.3083 - acc: 0.8900\n",
            "Epoch 68/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.3061 - acc: 0.8887\n",
            "Epoch 69/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.3038 - acc: 0.8887\n",
            "Epoch 70/100\n",
            "1500/1500 [==============================] - 0s 32us/step - loss: 0.3017 - acc: 0.8893\n",
            "Epoch 71/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.2998 - acc: 0.8893\n",
            "Epoch 72/100\n",
            "1500/1500 [==============================] - 0s 32us/step - loss: 0.2977 - acc: 0.8900\n",
            "Epoch 73/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.2961 - acc: 0.8893\n",
            "Epoch 74/100\n",
            "1500/1500 [==============================] - 0s 32us/step - loss: 0.2949 - acc: 0.8900\n",
            "Epoch 75/100\n",
            "1500/1500 [==============================] - 0s 32us/step - loss: 0.2931 - acc: 0.8887\n",
            "Epoch 76/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.2921 - acc: 0.8893\n",
            "Epoch 77/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.2907 - acc: 0.8887\n",
            "Epoch 78/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.2897 - acc: 0.8873\n",
            "Epoch 79/100\n",
            "1500/1500 [==============================] - 0s 32us/step - loss: 0.2885 - acc: 0.8880\n",
            "Epoch 80/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.2875 - acc: 0.8880\n",
            "Epoch 81/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.2867 - acc: 0.8893\n",
            "Epoch 82/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.2857 - acc: 0.8893\n",
            "Epoch 83/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2850 - acc: 0.8893\n",
            "Epoch 84/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 0.2841 - acc: 0.8887\n",
            "Epoch 85/100\n",
            "1500/1500 [==============================] - 0s 30us/step - loss: 0.2835 - acc: 0.8907\n",
            "Epoch 86/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.2830 - acc: 0.8900\n",
            "Epoch 87/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.2822 - acc: 0.8900\n",
            "Epoch 88/100\n",
            "1500/1500 [==============================] - 0s 32us/step - loss: 0.2816 - acc: 0.8907\n",
            "Epoch 89/100\n",
            "1500/1500 [==============================] - 0s 32us/step - loss: 0.2812 - acc: 0.8913\n",
            "Epoch 90/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.2806 - acc: 0.8907\n",
            "Epoch 91/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.2801 - acc: 0.8927\n",
            "Epoch 92/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.2798 - acc: 0.8907\n",
            "Epoch 93/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.2796 - acc: 0.8913\n",
            "Epoch 94/100\n",
            "1500/1500 [==============================] - 0s 32us/step - loss: 0.2791 - acc: 0.8893\n",
            "Epoch 95/100\n",
            "1500/1500 [==============================] - 0s 32us/step - loss: 0.2787 - acc: 0.8920\n",
            "Epoch 96/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.2784 - acc: 0.8900\n",
            "Epoch 97/100\n",
            "1500/1500 [==============================] - 0s 37us/step - loss: 0.2779 - acc: 0.8920\n",
            "Epoch 98/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.2777 - acc: 0.8907\n",
            "Epoch 99/100\n",
            "1500/1500 [==============================] - 0s 31us/step - loss: 0.2773 - acc: 0.8920\n",
            "Epoch 100/100\n",
            "1500/1500 [==============================] - 0s 32us/step - loss: 0.2772 - acc: 0.8913\n",
            "60/60 [==============================] - 0s 1ms/step\n",
            "\n",
            "acc: 85.00%\n",
            "[[15  0  3]\n",
            " [ 2 14  1]\n",
            " [ 3  0 22]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.83      0.79        18\n",
            "           1       1.00      0.82      0.90        17\n",
            "           2       0.85      0.88      0.86        25\n",
            "\n",
            "    accuracy                           0.85        60\n",
            "   macro avg       0.87      0.85      0.85        60\n",
            "weighted avg       0.86      0.85      0.85        60\n",
            "\n",
            "[0.454942911863327, 0.8499999880790711]\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_16 (Dense)             (None, 10)                30        \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 20)                220       \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 3)                 63        \n",
            "=================================================================\n",
            "Total params: 1,573\n",
            "Trainable params: 1,573\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1500/1500 [==============================] - 0s 237us/step - loss: 1.1017 - acc: 0.4147\n",
            "Epoch 2/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 1.0857 - acc: 0.4613\n",
            "Epoch 3/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 1.0721 - acc: 0.4727\n",
            "Epoch 4/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 1.0593 - acc: 0.5260\n",
            "Epoch 5/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 1.0465 - acc: 0.5647\n",
            "Epoch 6/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 1.0336 - acc: 0.5980\n",
            "Epoch 7/100\n",
            "1500/1500 [==============================] - 0s 48us/step - loss: 1.0202 - acc: 0.6380\n",
            "Epoch 8/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 1.0059 - acc: 0.7187\n",
            "Epoch 9/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.9902 - acc: 0.7767\n",
            "Epoch 10/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.9723 - acc: 0.8287\n",
            "Epoch 11/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.9519 - acc: 0.8433\n",
            "Epoch 12/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.9285 - acc: 0.8507\n",
            "Epoch 13/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.9024 - acc: 0.8520\n",
            "Epoch 14/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.8734 - acc: 0.8640\n",
            "Epoch 15/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.8417 - acc: 0.8700\n",
            "Epoch 16/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.8076 - acc: 0.8720\n",
            "Epoch 17/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.7710 - acc: 0.8753\n",
            "Epoch 18/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.7321 - acc: 0.8753\n",
            "Epoch 19/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.6911 - acc: 0.8673\n",
            "Epoch 20/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.6489 - acc: 0.8653\n",
            "Epoch 21/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.6073 - acc: 0.8667\n",
            "Epoch 22/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.5679 - acc: 0.8667\n",
            "Epoch 23/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.5310 - acc: 0.8680\n",
            "Epoch 24/100\n",
            "1500/1500 [==============================] - 0s 37us/step - loss: 0.4977 - acc: 0.8653\n",
            "Epoch 25/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.4677 - acc: 0.8673\n",
            "Epoch 26/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.4414 - acc: 0.8720\n",
            "Epoch 27/100\n",
            "1500/1500 [==============================] - 0s 42us/step - loss: 0.4184 - acc: 0.8740\n",
            "Epoch 28/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.3986 - acc: 0.8767\n",
            "Epoch 29/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.3813 - acc: 0.8807\n",
            "Epoch 30/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.3665 - acc: 0.8807\n",
            "Epoch 31/100\n",
            "1500/1500 [==============================] - 0s 40us/step - loss: 0.3541 - acc: 0.8800\n",
            "Epoch 32/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.3434 - acc: 0.8807\n",
            "Epoch 33/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.3348 - acc: 0.8807\n",
            "Epoch 34/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.3275 - acc: 0.8793\n",
            "Epoch 35/100\n",
            "1500/1500 [==============================] - 0s 39us/step - loss: 0.3221 - acc: 0.8800\n",
            "Epoch 36/100\n",
            "1500/1500 [==============================] - 0s 37us/step - loss: 0.3170 - acc: 0.8807\n",
            "Epoch 37/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.3133 - acc: 0.8813\n",
            "Epoch 38/100\n",
            "1500/1500 [==============================] - 0s 32us/step - loss: 0.3097 - acc: 0.8800\n",
            "Epoch 39/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.3070 - acc: 0.8813\n",
            "Epoch 40/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.3046 - acc: 0.8807\n",
            "Epoch 41/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.3029 - acc: 0.8800\n",
            "Epoch 42/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.3011 - acc: 0.8793\n",
            "Epoch 43/100\n",
            "1500/1500 [==============================] - 0s 37us/step - loss: 0.2996 - acc: 0.8793\n",
            "Epoch 44/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.2985 - acc: 0.8800\n",
            "Epoch 45/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.2977 - acc: 0.8787\n",
            "Epoch 46/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.2968 - acc: 0.8787\n",
            "Epoch 47/100\n",
            "1500/1500 [==============================] - 0s 32us/step - loss: 0.2960 - acc: 0.8787\n",
            "Epoch 48/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2952 - acc: 0.8793\n",
            "Epoch 49/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.2946 - acc: 0.8787\n",
            "Epoch 50/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2939 - acc: 0.8793\n",
            "Epoch 51/100\n",
            "1500/1500 [==============================] - 0s 37us/step - loss: 0.2932 - acc: 0.8780\n",
            "Epoch 52/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.2931 - acc: 0.8780\n",
            "Epoch 53/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2928 - acc: 0.8820\n",
            "Epoch 54/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2925 - acc: 0.8793\n",
            "Epoch 55/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.2919 - acc: 0.8787\n",
            "Epoch 56/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2916 - acc: 0.8793\n",
            "Epoch 57/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.2912 - acc: 0.8800\n",
            "Epoch 58/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.2910 - acc: 0.8813\n",
            "Epoch 59/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.2909 - acc: 0.8800\n",
            "Epoch 60/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.2901 - acc: 0.8793\n",
            "Epoch 61/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.2902 - acc: 0.8767\n",
            "Epoch 62/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.2900 - acc: 0.8827\n",
            "Epoch 63/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.2898 - acc: 0.8807\n",
            "Epoch 64/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.2899 - acc: 0.8780\n",
            "Epoch 65/100\n",
            "1500/1500 [==============================] - 0s 43us/step - loss: 0.2890 - acc: 0.8780\n",
            "Epoch 66/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2893 - acc: 0.8800\n",
            "Epoch 67/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2886 - acc: 0.8833\n",
            "Epoch 68/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.2887 - acc: 0.8793\n",
            "Epoch 69/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.2881 - acc: 0.8787\n",
            "Epoch 70/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.2879 - acc: 0.8807\n",
            "Epoch 71/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2883 - acc: 0.8833\n",
            "Epoch 72/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.2879 - acc: 0.8840\n",
            "Epoch 73/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.2881 - acc: 0.8813\n",
            "Epoch 74/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.2879 - acc: 0.8813\n",
            "Epoch 75/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2876 - acc: 0.8793\n",
            "Epoch 76/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.2871 - acc: 0.8807\n",
            "Epoch 77/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.2873 - acc: 0.8787\n",
            "Epoch 78/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.2870 - acc: 0.8807\n",
            "Epoch 79/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2867 - acc: 0.8807\n",
            "Epoch 80/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.2868 - acc: 0.8880\n",
            "Epoch 81/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.2867 - acc: 0.8820\n",
            "Epoch 82/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2865 - acc: 0.8827\n",
            "Epoch 83/100\n",
            "1500/1500 [==============================] - 0s 37us/step - loss: 0.2864 - acc: 0.8840\n",
            "Epoch 84/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.2863 - acc: 0.8840\n",
            "Epoch 85/100\n",
            "1500/1500 [==============================] - 0s 39us/step - loss: 0.2862 - acc: 0.8800\n",
            "Epoch 86/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.2864 - acc: 0.8787\n",
            "Epoch 87/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.2859 - acc: 0.8800\n",
            "Epoch 88/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.2861 - acc: 0.8813\n",
            "Epoch 89/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.2855 - acc: 0.8833\n",
            "Epoch 90/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.2855 - acc: 0.8860\n",
            "Epoch 91/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2858 - acc: 0.8820\n",
            "Epoch 92/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2856 - acc: 0.8820\n",
            "Epoch 93/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.2859 - acc: 0.8833\n",
            "Epoch 94/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2851 - acc: 0.8847\n",
            "Epoch 95/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.2851 - acc: 0.8847\n",
            "Epoch 96/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.2849 - acc: 0.8860\n",
            "Epoch 97/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2847 - acc: 0.8827\n",
            "Epoch 98/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2848 - acc: 0.8827\n",
            "Epoch 99/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.2847 - acc: 0.8853\n",
            "Epoch 100/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.2848 - acc: 0.8847\n",
            "60/60 [==============================] - 0s 2ms/step\n",
            "\n",
            "acc: 78.33%\n",
            "[[15  4  4]\n",
            " [ 1 16  1]\n",
            " [ 3  0 16]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.65      0.71        23\n",
            "           1       0.80      0.89      0.84        18\n",
            "           2       0.76      0.84      0.80        19\n",
            "\n",
            "    accuracy                           0.78        60\n",
            "   macro avg       0.78      0.79      0.79        60\n",
            "weighted avg       0.78      0.78      0.78        60\n",
            "\n",
            "[0.452211058139801, 0.7833333253860474]\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_22 (Dense)             (None, 10)                30        \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 20)                220       \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 3)                 63        \n",
            "=================================================================\n",
            "Total params: 1,993\n",
            "Trainable params: 1,993\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1500/1500 [==============================] - 0s 273us/step - loss: 1.0929 - acc: 0.3640\n",
            "Epoch 2/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 1.0862 - acc: 0.5133\n",
            "Epoch 3/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 1.0798 - acc: 0.5380\n",
            "Epoch 4/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 1.0724 - acc: 0.5920\n",
            "Epoch 5/100\n",
            "1500/1500 [==============================] - 0s 40us/step - loss: 1.0647 - acc: 0.6327\n",
            "Epoch 6/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 1.0571 - acc: 0.7173\n",
            "Epoch 7/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 1.0497 - acc: 0.7933\n",
            "Epoch 8/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 1.0421 - acc: 0.8047\n",
            "Epoch 9/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 1.0342 - acc: 0.8007\n",
            "Epoch 10/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 1.0257 - acc: 0.8000\n",
            "Epoch 11/100\n",
            "1500/1500 [==============================] - 0s 37us/step - loss: 1.0165 - acc: 0.8040\n",
            "Epoch 12/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 1.0065 - acc: 0.8067\n",
            "Epoch 13/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.9953 - acc: 0.8100\n",
            "Epoch 14/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.9829 - acc: 0.8093\n",
            "Epoch 15/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.9696 - acc: 0.8133\n",
            "Epoch 16/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.9553 - acc: 0.8153\n",
            "Epoch 17/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 0.9397 - acc: 0.8200\n",
            "Epoch 18/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.9231 - acc: 0.8253\n",
            "Epoch 19/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.9052 - acc: 0.8313\n",
            "Epoch 20/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.8861 - acc: 0.8360\n",
            "Epoch 21/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.8656 - acc: 0.8460\n",
            "Epoch 22/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.8440 - acc: 0.8500\n",
            "Epoch 23/100\n",
            "1500/1500 [==============================] - 0s 46us/step - loss: 0.8210 - acc: 0.8520\n",
            "Epoch 24/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.7969 - acc: 0.8527\n",
            "Epoch 25/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.7713 - acc: 0.8553\n",
            "Epoch 26/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.7442 - acc: 0.8600\n",
            "Epoch 27/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.7153 - acc: 0.8667\n",
            "Epoch 28/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.6849 - acc: 0.8673\n",
            "Epoch 29/100\n",
            "1500/1500 [==============================] - 0s 39us/step - loss: 0.6525 - acc: 0.8713\n",
            "Epoch 30/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.6190 - acc: 0.8740\n",
            "Epoch 31/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.5845 - acc: 0.8760\n",
            "Epoch 32/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.5500 - acc: 0.8787\n",
            "Epoch 33/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.5162 - acc: 0.8793\n",
            "Epoch 34/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.4843 - acc: 0.8820\n",
            "Epoch 35/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.4548 - acc: 0.8867\n",
            "Epoch 36/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.4280 - acc: 0.8887\n",
            "Epoch 37/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.4046 - acc: 0.8887\n",
            "Epoch 38/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.3848 - acc: 0.8920\n",
            "Epoch 39/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.3678 - acc: 0.8913\n",
            "Epoch 40/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.3530 - acc: 0.8947\n",
            "Epoch 41/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.3412 - acc: 0.8947\n",
            "Epoch 42/100\n",
            "1500/1500 [==============================] - 0s 49us/step - loss: 0.3310 - acc: 0.8973\n",
            "Epoch 43/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.3226 - acc: 0.8973\n",
            "Epoch 44/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.3153 - acc: 0.8980\n",
            "Epoch 45/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.3094 - acc: 0.8987\n",
            "Epoch 46/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.3041 - acc: 0.8987\n",
            "Epoch 47/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.2995 - acc: 0.8993\n",
            "Epoch 48/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.2954 - acc: 0.8987\n",
            "Epoch 49/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.2928 - acc: 0.9007\n",
            "Epoch 50/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.2898 - acc: 0.8987\n",
            "Epoch 51/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.2870 - acc: 0.8973\n",
            "Epoch 52/100\n",
            "1500/1500 [==============================] - 0s 42us/step - loss: 0.2851 - acc: 0.9000\n",
            "Epoch 53/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.2830 - acc: 0.8993\n",
            "Epoch 54/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2814 - acc: 0.8973\n",
            "Epoch 55/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2798 - acc: 0.8987\n",
            "Epoch 56/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.2790 - acc: 0.8973\n",
            "Epoch 57/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.2775 - acc: 0.8987\n",
            "Epoch 58/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2769 - acc: 0.8980\n",
            "Epoch 59/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2753 - acc: 0.8973\n",
            "Epoch 60/100\n",
            "1500/1500 [==============================] - 0s 40us/step - loss: 0.2747 - acc: 0.9000\n",
            "Epoch 61/100\n",
            "1500/1500 [==============================] - 0s 37us/step - loss: 0.2740 - acc: 0.8973\n",
            "Epoch 62/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2733 - acc: 0.8967\n",
            "Epoch 63/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.2723 - acc: 0.9007\n",
            "Epoch 64/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2721 - acc: 0.8987\n",
            "Epoch 65/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.2717 - acc: 0.9013\n",
            "Epoch 66/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2708 - acc: 0.8987\n",
            "Epoch 67/100\n",
            "1500/1500 [==============================] - 0s 37us/step - loss: 0.2703 - acc: 0.8993\n",
            "Epoch 68/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2701 - acc: 0.8973\n",
            "Epoch 69/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2698 - acc: 0.8973\n",
            "Epoch 70/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.2699 - acc: 0.8973\n",
            "Epoch 71/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2688 - acc: 0.8980\n",
            "Epoch 72/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2685 - acc: 0.8947\n",
            "Epoch 73/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.2685 - acc: 0.8967\n",
            "Epoch 74/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.2676 - acc: 0.8967\n",
            "Epoch 75/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.2673 - acc: 0.8973\n",
            "Epoch 76/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.2678 - acc: 0.8980\n",
            "Epoch 77/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.2670 - acc: 0.8973\n",
            "Epoch 78/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2666 - acc: 0.8960\n",
            "Epoch 79/100\n",
            "1500/1500 [==============================] - 0s 40us/step - loss: 0.2671 - acc: 0.8967\n",
            "Epoch 80/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.2661 - acc: 0.8973\n",
            "Epoch 81/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2667 - acc: 0.8953\n",
            "Epoch 82/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2661 - acc: 0.8960\n",
            "Epoch 83/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2660 - acc: 0.8967\n",
            "Epoch 84/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.2652 - acc: 0.8953\n",
            "Epoch 85/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2659 - acc: 0.8953\n",
            "Epoch 86/100\n",
            "1500/1500 [==============================] - 0s 39us/step - loss: 0.2651 - acc: 0.8960\n",
            "Epoch 87/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2652 - acc: 0.8960\n",
            "Epoch 88/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2654 - acc: 0.8967\n",
            "Epoch 89/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2651 - acc: 0.8960\n",
            "Epoch 90/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2649 - acc: 0.8960\n",
            "Epoch 91/100\n",
            "1500/1500 [==============================] - 0s 33us/step - loss: 0.2647 - acc: 0.8960\n",
            "Epoch 92/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2649 - acc: 0.8953\n",
            "Epoch 93/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2645 - acc: 0.8960\n",
            "Epoch 94/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.2636 - acc: 0.8947\n",
            "Epoch 95/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2642 - acc: 0.8973\n",
            "Epoch 96/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2637 - acc: 0.8960\n",
            "Epoch 97/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.2643 - acc: 0.8980\n",
            "Epoch 98/100\n",
            "1500/1500 [==============================] - 0s 39us/step - loss: 0.2646 - acc: 0.8967\n",
            "Epoch 99/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.2642 - acc: 0.8960\n",
            "Epoch 100/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2637 - acc: 0.8960\n",
            "60/60 [==============================] - 0s 2ms/step\n",
            "\n",
            "acc: 86.67%\n",
            "[[13  0  1]\n",
            " [ 4 22  0]\n",
            " [ 3  0 17]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.93      0.76        14\n",
            "           1       1.00      0.85      0.92        26\n",
            "           2       0.94      0.85      0.89        20\n",
            "\n",
            "    accuracy                           0.87        60\n",
            "   macro avg       0.86      0.87      0.86        60\n",
            "weighted avg       0.90      0.87      0.87        60\n",
            "\n",
            "[0.2754902223745982, 0.8666666626930237]\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_29 (Dense)             (None, 10)                30        \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 20)                220       \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 3)                 63        \n",
            "=================================================================\n",
            "Total params: 2,413\n",
            "Trainable params: 2,413\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1500/1500 [==============================] - 0s 320us/step - loss: 1.0502 - acc: 0.5967\n",
            "Epoch 2/100\n",
            "1500/1500 [==============================] - 0s 37us/step - loss: 1.0296 - acc: 0.6140\n",
            "Epoch 3/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 1.0075 - acc: 0.6427\n",
            "Epoch 4/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.9827 - acc: 0.6767\n",
            "Epoch 5/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.9550 - acc: 0.7067\n",
            "Epoch 6/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.9240 - acc: 0.7347\n",
            "Epoch 7/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.8904 - acc: 0.7747\n",
            "Epoch 8/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.8555 - acc: 0.8000\n",
            "Epoch 9/100\n",
            "1500/1500 [==============================] - 0s 42us/step - loss: 0.8218 - acc: 0.8173\n",
            "Epoch 10/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.7908 - acc: 0.8360\n",
            "Epoch 11/100\n",
            "1500/1500 [==============================] - 0s 45us/step - loss: 0.7623 - acc: 0.8527\n",
            "Epoch 12/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.7355 - acc: 0.8560\n",
            "Epoch 13/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.7101 - acc: 0.8613\n",
            "Epoch 14/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.6852 - acc: 0.8693\n",
            "Epoch 15/100\n",
            "1500/1500 [==============================] - 0s 37us/step - loss: 0.6607 - acc: 0.8740\n",
            "Epoch 16/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.6362 - acc: 0.8747\n",
            "Epoch 17/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.6114 - acc: 0.8773\n",
            "Epoch 18/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.5873 - acc: 0.8800\n",
            "Epoch 19/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.5639 - acc: 0.8820\n",
            "Epoch 20/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 0.5417 - acc: 0.8820\n",
            "Epoch 21/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.5207 - acc: 0.8820\n",
            "Epoch 22/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.5012 - acc: 0.8860\n",
            "Epoch 23/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.4834 - acc: 0.8887\n",
            "Epoch 24/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.4672 - acc: 0.8907\n",
            "Epoch 25/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.4531 - acc: 0.8893\n",
            "Epoch 26/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.4397 - acc: 0.8900\n",
            "Epoch 27/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.4277 - acc: 0.8900\n",
            "Epoch 28/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.4176 - acc: 0.8913\n",
            "Epoch 29/100\n",
            "1500/1500 [==============================] - 0s 47us/step - loss: 0.4074 - acc: 0.8920\n",
            "Epoch 30/100\n",
            "1500/1500 [==============================] - 0s 37us/step - loss: 0.3982 - acc: 0.8933\n",
            "Epoch 31/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.3900 - acc: 0.8947\n",
            "Epoch 32/100\n",
            "1500/1500 [==============================] - 0s 37us/step - loss: 0.3823 - acc: 0.8940\n",
            "Epoch 33/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.3756 - acc: 0.8940\n",
            "Epoch 34/100\n",
            "1500/1500 [==============================] - 0s 39us/step - loss: 0.3691 - acc: 0.8913\n",
            "Epoch 35/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.3635 - acc: 0.8927\n",
            "Epoch 36/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.3581 - acc: 0.8920\n",
            "Epoch 37/100\n",
            "1500/1500 [==============================] - 0s 37us/step - loss: 0.3531 - acc: 0.8933\n",
            "Epoch 38/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.3487 - acc: 0.8920\n",
            "Epoch 39/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.3449 - acc: 0.8927\n",
            "Epoch 40/100\n",
            "1500/1500 [==============================] - 0s 37us/step - loss: 0.3405 - acc: 0.8940\n",
            "Epoch 41/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.3378 - acc: 0.8933\n",
            "Epoch 42/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.3333 - acc: 0.8927\n",
            "Epoch 43/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.3307 - acc: 0.8920\n",
            "Epoch 44/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.3276 - acc: 0.8900\n",
            "Epoch 45/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.3256 - acc: 0.8920\n",
            "Epoch 46/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.3230 - acc: 0.8933\n",
            "Epoch 47/100\n",
            "1500/1500 [==============================] - 0s 48us/step - loss: 0.3201 - acc: 0.8927\n",
            "Epoch 48/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.3184 - acc: 0.8907\n",
            "Epoch 49/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.3167 - acc: 0.8907\n",
            "Epoch 50/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.3133 - acc: 0.8933\n",
            "Epoch 51/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.3118 - acc: 0.8960\n",
            "Epoch 52/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.3110 - acc: 0.8907\n",
            "Epoch 53/100\n",
            "1500/1500 [==============================] - 0s 42us/step - loss: 0.3082 - acc: 0.8940\n",
            "Epoch 54/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.3067 - acc: 0.8940\n",
            "Epoch 55/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.3059 - acc: 0.8960\n",
            "Epoch 56/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.3042 - acc: 0.8947\n",
            "Epoch 57/100\n",
            "1500/1500 [==============================] - 0s 37us/step - loss: 0.3025 - acc: 0.8933\n",
            "Epoch 58/100\n",
            "1500/1500 [==============================] - 0s 40us/step - loss: 0.3021 - acc: 0.8933\n",
            "Epoch 59/100\n",
            "1500/1500 [==============================] - 0s 39us/step - loss: 0.3001 - acc: 0.8953\n",
            "Epoch 60/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.2989 - acc: 0.8920\n",
            "Epoch 61/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.2976 - acc: 0.8940\n",
            "Epoch 62/100\n",
            "1500/1500 [==============================] - 0s 37us/step - loss: 0.2973 - acc: 0.8940\n",
            "Epoch 63/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.2957 - acc: 0.8947\n",
            "Epoch 64/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.2949 - acc: 0.8947\n",
            "Epoch 65/100\n",
            "1500/1500 [==============================] - 0s 47us/step - loss: 0.2941 - acc: 0.8947\n",
            "Epoch 66/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.2927 - acc: 0.8953\n",
            "Epoch 67/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.2939 - acc: 0.8953\n",
            "Epoch 68/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.2917 - acc: 0.8960\n",
            "Epoch 69/100\n",
            "1500/1500 [==============================] - 0s 37us/step - loss: 0.2909 - acc: 0.8960\n",
            "Epoch 70/100\n",
            "1500/1500 [==============================] - 0s 37us/step - loss: 0.2907 - acc: 0.8947\n",
            "Epoch 71/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.2890 - acc: 0.8953\n",
            "Epoch 72/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.2880 - acc: 0.8940\n",
            "Epoch 73/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.2878 - acc: 0.8960\n",
            "Epoch 74/100\n",
            "1500/1500 [==============================] - 0s 37us/step - loss: 0.2880 - acc: 0.8947\n",
            "Epoch 75/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.2871 - acc: 0.8953\n",
            "Epoch 76/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.2859 - acc: 0.8967\n",
            "Epoch 77/100\n",
            "1500/1500 [==============================] - 0s 39us/step - loss: 0.2860 - acc: 0.8980\n",
            "Epoch 78/100\n",
            "1500/1500 [==============================] - 0s 37us/step - loss: 0.2858 - acc: 0.8967\n",
            "Epoch 79/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.2842 - acc: 0.8953\n",
            "Epoch 80/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.2840 - acc: 0.8973\n",
            "Epoch 81/100\n",
            "1500/1500 [==============================] - 0s 37us/step - loss: 0.2840 - acc: 0.8973\n",
            "Epoch 82/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.2830 - acc: 0.8940\n",
            "Epoch 83/100\n",
            "1500/1500 [==============================] - 0s 48us/step - loss: 0.2832 - acc: 0.8967\n",
            "Epoch 84/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.2832 - acc: 0.8967\n",
            "Epoch 85/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.2818 - acc: 0.8947\n",
            "Epoch 86/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.2830 - acc: 0.8973\n",
            "Epoch 87/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.2804 - acc: 0.8980\n",
            "Epoch 88/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.2804 - acc: 0.8940\n",
            "Epoch 89/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.2799 - acc: 0.8960\n",
            "Epoch 90/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.2801 - acc: 0.8947\n",
            "Epoch 91/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.2794 - acc: 0.8953\n",
            "Epoch 92/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.2810 - acc: 0.8973\n",
            "Epoch 93/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.2782 - acc: 0.8960\n",
            "Epoch 94/100\n",
            "1500/1500 [==============================] - 0s 34us/step - loss: 0.2791 - acc: 0.8960\n",
            "Epoch 95/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.2774 - acc: 0.8980\n",
            "Epoch 96/100\n",
            "1500/1500 [==============================] - 0s 39us/step - loss: 0.2780 - acc: 0.8947\n",
            "Epoch 97/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.2773 - acc: 0.8953\n",
            "Epoch 98/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.2767 - acc: 0.8960\n",
            "Epoch 99/100\n",
            "1500/1500 [==============================] - 0s 36us/step - loss: 0.2771 - acc: 0.8953\n",
            "Epoch 100/100\n",
            "1500/1500 [==============================] - 0s 35us/step - loss: 0.2781 - acc: 0.8953\n",
            "60/60 [==============================] - 0s 2ms/step\n",
            "\n",
            "acc: 86.67%\n",
            "[[19  0  2]\n",
            " [ 1 19  0]\n",
            " [ 5  0 14]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.90      0.83        21\n",
            "           1       1.00      0.95      0.97        20\n",
            "           2       0.88      0.74      0.80        19\n",
            "\n",
            "    accuracy                           0.87        60\n",
            "   macro avg       0.88      0.86      0.87        60\n",
            "weighted avg       0.88      0.87      0.87        60\n",
            "\n",
            "[0.3584769437710444, 0.8666666547457377]\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_37 (Dense)             (None, 10)                30        \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 20)                220       \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_42 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_45 (Dense)             (None, 3)                 63        \n",
            "=================================================================\n",
            "Total params: 2,833\n",
            "Trainable params: 2,833\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1500/1500 [==============================] - 1s 372us/step - loss: 1.0921 - acc: 0.4973\n",
            "Epoch 2/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 1.0877 - acc: 0.6613\n",
            "Epoch 3/100\n",
            "1500/1500 [==============================] - 0s 42us/step - loss: 1.0849 - acc: 0.6487\n",
            "Epoch 4/100\n",
            "1500/1500 [==============================] - 0s 39us/step - loss: 1.0825 - acc: 0.6807\n",
            "Epoch 5/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 1.0800 - acc: 0.6793\n",
            "Epoch 6/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 1.0772 - acc: 0.7073\n",
            "Epoch 7/100\n",
            "1500/1500 [==============================] - 0s 37us/step - loss: 1.0743 - acc: 0.7300\n",
            "Epoch 8/100\n",
            "1500/1500 [==============================] - 0s 43us/step - loss: 1.0711 - acc: 0.7093\n",
            "Epoch 9/100\n",
            "1500/1500 [==============================] - 0s 39us/step - loss: 1.0675 - acc: 0.7427\n",
            "Epoch 10/100\n",
            "1500/1500 [==============================] - 0s 37us/step - loss: 1.0635 - acc: 0.7340\n",
            "Epoch 11/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 1.0588 - acc: 0.7387\n",
            "Epoch 12/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 1.0520 - acc: 0.7587\n",
            "Epoch 13/100\n",
            "1500/1500 [==============================] - 0s 37us/step - loss: 1.0431 - acc: 0.7307\n",
            "Epoch 14/100\n",
            "1500/1500 [==============================] - 0s 48us/step - loss: 1.0341 - acc: 0.7327\n",
            "Epoch 15/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 1.0245 - acc: 0.7453\n",
            "Epoch 16/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 1.0140 - acc: 0.7493\n",
            "Epoch 17/100\n",
            "1500/1500 [==============================] - 0s 39us/step - loss: 1.0021 - acc: 0.7500\n",
            "Epoch 18/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.9884 - acc: 0.7627\n",
            "Epoch 19/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 0.9729 - acc: 0.7593\n",
            "Epoch 20/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.9557 - acc: 0.7607\n",
            "Epoch 21/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.9368 - acc: 0.7580\n",
            "Epoch 22/100\n",
            "1500/1500 [==============================] - 0s 37us/step - loss: 0.9161 - acc: 0.7520\n",
            "Epoch 23/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.8935 - acc: 0.7453\n",
            "Epoch 24/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.8687 - acc: 0.7460\n",
            "Epoch 25/100\n",
            "1500/1500 [==============================] - 0s 39us/step - loss: 0.8425 - acc: 0.7367\n",
            "Epoch 26/100\n",
            "1500/1500 [==============================] - 0s 39us/step - loss: 0.8154 - acc: 0.7340\n",
            "Epoch 27/100\n",
            "1500/1500 [==============================] - 0s 37us/step - loss: 0.7878 - acc: 0.7420\n",
            "Epoch 28/100\n",
            "1500/1500 [==============================] - 0s 39us/step - loss: 0.7602 - acc: 0.7393\n",
            "Epoch 29/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.7331 - acc: 0.7500\n",
            "Epoch 30/100\n",
            "1500/1500 [==============================] - 0s 43us/step - loss: 0.7065 - acc: 0.7487\n",
            "Epoch 31/100\n",
            "1500/1500 [==============================] - 0s 51us/step - loss: 0.6809 - acc: 0.7653\n",
            "Epoch 32/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.6565 - acc: 0.7767\n",
            "Epoch 33/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.6337 - acc: 0.7893\n",
            "Epoch 34/100\n",
            "1500/1500 [==============================] - 0s 39us/step - loss: 0.6119 - acc: 0.8040\n",
            "Epoch 35/100\n",
            "1500/1500 [==============================] - 0s 45us/step - loss: 0.5915 - acc: 0.8127\n",
            "Epoch 36/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.5721 - acc: 0.8267\n",
            "Epoch 37/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.5532 - acc: 0.8360\n",
            "Epoch 38/100\n",
            "1500/1500 [==============================] - 0s 37us/step - loss: 0.5358 - acc: 0.8413\n",
            "Epoch 39/100\n",
            "1500/1500 [==============================] - 0s 37us/step - loss: 0.5183 - acc: 0.8493\n",
            "Epoch 40/100\n",
            "1500/1500 [==============================] - 0s 37us/step - loss: 0.5019 - acc: 0.8540\n",
            "Epoch 41/100\n",
            "1500/1500 [==============================] - 0s 46us/step - loss: 0.4862 - acc: 0.8580\n",
            "Epoch 42/100\n",
            "1500/1500 [==============================] - 0s 37us/step - loss: 0.4719 - acc: 0.8607\n",
            "Epoch 43/100\n",
            "1500/1500 [==============================] - 0s 39us/step - loss: 0.4566 - acc: 0.8607\n",
            "Epoch 44/100\n",
            "1500/1500 [==============================] - 0s 40us/step - loss: 0.4422 - acc: 0.8653\n",
            "Epoch 45/100\n",
            "1500/1500 [==============================] - 0s 39us/step - loss: 0.4287 - acc: 0.8727\n",
            "Epoch 46/100\n",
            "1500/1500 [==============================] - 0s 39us/step - loss: 0.4168 - acc: 0.8760\n",
            "Epoch 47/100\n",
            "1500/1500 [==============================] - 0s 49us/step - loss: 0.4047 - acc: 0.8773\n",
            "Epoch 48/100\n",
            "1500/1500 [==============================] - 0s 41us/step - loss: 0.3933 - acc: 0.8780\n",
            "Epoch 49/100\n",
            "1500/1500 [==============================] - 0s 40us/step - loss: 0.3831 - acc: 0.8773\n",
            "Epoch 50/100\n",
            "1500/1500 [==============================] - 0s 39us/step - loss: 0.3735 - acc: 0.8800\n",
            "Epoch 51/100\n",
            "1500/1500 [==============================] - 0s 39us/step - loss: 0.3649 - acc: 0.8827\n",
            "Epoch 52/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.3562 - acc: 0.8847\n",
            "Epoch 53/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.3493 - acc: 0.8840\n",
            "Epoch 54/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.3424 - acc: 0.8820\n",
            "Epoch 55/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.3364 - acc: 0.8853\n",
            "Epoch 56/100\n",
            "1500/1500 [==============================] - 0s 37us/step - loss: 0.3316 - acc: 0.8873\n",
            "Epoch 57/100\n",
            "1500/1500 [==============================] - 0s 45us/step - loss: 0.3260 - acc: 0.8873\n",
            "Epoch 58/100\n",
            "1500/1500 [==============================] - 0s 37us/step - loss: 0.3211 - acc: 0.8887\n",
            "Epoch 59/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.3169 - acc: 0.8887\n",
            "Epoch 60/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.3147 - acc: 0.8893\n",
            "Epoch 61/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.3114 - acc: 0.8900\n",
            "Epoch 62/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.3080 - acc: 0.8907\n",
            "Epoch 63/100\n",
            "1500/1500 [==============================] - 0s 37us/step - loss: 0.3055 - acc: 0.8933\n",
            "Epoch 64/100\n",
            "1500/1500 [==============================] - 0s 40us/step - loss: 0.3035 - acc: 0.8933\n",
            "Epoch 65/100\n",
            "1500/1500 [==============================] - 0s 42us/step - loss: 0.3020 - acc: 0.8960\n",
            "Epoch 66/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.2982 - acc: 0.8927\n",
            "Epoch 67/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.2968 - acc: 0.8913\n",
            "Epoch 68/100\n",
            "1500/1500 [==============================] - 0s 37us/step - loss: 0.2963 - acc: 0.8900\n",
            "Epoch 69/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.2933 - acc: 0.8940\n",
            "Epoch 70/100\n",
            "1500/1500 [==============================] - 0s 39us/step - loss: 0.2935 - acc: 0.8940\n",
            "Epoch 71/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.2923 - acc: 0.8913\n",
            "Epoch 72/100\n",
            "1500/1500 [==============================] - 0s 37us/step - loss: 0.2905 - acc: 0.8953\n",
            "Epoch 73/100\n",
            "1500/1500 [==============================] - 0s 37us/step - loss: 0.2894 - acc: 0.8933\n",
            "Epoch 74/100\n",
            "1500/1500 [==============================] - 0s 37us/step - loss: 0.2882 - acc: 0.8960\n",
            "Epoch 75/100\n",
            "1500/1500 [==============================] - 0s 37us/step - loss: 0.2882 - acc: 0.8947\n",
            "Epoch 76/100\n",
            "1500/1500 [==============================] - 0s 37us/step - loss: 0.2878 - acc: 0.8933\n",
            "Epoch 77/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 0.2849 - acc: 0.8940\n",
            "Epoch 78/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.2853 - acc: 0.8953\n",
            "Epoch 79/100\n",
            "1500/1500 [==============================] - 0s 37us/step - loss: 0.2858 - acc: 0.8947\n",
            "Epoch 80/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.2851 - acc: 0.8947\n",
            "Epoch 81/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.2835 - acc: 0.8913\n",
            "Epoch 82/100\n",
            "1500/1500 [==============================] - 0s 46us/step - loss: 0.2833 - acc: 0.8913\n",
            "Epoch 83/100\n",
            "1500/1500 [==============================] - 0s 46us/step - loss: 0.2835 - acc: 0.8913\n",
            "Epoch 84/100\n",
            "1500/1500 [==============================] - 0s 40us/step - loss: 0.2850 - acc: 0.8940\n",
            "Epoch 85/100\n",
            "1500/1500 [==============================] - 0s 40us/step - loss: 0.2842 - acc: 0.8887\n",
            "Epoch 86/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.2826 - acc: 0.8947\n",
            "Epoch 87/100\n",
            "1500/1500 [==============================] - 0s 45us/step - loss: 0.2821 - acc: 0.8947\n",
            "Epoch 88/100\n",
            "1500/1500 [==============================] - 0s 37us/step - loss: 0.2811 - acc: 0.8927\n",
            "Epoch 89/100\n",
            "1500/1500 [==============================] - 0s 39us/step - loss: 0.2802 - acc: 0.8953\n",
            "Epoch 90/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.2823 - acc: 0.8947\n",
            "Epoch 91/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.2805 - acc: 0.8953\n",
            "Epoch 92/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.2798 - acc: 0.8933\n",
            "Epoch 93/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.2815 - acc: 0.8907\n",
            "Epoch 94/100\n",
            "1500/1500 [==============================] - 0s 39us/step - loss: 0.2798 - acc: 0.8927\n",
            "Epoch 95/100\n",
            "1500/1500 [==============================] - 0s 40us/step - loss: 0.2805 - acc: 0.8940\n",
            "Epoch 96/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.2784 - acc: 0.8953\n",
            "Epoch 97/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.2793 - acc: 0.8920\n",
            "Epoch 98/100\n",
            "1500/1500 [==============================] - 0s 39us/step - loss: 0.2797 - acc: 0.8927\n",
            "Epoch 99/100\n",
            "1500/1500 [==============================] - 0s 47us/step - loss: 0.2798 - acc: 0.8927\n",
            "Epoch 100/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.2778 - acc: 0.8913\n",
            "60/60 [==============================] - 0s 3ms/step\n",
            "\n",
            "acc: 85.00%\n",
            "[[16  1  3]\n",
            " [ 1 16  0]\n",
            " [ 3  1 19]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.80      0.80        20\n",
            "           1       0.89      0.94      0.91        17\n",
            "           2       0.86      0.83      0.84        23\n",
            "\n",
            "    accuracy                           0.85        60\n",
            "   macro avg       0.85      0.86      0.85        60\n",
            "weighted avg       0.85      0.85      0.85        60\n",
            "\n",
            "[0.3134122351805369, 0.849999992052714]\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_46 (Dense)             (None, 10)                30        \n",
            "_________________________________________________________________\n",
            "dense_47 (Dense)             (None, 20)                220       \n",
            "_________________________________________________________________\n",
            "dense_48 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_49 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_50 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_51 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_52 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_53 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_54 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_55 (Dense)             (None, 3)                 63        \n",
            "=================================================================\n",
            "Total params: 3,253\n",
            "Trainable params: 3,253\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1500/1500 [==============================] - 1s 551us/step - loss: 1.0870 - acc: 0.3613\n",
            "Epoch 2/100\n",
            "1500/1500 [==============================] - 0s 42us/step - loss: 1.0837 - acc: 0.5247\n",
            "Epoch 3/100\n",
            "1500/1500 [==============================] - 0s 39us/step - loss: 1.0802 - acc: 0.6487\n",
            "Epoch 4/100\n",
            "1500/1500 [==============================] - 0s 39us/step - loss: 1.0769 - acc: 0.6300\n",
            "Epoch 5/100\n",
            "1500/1500 [==============================] - 0s 53us/step - loss: 1.0735 - acc: 0.6373\n",
            "Epoch 6/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 1.0699 - acc: 0.6013\n",
            "Epoch 7/100\n",
            "1500/1500 [==============================] - 0s 50us/step - loss: 1.0658 - acc: 0.5433\n",
            "Epoch 8/100\n",
            "1500/1500 [==============================] - 0s 40us/step - loss: 1.0612 - acc: 0.5467\n",
            "Epoch 9/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 1.0559 - acc: 0.5427\n",
            "Epoch 10/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 1.0490 - acc: 0.5607\n",
            "Epoch 11/100\n",
            "1500/1500 [==============================] - 0s 42us/step - loss: 1.0397 - acc: 0.7073\n",
            "Epoch 12/100\n",
            "1500/1500 [==============================] - 0s 45us/step - loss: 1.0289 - acc: 0.7267\n",
            "Epoch 13/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 1.0165 - acc: 0.7193\n",
            "Epoch 14/100\n",
            "1500/1500 [==============================] - 0s 45us/step - loss: 1.0014 - acc: 0.7073\n",
            "Epoch 15/100\n",
            "1500/1500 [==============================] - 0s 41us/step - loss: 0.9835 - acc: 0.6980\n",
            "Epoch 16/100\n",
            "1500/1500 [==============================] - 0s 41us/step - loss: 0.9623 - acc: 0.6913\n",
            "Epoch 17/100\n",
            "1500/1500 [==============================] - 0s 45us/step - loss: 0.9380 - acc: 0.6813\n",
            "Epoch 18/100\n",
            "1500/1500 [==============================] - 0s 43us/step - loss: 0.9115 - acc: 0.6887\n",
            "Epoch 19/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 0.8838 - acc: 0.6820\n",
            "Epoch 20/100\n",
            "1500/1500 [==============================] - 0s 43us/step - loss: 0.8570 - acc: 0.6740\n",
            "Epoch 21/100\n",
            "1500/1500 [==============================] - 0s 46us/step - loss: 0.8322 - acc: 0.6847\n",
            "Epoch 22/100\n",
            "1500/1500 [==============================] - 0s 46us/step - loss: 0.8101 - acc: 0.7013\n",
            "Epoch 23/100\n",
            "1500/1500 [==============================] - 0s 40us/step - loss: 0.7906 - acc: 0.7053\n",
            "Epoch 24/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 0.7734 - acc: 0.7133\n",
            "Epoch 25/100\n",
            "1500/1500 [==============================] - 0s 41us/step - loss: 0.7576 - acc: 0.7300\n",
            "Epoch 26/100\n",
            "1500/1500 [==============================] - 0s 42us/step - loss: 0.7427 - acc: 0.7640\n",
            "Epoch 27/100\n",
            "1500/1500 [==============================] - 0s 39us/step - loss: 0.7285 - acc: 0.7860\n",
            "Epoch 28/100\n",
            "1500/1500 [==============================] - 0s 42us/step - loss: 0.7145 - acc: 0.8040\n",
            "Epoch 29/100\n",
            "1500/1500 [==============================] - 0s 43us/step - loss: 0.7007 - acc: 0.8140\n",
            "Epoch 30/100\n",
            "1500/1500 [==============================] - 0s 45us/step - loss: 0.6871 - acc: 0.8227\n",
            "Epoch 31/100\n",
            "1500/1500 [==============================] - 0s 42us/step - loss: 0.6738 - acc: 0.8273\n",
            "Epoch 32/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 0.6607 - acc: 0.8307\n",
            "Epoch 33/100\n",
            "1500/1500 [==============================] - 0s 49us/step - loss: 0.6482 - acc: 0.8387\n",
            "Epoch 34/100\n",
            "1500/1500 [==============================] - 0s 40us/step - loss: 0.6353 - acc: 0.8393\n",
            "Epoch 35/100\n",
            "1500/1500 [==============================] - 0s 41us/step - loss: 0.6223 - acc: 0.8447\n",
            "Epoch 36/100\n",
            "1500/1500 [==============================] - 0s 52us/step - loss: 0.6095 - acc: 0.8460\n",
            "Epoch 37/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 0.5965 - acc: 0.8500\n",
            "Epoch 38/100\n",
            "1500/1500 [==============================] - 0s 45us/step - loss: 0.5837 - acc: 0.8533\n",
            "Epoch 39/100\n",
            "1500/1500 [==============================] - 0s 39us/step - loss: 0.5713 - acc: 0.8547\n",
            "Epoch 40/100\n",
            "1500/1500 [==============================] - 0s 43us/step - loss: 0.5590 - acc: 0.8547\n",
            "Epoch 41/100\n",
            "1500/1500 [==============================] - 0s 43us/step - loss: 0.5471 - acc: 0.8573\n",
            "Epoch 42/100\n",
            "1500/1500 [==============================] - 0s 43us/step - loss: 0.5359 - acc: 0.8607\n",
            "Epoch 43/100\n",
            "1500/1500 [==============================] - 0s 42us/step - loss: 0.5247 - acc: 0.8600\n",
            "Epoch 44/100\n",
            "1500/1500 [==============================] - 0s 48us/step - loss: 0.5140 - acc: 0.8593\n",
            "Epoch 45/100\n",
            "1500/1500 [==============================] - 0s 40us/step - loss: 0.5041 - acc: 0.8613\n",
            "Epoch 46/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 0.4939 - acc: 0.8573\n",
            "Epoch 47/100\n",
            "1500/1500 [==============================] - 0s 40us/step - loss: 0.4846 - acc: 0.8593\n",
            "Epoch 48/100\n",
            "1500/1500 [==============================] - 0s 40us/step - loss: 0.4760 - acc: 0.8613\n",
            "Epoch 49/100\n",
            "1500/1500 [==============================] - 0s 45us/step - loss: 0.4675 - acc: 0.8593\n",
            "Epoch 50/100\n",
            "1500/1500 [==============================] - 0s 43us/step - loss: 0.4597 - acc: 0.8607\n",
            "Epoch 51/100\n",
            "1500/1500 [==============================] - 0s 40us/step - loss: 0.4525 - acc: 0.8607\n",
            "Epoch 52/100\n",
            "1500/1500 [==============================] - 0s 52us/step - loss: 0.4454 - acc: 0.8613\n",
            "Epoch 53/100\n",
            "1500/1500 [==============================] - 0s 43us/step - loss: 0.4393 - acc: 0.8580\n",
            "Epoch 54/100\n",
            "1500/1500 [==============================] - 0s 45us/step - loss: 0.4328 - acc: 0.8613\n",
            "Epoch 55/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 0.4275 - acc: 0.8633\n",
            "Epoch 56/100\n",
            "1500/1500 [==============================] - 0s 41us/step - loss: 0.4219 - acc: 0.8640\n",
            "Epoch 57/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 0.4172 - acc: 0.8620\n",
            "Epoch 58/100\n",
            "1500/1500 [==============================] - 0s 40us/step - loss: 0.4128 - acc: 0.8647\n",
            "Epoch 59/100\n",
            "1500/1500 [==============================] - 0s 47us/step - loss: 0.4080 - acc: 0.8680\n",
            "Epoch 60/100\n",
            "1500/1500 [==============================] - 0s 45us/step - loss: 0.4041 - acc: 0.8687\n",
            "Epoch 61/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 0.4003 - acc: 0.8667\n",
            "Epoch 62/100\n",
            "1500/1500 [==============================] - 0s 40us/step - loss: 0.3970 - acc: 0.8700\n",
            "Epoch 63/100\n",
            "1500/1500 [==============================] - 0s 43us/step - loss: 0.3937 - acc: 0.8673\n",
            "Epoch 64/100\n",
            "1500/1500 [==============================] - 0s 43us/step - loss: 0.3911 - acc: 0.8693\n",
            "Epoch 65/100\n",
            "1500/1500 [==============================] - 0s 48us/step - loss: 0.3869 - acc: 0.8680\n",
            "Epoch 66/100\n",
            "1500/1500 [==============================] - 0s 40us/step - loss: 0.3843 - acc: 0.8680\n",
            "Epoch 67/100\n",
            "1500/1500 [==============================] - 0s 52us/step - loss: 0.3808 - acc: 0.8693\n",
            "Epoch 68/100\n",
            "1500/1500 [==============================] - 0s 47us/step - loss: 0.3793 - acc: 0.8727\n",
            "Epoch 69/100\n",
            "1500/1500 [==============================] - 0s 39us/step - loss: 0.3772 - acc: 0.8707\n",
            "Epoch 70/100\n",
            "1500/1500 [==============================] - 0s 40us/step - loss: 0.3751 - acc: 0.8720\n",
            "Epoch 71/100\n",
            "1500/1500 [==============================] - 0s 43us/step - loss: 0.3726 - acc: 0.8713\n",
            "Epoch 72/100\n",
            "1500/1500 [==============================] - 0s 41us/step - loss: 0.3711 - acc: 0.8707\n",
            "Epoch 73/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 0.3695 - acc: 0.8720\n",
            "Epoch 74/100\n",
            "1500/1500 [==============================] - 0s 40us/step - loss: 0.3673 - acc: 0.8727\n",
            "Epoch 75/100\n",
            "1500/1500 [==============================] - 0s 40us/step - loss: 0.3661 - acc: 0.8713\n",
            "Epoch 76/100\n",
            "1500/1500 [==============================] - 0s 40us/step - loss: 0.3632 - acc: 0.8720\n",
            "Epoch 77/100\n",
            "1500/1500 [==============================] - 0s 45us/step - loss: 0.3622 - acc: 0.8747\n",
            "Epoch 78/100\n",
            "1500/1500 [==============================] - 0s 42us/step - loss: 0.3613 - acc: 0.8700\n",
            "Epoch 79/100\n",
            "1500/1500 [==============================] - 0s 38us/step - loss: 0.3604 - acc: 0.8707\n",
            "Epoch 80/100\n",
            "1500/1500 [==============================] - 0s 40us/step - loss: 0.3586 - acc: 0.8720\n",
            "Epoch 81/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 0.3578 - acc: 0.8740\n",
            "Epoch 82/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 0.3567 - acc: 0.8727\n",
            "Epoch 83/100\n",
            "1500/1500 [==============================] - 0s 51us/step - loss: 0.3556 - acc: 0.8700\n",
            "Epoch 84/100\n",
            "1500/1500 [==============================] - 0s 40us/step - loss: 0.3543 - acc: 0.8720\n",
            "Epoch 85/100\n",
            "1500/1500 [==============================] - 0s 43us/step - loss: 0.3532 - acc: 0.8733\n",
            "Epoch 86/100\n",
            "1500/1500 [==============================] - 0s 41us/step - loss: 0.3507 - acc: 0.8727\n",
            "Epoch 87/100\n",
            "1500/1500 [==============================] - 0s 39us/step - loss: 0.3505 - acc: 0.8740\n",
            "Epoch 88/100\n",
            "1500/1500 [==============================] - 0s 45us/step - loss: 0.3499 - acc: 0.8720\n",
            "Epoch 89/100\n",
            "1500/1500 [==============================] - 0s 43us/step - loss: 0.3495 - acc: 0.8747\n",
            "Epoch 90/100\n",
            "1500/1500 [==============================] - 0s 40us/step - loss: 0.3486 - acc: 0.8720\n",
            "Epoch 91/100\n",
            "1500/1500 [==============================] - 0s 40us/step - loss: 0.3467 - acc: 0.8733\n",
            "Epoch 92/100\n",
            "1500/1500 [==============================] - 0s 43us/step - loss: 0.3471 - acc: 0.8740\n",
            "Epoch 93/100\n",
            "1500/1500 [==============================] - 0s 47us/step - loss: 0.3460 - acc: 0.8753\n",
            "Epoch 94/100\n",
            "1500/1500 [==============================] - 0s 42us/step - loss: 0.3454 - acc: 0.8760\n",
            "Epoch 95/100\n",
            "1500/1500 [==============================] - 0s 39us/step - loss: 0.3438 - acc: 0.8773\n",
            "Epoch 96/100\n",
            "1500/1500 [==============================] - 0s 40us/step - loss: 0.3419 - acc: 0.8753\n",
            "Epoch 97/100\n",
            "1500/1500 [==============================] - 0s 40us/step - loss: 0.3421 - acc: 0.8753\n",
            "Epoch 98/100\n",
            "1500/1500 [==============================] - 0s 43us/step - loss: 0.3412 - acc: 0.8753\n",
            "Epoch 99/100\n",
            "1500/1500 [==============================] - 0s 48us/step - loss: 0.3402 - acc: 0.8773\n",
            "Epoch 100/100\n",
            "1500/1500 [==============================] - 0s 40us/step - loss: 0.3391 - acc: 0.8740\n",
            "60/60 [==============================] - 0s 3ms/step\n",
            "\n",
            "acc: 83.33%\n",
            "[[15  2  4]\n",
            " [ 4 16  0]\n",
            " [ 0  0 19]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.71      0.75        21\n",
            "           1       0.89      0.80      0.84        20\n",
            "           2       0.83      1.00      0.90        19\n",
            "\n",
            "    accuracy                           0.83        60\n",
            "   macro avg       0.83      0.84      0.83        60\n",
            "weighted avg       0.83      0.83      0.83        60\n",
            "\n",
            "[0.4400524655977885, 0.8333333253860473]\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_56 (Dense)             (None, 10)                30        \n",
            "_________________________________________________________________\n",
            "dense_57 (Dense)             (None, 20)                220       \n",
            "_________________________________________________________________\n",
            "dense_58 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_59 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_60 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_61 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_62 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_63 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_64 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_65 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_66 (Dense)             (None, 3)                 63        \n",
            "=================================================================\n",
            "Total params: 3,673\n",
            "Trainable params: 3,673\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1500/1500 [==============================] - 1s 472us/step - loss: 1.0946 - acc: 0.4440\n",
            "Epoch 2/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 1.0917 - acc: 0.5887\n",
            "Epoch 3/100\n",
            "1500/1500 [==============================] - 0s 43us/step - loss: 1.0894 - acc: 0.6080\n",
            "Epoch 4/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 1.0875 - acc: 0.5987\n",
            "Epoch 5/100\n",
            "1500/1500 [==============================] - 0s 64us/step - loss: 1.0859 - acc: 0.6253\n",
            "Epoch 6/100\n",
            "1500/1500 [==============================] - 0s 47us/step - loss: 1.0844 - acc: 0.5753\n",
            "Epoch 7/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 1.0829 - acc: 0.6400\n",
            "Epoch 8/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 1.0813 - acc: 0.6293\n",
            "Epoch 9/100\n",
            "1500/1500 [==============================] - 0s 45us/step - loss: 1.0797 - acc: 0.6387\n",
            "Epoch 10/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 1.0778 - acc: 0.6520\n",
            "Epoch 11/100\n",
            "1500/1500 [==============================] - 0s 47us/step - loss: 1.0758 - acc: 0.6453\n",
            "Epoch 12/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 1.0738 - acc: 0.6507\n",
            "Epoch 13/100\n",
            "1500/1500 [==============================] - 0s 46us/step - loss: 1.0716 - acc: 0.6673\n",
            "Epoch 14/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 1.0693 - acc: 0.6667\n",
            "Epoch 15/100\n",
            "1500/1500 [==============================] - 0s 43us/step - loss: 1.0668 - acc: 0.7087\n",
            "Epoch 16/100\n",
            "1500/1500 [==============================] - 0s 48us/step - loss: 1.0640 - acc: 0.7053\n",
            "Epoch 17/100\n",
            "1500/1500 [==============================] - 0s 42us/step - loss: 1.0610 - acc: 0.7160\n",
            "Epoch 18/100\n",
            "1500/1500 [==============================] - 0s 45us/step - loss: 1.0576 - acc: 0.7473\n",
            "Epoch 19/100\n",
            "1500/1500 [==============================] - 0s 43us/step - loss: 1.0540 - acc: 0.7207\n",
            "Epoch 20/100\n",
            "1500/1500 [==============================] - 0s 50us/step - loss: 1.0500 - acc: 0.7573\n",
            "Epoch 21/100\n",
            "1500/1500 [==============================] - 0s 46us/step - loss: 1.0456 - acc: 0.7633\n",
            "Epoch 22/100\n",
            "1500/1500 [==============================] - 0s 43us/step - loss: 1.0407 - acc: 0.7840\n",
            "Epoch 23/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 1.0353 - acc: 0.8253\n",
            "Epoch 24/100\n",
            "1500/1500 [==============================] - 0s 42us/step - loss: 1.0293 - acc: 0.8393\n",
            "Epoch 25/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 1.0225 - acc: 0.8427\n",
            "Epoch 26/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 1.0150 - acc: 0.8633\n",
            "Epoch 27/100\n",
            "1500/1500 [==============================] - 0s 47us/step - loss: 1.0064 - acc: 0.8720\n",
            "Epoch 28/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 0.9967 - acc: 0.8780\n",
            "Epoch 29/100\n",
            "1500/1500 [==============================] - 0s 50us/step - loss: 0.9856 - acc: 0.8833\n",
            "Epoch 30/100\n",
            "1500/1500 [==============================] - 0s 43us/step - loss: 0.9729 - acc: 0.8880\n",
            "Epoch 31/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 0.9580 - acc: 0.8887\n",
            "Epoch 32/100\n",
            "1500/1500 [==============================] - 0s 43us/step - loss: 0.9410 - acc: 0.8900\n",
            "Epoch 33/100\n",
            "1500/1500 [==============================] - 0s 46us/step - loss: 0.9209 - acc: 0.8893\n",
            "Epoch 34/100\n",
            "1500/1500 [==============================] - 0s 46us/step - loss: 0.8970 - acc: 0.8927\n",
            "Epoch 35/100\n",
            "1500/1500 [==============================] - 0s 52us/step - loss: 0.8688 - acc: 0.8933\n",
            "Epoch 36/100\n",
            "1500/1500 [==============================] - 0s 43us/step - loss: 0.8364 - acc: 0.8960\n",
            "Epoch 37/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 0.7986 - acc: 0.8973\n",
            "Epoch 38/100\n",
            "1500/1500 [==============================] - 0s 43us/step - loss: 0.7562 - acc: 0.8973\n",
            "Epoch 39/100\n",
            "1500/1500 [==============================] - 0s 46us/step - loss: 0.7103 - acc: 0.8980\n",
            "Epoch 40/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 0.6637 - acc: 0.8960\n",
            "Epoch 41/100\n",
            "1500/1500 [==============================] - 0s 43us/step - loss: 0.6180 - acc: 0.8973\n",
            "Epoch 42/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 0.5746 - acc: 0.8967\n",
            "Epoch 43/100\n",
            "1500/1500 [==============================] - 0s 43us/step - loss: 0.5345 - acc: 0.8960\n",
            "Epoch 44/100\n",
            "1500/1500 [==============================] - 0s 49us/step - loss: 0.4972 - acc: 0.8953\n",
            "Epoch 45/100\n",
            "1500/1500 [==============================] - 0s 45us/step - loss: 0.4659 - acc: 0.8947\n",
            "Epoch 46/100\n",
            "1500/1500 [==============================] - 0s 47us/step - loss: 0.4369 - acc: 0.8940\n",
            "Epoch 47/100\n",
            "1500/1500 [==============================] - 0s 51us/step - loss: 0.4114 - acc: 0.8967\n",
            "Epoch 48/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 0.3892 - acc: 0.8933\n",
            "Epoch 49/100\n",
            "1500/1500 [==============================] - 0s 52us/step - loss: 0.3702 - acc: 0.8947\n",
            "Epoch 50/100\n",
            "1500/1500 [==============================] - 0s 49us/step - loss: 0.3544 - acc: 0.8960\n",
            "Epoch 51/100\n",
            "1500/1500 [==============================] - 0s 43us/step - loss: 0.3408 - acc: 0.8960\n",
            "Epoch 52/100\n",
            "1500/1500 [==============================] - 0s 46us/step - loss: 0.3290 - acc: 0.8967\n",
            "Epoch 53/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 0.3196 - acc: 0.8987\n",
            "Epoch 54/100\n",
            "1500/1500 [==============================] - 0s 48us/step - loss: 0.3122 - acc: 0.8980\n",
            "Epoch 55/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 0.3045 - acc: 0.8980\n",
            "Epoch 56/100\n",
            "1500/1500 [==============================] - 0s 43us/step - loss: 0.3001 - acc: 0.8987\n",
            "Epoch 57/100\n",
            "1500/1500 [==============================] - 0s 45us/step - loss: 0.2943 - acc: 0.9033\n",
            "Epoch 58/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 0.2883 - acc: 0.9007\n",
            "Epoch 59/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 0.2880 - acc: 0.9040\n",
            "Epoch 60/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 0.2833 - acc: 0.9047\n",
            "Epoch 61/100\n",
            "1500/1500 [==============================] - 0s 47us/step - loss: 0.2808 - acc: 0.9047\n",
            "Epoch 62/100\n",
            "1500/1500 [==============================] - 0s 41us/step - loss: 0.2790 - acc: 0.9067\n",
            "Epoch 63/100\n",
            "1500/1500 [==============================] - 0s 47us/step - loss: 0.2764 - acc: 0.9027\n",
            "Epoch 64/100\n",
            "1500/1500 [==============================] - 0s 49us/step - loss: 0.2726 - acc: 0.9080\n",
            "Epoch 65/100\n",
            "1500/1500 [==============================] - 0s 46us/step - loss: 0.2722 - acc: 0.9100\n",
            "Epoch 66/100\n",
            "1500/1500 [==============================] - 0s 46us/step - loss: 0.2705 - acc: 0.9087\n",
            "Epoch 67/100\n",
            "1500/1500 [==============================] - 0s 43us/step - loss: 0.2702 - acc: 0.9053\n",
            "Epoch 68/100\n",
            "1500/1500 [==============================] - 0s 45us/step - loss: 0.2746 - acc: 0.9053\n",
            "Epoch 69/100\n",
            "1500/1500 [==============================] - 0s 43us/step - loss: 0.2667 - acc: 0.9087\n",
            "Epoch 70/100\n",
            "1500/1500 [==============================] - 0s 45us/step - loss: 0.2680 - acc: 0.9040\n",
            "Epoch 71/100\n",
            "1500/1500 [==============================] - 0s 47us/step - loss: 0.2658 - acc: 0.9027\n",
            "Epoch 72/100\n",
            "1500/1500 [==============================] - 0s 45us/step - loss: 0.2647 - acc: 0.9053\n",
            "Epoch 73/100\n",
            "1500/1500 [==============================] - 0s 46us/step - loss: 0.2637 - acc: 0.9067\n",
            "Epoch 74/100\n",
            "1500/1500 [==============================] - 0s 43us/step - loss: 0.2651 - acc: 0.9047\n",
            "Epoch 75/100\n",
            "1500/1500 [==============================] - 0s 43us/step - loss: 0.2625 - acc: 0.9040\n",
            "Epoch 76/100\n",
            "1500/1500 [==============================] - 0s 50us/step - loss: 0.2623 - acc: 0.9073\n",
            "Epoch 77/100\n",
            "1500/1500 [==============================] - 0s 45us/step - loss: 0.2625 - acc: 0.9013\n",
            "Epoch 78/100\n",
            "1500/1500 [==============================] - 0s 43us/step - loss: 0.2645 - acc: 0.9067\n",
            "Epoch 79/100\n",
            "1500/1500 [==============================] - 0s 50us/step - loss: 0.2615 - acc: 0.9073\n",
            "Epoch 80/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 0.2623 - acc: 0.9033\n",
            "Epoch 81/100\n",
            "1500/1500 [==============================] - 0s 49us/step - loss: 0.2626 - acc: 0.9040\n",
            "Epoch 82/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 0.2597 - acc: 0.9073\n",
            "Epoch 83/100\n",
            "1500/1500 [==============================] - 0s 45us/step - loss: 0.2599 - acc: 0.9040\n",
            "Epoch 84/100\n",
            "1500/1500 [==============================] - 0s 43us/step - loss: 0.2585 - acc: 0.9047\n",
            "Epoch 85/100\n",
            "1500/1500 [==============================] - 0s 42us/step - loss: 0.2575 - acc: 0.9053\n",
            "Epoch 86/100\n",
            "1500/1500 [==============================] - 0s 45us/step - loss: 0.2580 - acc: 0.9080\n",
            "Epoch 87/100\n",
            "1500/1500 [==============================] - 0s 46us/step - loss: 0.2616 - acc: 0.9060\n",
            "Epoch 88/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 0.2589 - acc: 0.9067\n",
            "Epoch 89/100\n",
            "1500/1500 [==============================] - 0s 45us/step - loss: 0.2570 - acc: 0.9067\n",
            "Epoch 90/100\n",
            "1500/1500 [==============================] - 0s 50us/step - loss: 0.2559 - acc: 0.9047\n",
            "Epoch 91/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 0.2583 - acc: 0.9073\n",
            "Epoch 92/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 0.2568 - acc: 0.9080\n",
            "Epoch 93/100\n",
            "1500/1500 [==============================] - 0s 43us/step - loss: 0.2610 - acc: 0.9027\n",
            "Epoch 94/100\n",
            "1500/1500 [==============================] - 0s 54us/step - loss: 0.2548 - acc: 0.9047\n",
            "Epoch 95/100\n",
            "1500/1500 [==============================] - 0s 45us/step - loss: 0.2562 - acc: 0.9060\n",
            "Epoch 96/100\n",
            "1500/1500 [==============================] - 0s 46us/step - loss: 0.2571 - acc: 0.9053\n",
            "Epoch 97/100\n",
            "1500/1500 [==============================] - 0s 43us/step - loss: 0.2560 - acc: 0.9040\n",
            "Epoch 98/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 0.2530 - acc: 0.9027\n",
            "Epoch 99/100\n",
            "1500/1500 [==============================] - 0s 44us/step - loss: 0.2611 - acc: 0.9053\n",
            "Epoch 100/100\n",
            "1500/1500 [==============================] - 0s 48us/step - loss: 0.2548 - acc: 0.9093\n",
            "60/60 [==============================] - 0s 4ms/step\n",
            "\n",
            "acc: 93.33%\n",
            "[[24  2  0]\n",
            " [ 1 18  0]\n",
            " [ 0  1 14]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.92      0.94        26\n",
            "           1       0.86      0.95      0.90        19\n",
            "           2       1.00      0.93      0.97        15\n",
            "\n",
            "    accuracy                           0.93        60\n",
            "   macro avg       0.94      0.93      0.94        60\n",
            "weighted avg       0.94      0.93      0.93        60\n",
            "\n",
            "[0.19608651498953503, 0.9333333293596904]\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_67 (Dense)             (None, 10)                30        \n",
            "_________________________________________________________________\n",
            "dense_68 (Dense)             (None, 20)                220       \n",
            "_________________________________________________________________\n",
            "dense_69 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_70 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_71 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_72 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_73 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_74 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_75 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_76 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_77 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_78 (Dense)             (None, 3)                 63        \n",
            "=================================================================\n",
            "Total params: 4,093\n",
            "Trainable params: 4,093\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1500/1500 [==============================] - 1s 569us/step - loss: 1.0965 - acc: 0.5207\n",
            "Epoch 2/100\n",
            "1500/1500 [==============================] - 0s 46us/step - loss: 1.0935 - acc: 0.5693\n",
            "Epoch 3/100\n",
            "1500/1500 [==============================] - 0s 46us/step - loss: 1.0916 - acc: 0.5907\n",
            "Epoch 4/100\n",
            "1500/1500 [==============================] - 0s 47us/step - loss: 1.0901 - acc: 0.6193\n",
            "Epoch 5/100\n",
            "1500/1500 [==============================] - 0s 49us/step - loss: 1.0888 - acc: 0.6713\n",
            "Epoch 6/100\n",
            "1500/1500 [==============================] - 0s 46us/step - loss: 1.0875 - acc: 0.5867\n",
            "Epoch 7/100\n",
            "1500/1500 [==============================] - 0s 49us/step - loss: 1.0862 - acc: 0.6060\n",
            "Epoch 8/100\n",
            "1500/1500 [==============================] - 0s 47us/step - loss: 1.0847 - acc: 0.6360\n",
            "Epoch 9/100\n",
            "1500/1500 [==============================] - 0s 47us/step - loss: 1.0831 - acc: 0.6267\n",
            "Epoch 10/100\n",
            "1500/1500 [==============================] - 0s 49us/step - loss: 1.0817 - acc: 0.6833\n",
            "Epoch 11/100\n",
            "1500/1500 [==============================] - 0s 52us/step - loss: 1.0800 - acc: 0.6420\n",
            "Epoch 12/100\n",
            "1500/1500 [==============================] - 0s 47us/step - loss: 1.0783 - acc: 0.7120\n",
            "Epoch 13/100\n",
            "1500/1500 [==============================] - 0s 47us/step - loss: 1.0764 - acc: 0.6760\n",
            "Epoch 14/100\n",
            "1500/1500 [==============================] - 0s 52us/step - loss: 1.0742 - acc: 0.6953\n",
            "Epoch 15/100\n",
            "1500/1500 [==============================] - 0s 49us/step - loss: 1.0717 - acc: 0.7160\n",
            "Epoch 16/100\n",
            "1500/1500 [==============================] - 0s 47us/step - loss: 1.0689 - acc: 0.7187\n",
            "Epoch 17/100\n",
            "1500/1500 [==============================] - 0s 47us/step - loss: 1.0660 - acc: 0.7313\n",
            "Epoch 18/100\n",
            "1500/1500 [==============================] - 0s 49us/step - loss: 1.0627 - acc: 0.7580\n",
            "Epoch 19/100\n",
            "1500/1500 [==============================] - 0s 48us/step - loss: 1.0593 - acc: 0.7760\n",
            "Epoch 20/100\n",
            "1500/1500 [==============================] - 0s 50us/step - loss: 1.0557 - acc: 0.7567\n",
            "Epoch 21/100\n",
            "1500/1500 [==============================] - 0s 47us/step - loss: 1.0520 - acc: 0.7673\n",
            "Epoch 22/100\n",
            "1500/1500 [==============================] - 0s 47us/step - loss: 1.0480 - acc: 0.7960\n",
            "Epoch 23/100\n",
            "1500/1500 [==============================] - 0s 46us/step - loss: 1.0438 - acc: 0.8073\n",
            "Epoch 24/100\n",
            "1500/1500 [==============================] - 0s 49us/step - loss: 1.0392 - acc: 0.8140\n",
            "Epoch 25/100\n",
            "1500/1500 [==============================] - 0s 55us/step - loss: 1.0343 - acc: 0.8180\n",
            "Epoch 26/100\n",
            "1500/1500 [==============================] - 0s 48us/step - loss: 1.0291 - acc: 0.8380\n",
            "Epoch 27/100\n",
            "1500/1500 [==============================] - 0s 46us/step - loss: 1.0235 - acc: 0.8420\n",
            "Epoch 28/100\n",
            "1500/1500 [==============================] - 0s 48us/step - loss: 1.0174 - acc: 0.8500\n",
            "Epoch 29/100\n",
            "1500/1500 [==============================] - 0s 46us/step - loss: 1.0108 - acc: 0.8520\n",
            "Epoch 30/100\n",
            "1500/1500 [==============================] - 0s 48us/step - loss: 1.0039 - acc: 0.8600\n",
            "Epoch 31/100\n",
            "1500/1500 [==============================] - 0s 47us/step - loss: 0.9964 - acc: 0.8587\n",
            "Epoch 32/100\n",
            "1500/1500 [==============================] - 0s 48us/step - loss: 0.9882 - acc: 0.8620\n",
            "Epoch 33/100\n",
            "1500/1500 [==============================] - 0s 47us/step - loss: 0.9789 - acc: 0.8693\n",
            "Epoch 34/100\n",
            "1500/1500 [==============================] - 0s 48us/step - loss: 0.9687 - acc: 0.8700\n",
            "Epoch 35/100\n",
            "1500/1500 [==============================] - 0s 50us/step - loss: 0.9578 - acc: 0.8733\n",
            "Epoch 36/100\n",
            "1500/1500 [==============================] - 0s 47us/step - loss: 0.9460 - acc: 0.8740\n",
            "Epoch 37/100\n",
            "1500/1500 [==============================] - 0s 46us/step - loss: 0.9335 - acc: 0.8760\n",
            "Epoch 38/100\n",
            "1500/1500 [==============================] - 0s 45us/step - loss: 0.9198 - acc: 0.8740\n",
            "Epoch 39/100\n",
            "1500/1500 [==============================] - 0s 50us/step - loss: 0.9054 - acc: 0.8747\n",
            "Epoch 40/100\n",
            "1500/1500 [==============================] - 0s 54us/step - loss: 0.8900 - acc: 0.8767\n",
            "Epoch 41/100\n",
            "1500/1500 [==============================] - 0s 47us/step - loss: 0.8729 - acc: 0.8767\n",
            "Epoch 42/100\n",
            "1500/1500 [==============================] - 0s 48us/step - loss: 0.8554 - acc: 0.8760\n",
            "Epoch 43/100\n",
            "1500/1500 [==============================] - 0s 47us/step - loss: 0.8362 - acc: 0.8807\n",
            "Epoch 44/100\n",
            "1500/1500 [==============================] - 0s 50us/step - loss: 0.8165 - acc: 0.8793\n",
            "Epoch 45/100\n",
            "1500/1500 [==============================] - 0s 48us/step - loss: 0.7951 - acc: 0.8813\n",
            "Epoch 46/100\n",
            "1500/1500 [==============================] - 0s 46us/step - loss: 0.7729 - acc: 0.8780\n",
            "Epoch 47/100\n",
            "1500/1500 [==============================] - 0s 51us/step - loss: 0.7501 - acc: 0.8840\n",
            "Epoch 48/100\n",
            "1500/1500 [==============================] - 0s 47us/step - loss: 0.7260 - acc: 0.8827\n",
            "Epoch 49/100\n",
            "1500/1500 [==============================] - 0s 52us/step - loss: 0.7015 - acc: 0.8860\n",
            "Epoch 50/100\n",
            "1500/1500 [==============================] - 0s 47us/step - loss: 0.6770 - acc: 0.8853\n",
            "Epoch 51/100\n",
            "1500/1500 [==============================] - 0s 46us/step - loss: 0.6517 - acc: 0.8880\n",
            "Epoch 52/100\n",
            "1500/1500 [==============================] - 0s 47us/step - loss: 0.6270 - acc: 0.8887\n",
            "Epoch 53/100\n",
            "1500/1500 [==============================] - 0s 55us/step - loss: 0.6025 - acc: 0.8893\n",
            "Epoch 54/100\n",
            "1500/1500 [==============================] - 0s 49us/step - loss: 0.5783 - acc: 0.8913\n",
            "Epoch 55/100\n",
            "1500/1500 [==============================] - 0s 49us/step - loss: 0.5555 - acc: 0.8927\n",
            "Epoch 56/100\n",
            "1500/1500 [==============================] - 0s 50us/step - loss: 0.5318 - acc: 0.8933\n",
            "Epoch 57/100\n",
            "1500/1500 [==============================] - 0s 47us/step - loss: 0.5107 - acc: 0.8940\n",
            "Epoch 58/100\n",
            "1500/1500 [==============================] - 0s 49us/step - loss: 0.4909 - acc: 0.8920\n",
            "Epoch 59/100\n",
            "1500/1500 [==============================] - 0s 48us/step - loss: 0.4713 - acc: 0.8947\n",
            "Epoch 60/100\n",
            "1500/1500 [==============================] - 0s 46us/step - loss: 0.4542 - acc: 0.8940\n",
            "Epoch 61/100\n",
            "1500/1500 [==============================] - 0s 51us/step - loss: 0.4364 - acc: 0.8967\n",
            "Epoch 62/100\n",
            "1500/1500 [==============================] - 0s 51us/step - loss: 0.4211 - acc: 0.8987\n",
            "Epoch 63/100\n",
            "1500/1500 [==============================] - 0s 47us/step - loss: 0.4064 - acc: 0.8960\n",
            "Epoch 64/100\n",
            "1500/1500 [==============================] - 0s 50us/step - loss: 0.3935 - acc: 0.8987\n",
            "Epoch 65/100\n",
            "1500/1500 [==============================] - 0s 50us/step - loss: 0.3840 - acc: 0.8947\n",
            "Epoch 66/100\n",
            "1500/1500 [==============================] - 0s 52us/step - loss: 0.3724 - acc: 0.8967\n",
            "Epoch 67/100\n",
            "1500/1500 [==============================] - 0s 62us/step - loss: 0.3609 - acc: 0.8967\n",
            "Epoch 68/100\n",
            "1500/1500 [==============================] - 0s 48us/step - loss: 0.3542 - acc: 0.9027\n",
            "Epoch 69/100\n",
            "1500/1500 [==============================] - 0s 46us/step - loss: 0.3452 - acc: 0.8987\n",
            "Epoch 70/100\n",
            "1500/1500 [==============================] - 0s 47us/step - loss: 0.3395 - acc: 0.8973\n",
            "Epoch 71/100\n",
            "1500/1500 [==============================] - 0s 51us/step - loss: 0.3315 - acc: 0.9020\n",
            "Epoch 72/100\n",
            "1500/1500 [==============================] - 0s 47us/step - loss: 0.3261 - acc: 0.9027\n",
            "Epoch 73/100\n",
            "1500/1500 [==============================] - 0s 48us/step - loss: 0.3216 - acc: 0.9000\n",
            "Epoch 74/100\n",
            "1500/1500 [==============================] - 0s 48us/step - loss: 0.3168 - acc: 0.8987\n",
            "Epoch 75/100\n",
            "1500/1500 [==============================] - 0s 47us/step - loss: 0.3101 - acc: 0.9013\n",
            "Epoch 76/100\n",
            "1500/1500 [==============================] - 0s 50us/step - loss: 0.3062 - acc: 0.9027\n",
            "Epoch 77/100\n",
            "1500/1500 [==============================] - 0s 46us/step - loss: 0.3049 - acc: 0.9007\n",
            "Epoch 78/100\n",
            "1500/1500 [==============================] - 0s 47us/step - loss: 0.2988 - acc: 0.9027\n",
            "Epoch 79/100\n",
            "1500/1500 [==============================] - 0s 52us/step - loss: 0.2975 - acc: 0.8987\n",
            "Epoch 80/100\n",
            "1500/1500 [==============================] - 0s 54us/step - loss: 0.2945 - acc: 0.9000\n",
            "Epoch 81/100\n",
            "1500/1500 [==============================] - 0s 51us/step - loss: 0.2927 - acc: 0.9033\n",
            "Epoch 82/100\n",
            "1500/1500 [==============================] - 0s 48us/step - loss: 0.2896 - acc: 0.8987\n",
            "Epoch 83/100\n",
            "1500/1500 [==============================] - 0s 47us/step - loss: 0.2897 - acc: 0.8987\n",
            "Epoch 84/100\n",
            "1500/1500 [==============================] - 0s 51us/step - loss: 0.2878 - acc: 0.8980\n",
            "Epoch 85/100\n",
            "1500/1500 [==============================] - 0s 48us/step - loss: 0.2840 - acc: 0.9000\n",
            "Epoch 86/100\n",
            "1500/1500 [==============================] - 0s 47us/step - loss: 0.2841 - acc: 0.9000\n",
            "Epoch 87/100\n",
            "1500/1500 [==============================] - 0s 47us/step - loss: 0.2825 - acc: 0.9000\n",
            "Epoch 88/100\n",
            "1500/1500 [==============================] - 0s 49us/step - loss: 0.2802 - acc: 0.9033\n",
            "Epoch 89/100\n",
            "1500/1500 [==============================] - 0s 47us/step - loss: 0.2799 - acc: 0.8980\n",
            "Epoch 90/100\n",
            "1500/1500 [==============================] - 0s 49us/step - loss: 0.2810 - acc: 0.8993\n",
            "Epoch 91/100\n",
            "1500/1500 [==============================] - 0s 46us/step - loss: 0.2785 - acc: 0.8993\n",
            "Epoch 92/100\n",
            "1500/1500 [==============================] - 0s 47us/step - loss: 0.2770 - acc: 0.9060\n",
            "Epoch 93/100\n",
            "1500/1500 [==============================] - 0s 47us/step - loss: 0.2791 - acc: 0.9047\n",
            "Epoch 94/100\n",
            "1500/1500 [==============================] - 0s 49us/step - loss: 0.2772 - acc: 0.8987\n",
            "Epoch 95/100\n",
            "1500/1500 [==============================] - 0s 56us/step - loss: 0.2724 - acc: 0.9033\n",
            "Epoch 96/100\n",
            "1500/1500 [==============================] - 0s 47us/step - loss: 0.2730 - acc: 0.9040\n",
            "Epoch 97/100\n",
            "1500/1500 [==============================] - 0s 46us/step - loss: 0.2716 - acc: 0.9013\n",
            "Epoch 98/100\n",
            "1500/1500 [==============================] - 0s 48us/step - loss: 0.2761 - acc: 0.8993\n",
            "Epoch 99/100\n",
            "1500/1500 [==============================] - 0s 48us/step - loss: 0.2727 - acc: 0.9027\n",
            "Epoch 100/100\n",
            "1500/1500 [==============================] - 0s 48us/step - loss: 0.2724 - acc: 0.9007\n",
            "60/60 [==============================] - 0s 4ms/step\n",
            "\n",
            "acc: 95.00%\n",
            "[[15  1  1]\n",
            " [ 1 23  0]\n",
            " [ 0  0 19]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.88      0.91        17\n",
            "           1       0.96      0.96      0.96        24\n",
            "           2       0.95      1.00      0.97        19\n",
            "\n",
            "    accuracy                           0.95        60\n",
            "   macro avg       0.95      0.95      0.95        60\n",
            "weighted avg       0.95      0.95      0.95        60\n",
            "\n",
            "[0.17363232026497524, 0.950000007947286]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i42cV67ETzP4",
        "colab_type": "code",
        "outputId": "2fe947aa-8819-43af-b58c-0927f803b56c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 41601
        }
      },
      "source": [
        "N_acc=[]\n",
        "for element in N:\n",
        "  model, mean_train, stddev_train = trainModel(element, 3, 100)\n",
        "  accuracy, CM = testModel(model, 20, mean_train, stddev_train)\n",
        "  N_acc.append(accuracy)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_79 (Dense)             (None, 10)                30        \n",
            "_________________________________________________________________\n",
            "dense_80 (Dense)             (None, 20)                220       \n",
            "_________________________________________________________________\n",
            "dense_81 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_82 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_83 (Dense)             (None, 3)                 63        \n",
            "=================================================================\n",
            "Total params: 1,153\n",
            "Trainable params: 1,153\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "30/30 [==============================] - 1s 23ms/step - loss: 1.1090 - acc: 0.0000e+00\n",
            "Epoch 2/100\n",
            "30/30 [==============================] - 0s 408us/step - loss: 1.1071 - acc: 0.0000e+00\n",
            "Epoch 3/100\n",
            "30/30 [==============================] - 0s 229us/step - loss: 1.1052 - acc: 0.0000e+00\n",
            "Epoch 4/100\n",
            "30/30 [==============================] - 0s 288us/step - loss: 1.1033 - acc: 0.0000e+00\n",
            "Epoch 5/100\n",
            "30/30 [==============================] - 0s 176us/step - loss: 1.1014 - acc: 0.0000e+00\n",
            "Epoch 6/100\n",
            "30/30 [==============================] - 0s 113us/step - loss: 1.0995 - acc: 0.0333\n",
            "Epoch 7/100\n",
            "30/30 [==============================] - 0s 126us/step - loss: 1.0976 - acc: 0.0667\n",
            "Epoch 8/100\n",
            "30/30 [==============================] - 0s 159us/step - loss: 1.0958 - acc: 0.1000\n",
            "Epoch 9/100\n",
            "30/30 [==============================] - 0s 111us/step - loss: 1.0940 - acc: 0.1333\n",
            "Epoch 10/100\n",
            "30/30 [==============================] - 0s 110us/step - loss: 1.0922 - acc: 0.1333\n",
            "Epoch 11/100\n",
            "30/30 [==============================] - 0s 113us/step - loss: 1.0904 - acc: 0.1333\n",
            "Epoch 12/100\n",
            "30/30 [==============================] - 0s 185us/step - loss: 1.0885 - acc: 0.1667\n",
            "Epoch 13/100\n",
            "30/30 [==============================] - 0s 164us/step - loss: 1.0867 - acc: 0.2333\n",
            "Epoch 14/100\n",
            "30/30 [==============================] - 0s 177us/step - loss: 1.0849 - acc: 0.2333\n",
            "Epoch 15/100\n",
            "30/30 [==============================] - 0s 123us/step - loss: 1.0830 - acc: 0.3000\n",
            "Epoch 16/100\n",
            "30/30 [==============================] - 0s 159us/step - loss: 1.0811 - acc: 0.3000\n",
            "Epoch 17/100\n",
            "30/30 [==============================] - 0s 189us/step - loss: 1.0792 - acc: 0.3333\n",
            "Epoch 18/100\n",
            "30/30 [==============================] - 0s 171us/step - loss: 1.0773 - acc: 0.3667\n",
            "Epoch 19/100\n",
            "30/30 [==============================] - 0s 107us/step - loss: 1.0754 - acc: 0.3667\n",
            "Epoch 20/100\n",
            "30/30 [==============================] - 0s 113us/step - loss: 1.0736 - acc: 0.3667\n",
            "Epoch 21/100\n",
            "30/30 [==============================] - 0s 184us/step - loss: 1.0718 - acc: 0.3667\n",
            "Epoch 22/100\n",
            "30/30 [==============================] - 0s 172us/step - loss: 1.0701 - acc: 0.4000\n",
            "Epoch 23/100\n",
            "30/30 [==============================] - 0s 206us/step - loss: 1.0683 - acc: 0.5000\n",
            "Epoch 24/100\n",
            "30/30 [==============================] - 0s 162us/step - loss: 1.0666 - acc: 0.5000\n",
            "Epoch 25/100\n",
            "30/30 [==============================] - 0s 137us/step - loss: 1.0650 - acc: 0.5000\n",
            "Epoch 26/100\n",
            "30/30 [==============================] - 0s 167us/step - loss: 1.0633 - acc: 0.5333\n",
            "Epoch 27/100\n",
            "30/30 [==============================] - 0s 179us/step - loss: 1.0616 - acc: 0.5333\n",
            "Epoch 28/100\n",
            "30/30 [==============================] - 0s 155us/step - loss: 1.0600 - acc: 0.5333\n",
            "Epoch 29/100\n",
            "30/30 [==============================] - 0s 168us/step - loss: 1.0583 - acc: 0.5667\n",
            "Epoch 30/100\n",
            "30/30 [==============================] - 0s 162us/step - loss: 1.0567 - acc: 0.5667\n",
            "Epoch 31/100\n",
            "30/30 [==============================] - 0s 180us/step - loss: 1.0551 - acc: 0.6000\n",
            "Epoch 32/100\n",
            "30/30 [==============================] - 0s 144us/step - loss: 1.0535 - acc: 0.6000\n",
            "Epoch 33/100\n",
            "30/30 [==============================] - 0s 163us/step - loss: 1.0519 - acc: 0.6667\n",
            "Epoch 34/100\n",
            "30/30 [==============================] - 0s 145us/step - loss: 1.0504 - acc: 0.6667\n",
            "Epoch 35/100\n",
            "30/30 [==============================] - 0s 134us/step - loss: 1.0488 - acc: 0.6667\n",
            "Epoch 36/100\n",
            "30/30 [==============================] - 0s 131us/step - loss: 1.0473 - acc: 0.7000\n",
            "Epoch 37/100\n",
            "30/30 [==============================] - 0s 183us/step - loss: 1.0458 - acc: 0.7000\n",
            "Epoch 38/100\n",
            "30/30 [==============================] - 0s 153us/step - loss: 1.0442 - acc: 0.7000\n",
            "Epoch 39/100\n",
            "30/30 [==============================] - 0s 159us/step - loss: 1.0427 - acc: 0.7000\n",
            "Epoch 40/100\n",
            "30/30 [==============================] - 0s 170us/step - loss: 1.0411 - acc: 0.7333\n",
            "Epoch 41/100\n",
            "30/30 [==============================] - 0s 162us/step - loss: 1.0395 - acc: 0.7667\n",
            "Epoch 42/100\n",
            "30/30 [==============================] - 0s 166us/step - loss: 1.0378 - acc: 0.8000\n",
            "Epoch 43/100\n",
            "30/30 [==============================] - 0s 171us/step - loss: 1.0362 - acc: 0.8000\n",
            "Epoch 44/100\n",
            "30/30 [==============================] - 0s 168us/step - loss: 1.0345 - acc: 0.8000\n",
            "Epoch 45/100\n",
            "30/30 [==============================] - 0s 137us/step - loss: 1.0329 - acc: 0.8000\n",
            "Epoch 46/100\n",
            "30/30 [==============================] - 0s 156us/step - loss: 1.0312 - acc: 0.8000\n",
            "Epoch 47/100\n",
            "30/30 [==============================] - 0s 136us/step - loss: 1.0296 - acc: 0.8000\n",
            "Epoch 48/100\n",
            "30/30 [==============================] - 0s 137us/step - loss: 1.0280 - acc: 0.8000\n",
            "Epoch 49/100\n",
            "30/30 [==============================] - 0s 131us/step - loss: 1.0263 - acc: 0.8000\n",
            "Epoch 50/100\n",
            "30/30 [==============================] - 0s 181us/step - loss: 1.0247 - acc: 0.8000\n",
            "Epoch 51/100\n",
            "30/30 [==============================] - 0s 128us/step - loss: 1.0230 - acc: 0.8000\n",
            "Epoch 52/100\n",
            "30/30 [==============================] - 0s 126us/step - loss: 1.0213 - acc: 0.8000\n",
            "Epoch 53/100\n",
            "30/30 [==============================] - 0s 138us/step - loss: 1.0197 - acc: 0.8000\n",
            "Epoch 54/100\n",
            "30/30 [==============================] - 0s 145us/step - loss: 1.0180 - acc: 0.8000\n",
            "Epoch 55/100\n",
            "30/30 [==============================] - 0s 156us/step - loss: 1.0163 - acc: 0.8000\n",
            "Epoch 56/100\n",
            "30/30 [==============================] - 0s 172us/step - loss: 1.0147 - acc: 0.8000\n",
            "Epoch 57/100\n",
            "30/30 [==============================] - 0s 159us/step - loss: 1.0130 - acc: 0.8000\n",
            "Epoch 58/100\n",
            "30/30 [==============================] - 0s 154us/step - loss: 1.0113 - acc: 0.8000\n",
            "Epoch 59/100\n",
            "30/30 [==============================] - 0s 187us/step - loss: 1.0096 - acc: 0.8000\n",
            "Epoch 60/100\n",
            "30/30 [==============================] - 0s 149us/step - loss: 1.0079 - acc: 0.8000\n",
            "Epoch 61/100\n",
            "30/30 [==============================] - 0s 162us/step - loss: 1.0062 - acc: 0.8000\n",
            "Epoch 62/100\n",
            "30/30 [==============================] - 0s 174us/step - loss: 1.0045 - acc: 0.8000\n",
            "Epoch 63/100\n",
            "30/30 [==============================] - 0s 163us/step - loss: 1.0028 - acc: 0.8000\n",
            "Epoch 64/100\n",
            "30/30 [==============================] - 0s 164us/step - loss: 1.0011 - acc: 0.8000\n",
            "Epoch 65/100\n",
            "30/30 [==============================] - 0s 165us/step - loss: 0.9994 - acc: 0.8000\n",
            "Epoch 66/100\n",
            "30/30 [==============================] - 0s 145us/step - loss: 0.9977 - acc: 0.8000\n",
            "Epoch 67/100\n",
            "30/30 [==============================] - 0s 143us/step - loss: 0.9960 - acc: 0.8000\n",
            "Epoch 68/100\n",
            "30/30 [==============================] - 0s 171us/step - loss: 0.9943 - acc: 0.8000\n",
            "Epoch 69/100\n",
            "30/30 [==============================] - 0s 184us/step - loss: 0.9925 - acc: 0.8000\n",
            "Epoch 70/100\n",
            "30/30 [==============================] - 0s 163us/step - loss: 0.9908 - acc: 0.8000\n",
            "Epoch 71/100\n",
            "30/30 [==============================] - 0s 210us/step - loss: 0.9890 - acc: 0.8000\n",
            "Epoch 72/100\n",
            "30/30 [==============================] - 0s 393us/step - loss: 0.9872 - acc: 0.8000\n",
            "Epoch 73/100\n",
            "30/30 [==============================] - 0s 172us/step - loss: 0.9855 - acc: 0.8000\n",
            "Epoch 74/100\n",
            "30/30 [==============================] - 0s 177us/step - loss: 0.9837 - acc: 0.8000\n",
            "Epoch 75/100\n",
            "30/30 [==============================] - 0s 121us/step - loss: 0.9818 - acc: 0.8000\n",
            "Epoch 76/100\n",
            "30/30 [==============================] - 0s 209us/step - loss: 0.9800 - acc: 0.8000\n",
            "Epoch 77/100\n",
            "30/30 [==============================] - 0s 134us/step - loss: 0.9782 - acc: 0.8000\n",
            "Epoch 78/100\n",
            "30/30 [==============================] - 0s 168us/step - loss: 0.9764 - acc: 0.8000\n",
            "Epoch 79/100\n",
            "30/30 [==============================] - 0s 191us/step - loss: 0.9746 - acc: 0.8000\n",
            "Epoch 80/100\n",
            "30/30 [==============================] - 0s 172us/step - loss: 0.9728 - acc: 0.8000\n",
            "Epoch 81/100\n",
            "30/30 [==============================] - 0s 175us/step - loss: 0.9710 - acc: 0.8000\n",
            "Epoch 82/100\n",
            "30/30 [==============================] - 0s 185us/step - loss: 0.9691 - acc: 0.8000\n",
            "Epoch 83/100\n",
            "30/30 [==============================] - 0s 217us/step - loss: 0.9673 - acc: 0.8000\n",
            "Epoch 84/100\n",
            "30/30 [==============================] - 0s 185us/step - loss: 0.9655 - acc: 0.8000\n",
            "Epoch 85/100\n",
            "30/30 [==============================] - 0s 177us/step - loss: 0.9637 - acc: 0.8000\n",
            "Epoch 86/100\n",
            "30/30 [==============================] - 0s 217us/step - loss: 0.9619 - acc: 0.8000\n",
            "Epoch 87/100\n",
            "30/30 [==============================] - 0s 226us/step - loss: 0.9601 - acc: 0.8000\n",
            "Epoch 88/100\n",
            "30/30 [==============================] - 0s 206us/step - loss: 0.9583 - acc: 0.8000\n",
            "Epoch 89/100\n",
            "30/30 [==============================] - 0s 184us/step - loss: 0.9564 - acc: 0.8000\n",
            "Epoch 90/100\n",
            "30/30 [==============================] - 0s 226us/step - loss: 0.9546 - acc: 0.8000\n",
            "Epoch 91/100\n",
            "30/30 [==============================] - 0s 210us/step - loss: 0.9527 - acc: 0.8000\n",
            "Epoch 92/100\n",
            "30/30 [==============================] - 0s 188us/step - loss: 0.9508 - acc: 0.8000\n",
            "Epoch 93/100\n",
            "30/30 [==============================] - 0s 207us/step - loss: 0.9489 - acc: 0.8000\n",
            "Epoch 94/100\n",
            "30/30 [==============================] - 0s 232us/step - loss: 0.9470 - acc: 0.8000\n",
            "Epoch 95/100\n",
            "30/30 [==============================] - 0s 204us/step - loss: 0.9450 - acc: 0.8000\n",
            "Epoch 96/100\n",
            "30/30 [==============================] - 0s 206us/step - loss: 0.9431 - acc: 0.8000\n",
            "Epoch 97/100\n",
            "30/30 [==============================] - 0s 158us/step - loss: 0.9411 - acc: 0.8000\n",
            "Epoch 98/100\n",
            "30/30 [==============================] - 0s 177us/step - loss: 0.9392 - acc: 0.8000\n",
            "Epoch 99/100\n",
            "30/30 [==============================] - 0s 127us/step - loss: 0.9373 - acc: 0.8000\n",
            "Epoch 100/100\n",
            "30/30 [==============================] - 0s 187us/step - loss: 0.9354 - acc: 0.8000\n",
            "60/60 [==============================] - 0s 4ms/step\n",
            "\n",
            "acc: 55.00%\n",
            "[[10  4  0]\n",
            " [ 1 23  0]\n",
            " [18  4  0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.34      0.71      0.47        14\n",
            "           1       0.74      0.96      0.84        24\n",
            "           2       0.00      0.00      0.00        22\n",
            "\n",
            "    accuracy                           0.55        60\n",
            "   macro avg       0.36      0.56      0.43        60\n",
            "weighted avg       0.38      0.55      0.44        60\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_84 (Dense)             (None, 10)                30        \n",
            "_________________________________________________________________\n",
            "dense_85 (Dense)             (None, 20)                220       \n",
            "_________________________________________________________________\n",
            "dense_86 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_87 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_88 (Dense)             (None, 3)                 63        \n",
            "=================================================================\n",
            "Total params: 1,153\n",
            "Trainable params: 1,153\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 1.1155 - acc: 0.3167\n",
            "Epoch 2/100\n",
            "60/60 [==============================] - 0s 124us/step - loss: 1.1139 - acc: 0.3333\n",
            "Epoch 3/100\n",
            "60/60 [==============================] - 0s 120us/step - loss: 1.1123 - acc: 0.3667\n",
            "Epoch 4/100\n",
            "60/60 [==============================] - 0s 85us/step - loss: 1.1107 - acc: 0.3833\n",
            "Epoch 5/100\n",
            "60/60 [==============================] - 0s 75us/step - loss: 1.1091 - acc: 0.4167\n",
            "Epoch 6/100\n",
            "60/60 [==============================] - 0s 89us/step - loss: 1.1075 - acc: 0.4167\n",
            "Epoch 7/100\n",
            "60/60 [==============================] - 0s 94us/step - loss: 1.1060 - acc: 0.4167\n",
            "Epoch 8/100\n",
            "60/60 [==============================] - 0s 86us/step - loss: 1.1044 - acc: 0.4167\n",
            "Epoch 9/100\n",
            "60/60 [==============================] - 0s 91us/step - loss: 1.1029 - acc: 0.4500\n",
            "Epoch 10/100\n",
            "60/60 [==============================] - 0s 95us/step - loss: 1.1014 - acc: 0.4667\n",
            "Epoch 11/100\n",
            "60/60 [==============================] - 0s 83us/step - loss: 1.0998 - acc: 0.4833\n",
            "Epoch 12/100\n",
            "60/60 [==============================] - 0s 88us/step - loss: 1.0982 - acc: 0.4833\n",
            "Epoch 13/100\n",
            "60/60 [==============================] - 0s 66us/step - loss: 1.0967 - acc: 0.5000\n",
            "Epoch 14/100\n",
            "60/60 [==============================] - 0s 70us/step - loss: 1.0951 - acc: 0.5000\n",
            "Epoch 15/100\n",
            "60/60 [==============================] - 0s 86us/step - loss: 1.0936 - acc: 0.5000\n",
            "Epoch 16/100\n",
            "60/60 [==============================] - 0s 76us/step - loss: 1.0921 - acc: 0.5000\n",
            "Epoch 17/100\n",
            "60/60 [==============================] - 0s 96us/step - loss: 1.0906 - acc: 0.5167\n",
            "Epoch 18/100\n",
            "60/60 [==============================] - 0s 79us/step - loss: 1.0891 - acc: 0.5167\n",
            "Epoch 19/100\n",
            "60/60 [==============================] - 0s 70us/step - loss: 1.0875 - acc: 0.5167\n",
            "Epoch 20/100\n",
            "60/60 [==============================] - 0s 57us/step - loss: 1.0860 - acc: 0.5167\n",
            "Epoch 21/100\n",
            "60/60 [==============================] - 0s 86us/step - loss: 1.0845 - acc: 0.5167\n",
            "Epoch 22/100\n",
            "60/60 [==============================] - 0s 80us/step - loss: 1.0830 - acc: 0.5167\n",
            "Epoch 23/100\n",
            "60/60 [==============================] - 0s 83us/step - loss: 1.0814 - acc: 0.5167\n",
            "Epoch 24/100\n",
            "60/60 [==============================] - 0s 55us/step - loss: 1.0799 - acc: 0.5167\n",
            "Epoch 25/100\n",
            "60/60 [==============================] - 0s 97us/step - loss: 1.0784 - acc: 0.5167\n",
            "Epoch 26/100\n",
            "60/60 [==============================] - 0s 89us/step - loss: 1.0769 - acc: 0.5167\n",
            "Epoch 27/100\n",
            "60/60 [==============================] - 0s 69us/step - loss: 1.0754 - acc: 0.5167\n",
            "Epoch 28/100\n",
            "60/60 [==============================] - 0s 65us/step - loss: 1.0738 - acc: 0.5167\n",
            "Epoch 29/100\n",
            "60/60 [==============================] - 0s 74us/step - loss: 1.0723 - acc: 0.5167\n",
            "Epoch 30/100\n",
            "60/60 [==============================] - 0s 59us/step - loss: 1.0708 - acc: 0.5167\n",
            "Epoch 31/100\n",
            "60/60 [==============================] - 0s 78us/step - loss: 1.0694 - acc: 0.5167\n",
            "Epoch 32/100\n",
            "60/60 [==============================] - 0s 67us/step - loss: 1.0679 - acc: 0.5167\n",
            "Epoch 33/100\n",
            "60/60 [==============================] - 0s 73us/step - loss: 1.0664 - acc: 0.5167\n",
            "Epoch 34/100\n",
            "60/60 [==============================] - 0s 90us/step - loss: 1.0649 - acc: 0.5167\n",
            "Epoch 35/100\n",
            "60/60 [==============================] - 0s 69us/step - loss: 1.0634 - acc: 0.5167\n",
            "Epoch 36/100\n",
            "60/60 [==============================] - 0s 62us/step - loss: 1.0619 - acc: 0.5167\n",
            "Epoch 37/100\n",
            "60/60 [==============================] - 0s 99us/step - loss: 1.0604 - acc: 0.5167\n",
            "Epoch 38/100\n",
            "60/60 [==============================] - 0s 83us/step - loss: 1.0589 - acc: 0.5167\n",
            "Epoch 39/100\n",
            "60/60 [==============================] - 0s 140us/step - loss: 1.0574 - acc: 0.5167\n",
            "Epoch 40/100\n",
            "60/60 [==============================] - 0s 98us/step - loss: 1.0559 - acc: 0.5167\n",
            "Epoch 41/100\n",
            "60/60 [==============================] - 0s 99us/step - loss: 1.0544 - acc: 0.5167\n",
            "Epoch 42/100\n",
            "60/60 [==============================] - 0s 91us/step - loss: 1.0528 - acc: 0.5167\n",
            "Epoch 43/100\n",
            "60/60 [==============================] - 0s 79us/step - loss: 1.0513 - acc: 0.5167\n",
            "Epoch 44/100\n",
            "60/60 [==============================] - 0s 112us/step - loss: 1.0497 - acc: 0.5167\n",
            "Epoch 45/100\n",
            "60/60 [==============================] - 0s 100us/step - loss: 1.0481 - acc: 0.5167\n",
            "Epoch 46/100\n",
            "60/60 [==============================] - 0s 80us/step - loss: 1.0466 - acc: 0.5167\n",
            "Epoch 47/100\n",
            "60/60 [==============================] - 0s 78us/step - loss: 1.0449 - acc: 0.5167\n",
            "Epoch 48/100\n",
            "60/60 [==============================] - 0s 88us/step - loss: 1.0433 - acc: 0.5167\n",
            "Epoch 49/100\n",
            "60/60 [==============================] - 0s 93us/step - loss: 1.0416 - acc: 0.5167\n",
            "Epoch 50/100\n",
            "60/60 [==============================] - 0s 90us/step - loss: 1.0400 - acc: 0.5167\n",
            "Epoch 51/100\n",
            "60/60 [==============================] - 0s 79us/step - loss: 1.0384 - acc: 0.5167\n",
            "Epoch 52/100\n",
            "60/60 [==============================] - 0s 80us/step - loss: 1.0367 - acc: 0.5167\n",
            "Epoch 53/100\n",
            "60/60 [==============================] - 0s 68us/step - loss: 1.0351 - acc: 0.5167\n",
            "Epoch 54/100\n",
            "60/60 [==============================] - 0s 65us/step - loss: 1.0335 - acc: 0.5167\n",
            "Epoch 55/100\n",
            "60/60 [==============================] - 0s 54us/step - loss: 1.0319 - acc: 0.5167\n",
            "Epoch 56/100\n",
            "60/60 [==============================] - 0s 72us/step - loss: 1.0303 - acc: 0.5167\n",
            "Epoch 57/100\n",
            "60/60 [==============================] - 0s 73us/step - loss: 1.0286 - acc: 0.5167\n",
            "Epoch 58/100\n",
            "60/60 [==============================] - 0s 74us/step - loss: 1.0270 - acc: 0.5167\n",
            "Epoch 59/100\n",
            "60/60 [==============================] - 0s 61us/step - loss: 1.0254 - acc: 0.5167\n",
            "Epoch 60/100\n",
            "60/60 [==============================] - 0s 78us/step - loss: 1.0238 - acc: 0.5167\n",
            "Epoch 61/100\n",
            "60/60 [==============================] - 0s 77us/step - loss: 1.0222 - acc: 0.5167\n",
            "Epoch 62/100\n",
            "60/60 [==============================] - 0s 64us/step - loss: 1.0206 - acc: 0.5167\n",
            "Epoch 63/100\n",
            "60/60 [==============================] - 0s 74us/step - loss: 1.0190 - acc: 0.5167\n",
            "Epoch 64/100\n",
            "60/60 [==============================] - 0s 72us/step - loss: 1.0174 - acc: 0.5167\n",
            "Epoch 65/100\n",
            "60/60 [==============================] - 0s 86us/step - loss: 1.0157 - acc: 0.5167\n",
            "Epoch 66/100\n",
            "60/60 [==============================] - 0s 76us/step - loss: 1.0141 - acc: 0.5167\n",
            "Epoch 67/100\n",
            "60/60 [==============================] - 0s 84us/step - loss: 1.0124 - acc: 0.5167\n",
            "Epoch 68/100\n",
            "60/60 [==============================] - 0s 81us/step - loss: 1.0108 - acc: 0.5167\n",
            "Epoch 69/100\n",
            "60/60 [==============================] - 0s 67us/step - loss: 1.0091 - acc: 0.5167\n",
            "Epoch 70/100\n",
            "60/60 [==============================] - 0s 116us/step - loss: 1.0074 - acc: 0.5167\n",
            "Epoch 71/100\n",
            "60/60 [==============================] - 0s 67us/step - loss: 1.0058 - acc: 0.5167\n",
            "Epoch 72/100\n",
            "60/60 [==============================] - 0s 70us/step - loss: 1.0041 - acc: 0.5167\n",
            "Epoch 73/100\n",
            "60/60 [==============================] - 0s 94us/step - loss: 1.0025 - acc: 0.5167\n",
            "Epoch 74/100\n",
            "60/60 [==============================] - 0s 66us/step - loss: 1.0009 - acc: 0.5167\n",
            "Epoch 75/100\n",
            "60/60 [==============================] - 0s 76us/step - loss: 0.9992 - acc: 0.5167\n",
            "Epoch 76/100\n",
            "60/60 [==============================] - 0s 112us/step - loss: 0.9976 - acc: 0.5167\n",
            "Epoch 77/100\n",
            "60/60 [==============================] - 0s 79us/step - loss: 0.9959 - acc: 0.5167\n",
            "Epoch 78/100\n",
            "60/60 [==============================] - 0s 85us/step - loss: 0.9943 - acc: 0.5167\n",
            "Epoch 79/100\n",
            "60/60 [==============================] - 0s 106us/step - loss: 0.9927 - acc: 0.5167\n",
            "Epoch 80/100\n",
            "60/60 [==============================] - 0s 92us/step - loss: 0.9911 - acc: 0.5167\n",
            "Epoch 81/100\n",
            "60/60 [==============================] - 0s 83us/step - loss: 0.9894 - acc: 0.5167\n",
            "Epoch 82/100\n",
            "60/60 [==============================] - 0s 160us/step - loss: 0.9878 - acc: 0.5167\n",
            "Epoch 83/100\n",
            "60/60 [==============================] - 0s 98us/step - loss: 0.9861 - acc: 0.5167\n",
            "Epoch 84/100\n",
            "60/60 [==============================] - 0s 200us/step - loss: 0.9845 - acc: 0.5167\n",
            "Epoch 85/100\n",
            "60/60 [==============================] - 0s 62us/step - loss: 0.9829 - acc: 0.5167\n",
            "Epoch 86/100\n",
            "60/60 [==============================] - 0s 227us/step - loss: 0.9813 - acc: 0.5167\n",
            "Epoch 87/100\n",
            "60/60 [==============================] - 0s 134us/step - loss: 0.9796 - acc: 0.5167\n",
            "Epoch 88/100\n",
            "60/60 [==============================] - 0s 135us/step - loss: 0.9779 - acc: 0.5167\n",
            "Epoch 89/100\n",
            "60/60 [==============================] - 0s 139us/step - loss: 0.9763 - acc: 0.5167\n",
            "Epoch 90/100\n",
            "60/60 [==============================] - 0s 141us/step - loss: 0.9746 - acc: 0.5167\n",
            "Epoch 91/100\n",
            "60/60 [==============================] - 0s 136us/step - loss: 0.9729 - acc: 0.5167\n",
            "Epoch 92/100\n",
            "60/60 [==============================] - 0s 145us/step - loss: 0.9713 - acc: 0.5167\n",
            "Epoch 93/100\n",
            "60/60 [==============================] - 0s 135us/step - loss: 0.9696 - acc: 0.5167\n",
            "Epoch 94/100\n",
            "60/60 [==============================] - 0s 139us/step - loss: 0.9680 - acc: 0.5167\n",
            "Epoch 95/100\n",
            "60/60 [==============================] - 0s 132us/step - loss: 0.9664 - acc: 0.5167\n",
            "Epoch 96/100\n",
            "60/60 [==============================] - 0s 133us/step - loss: 0.9648 - acc: 0.5167\n",
            "Epoch 97/100\n",
            "60/60 [==============================] - 0s 121us/step - loss: 0.9632 - acc: 0.5167\n",
            "Epoch 98/100\n",
            "60/60 [==============================] - 0s 70us/step - loss: 0.9616 - acc: 0.5167\n",
            "Epoch 99/100\n",
            "60/60 [==============================] - 0s 127us/step - loss: 0.9600 - acc: 0.5167\n",
            "Epoch 100/100\n",
            "60/60 [==============================] - 0s 80us/step - loss: 0.9584 - acc: 0.5167\n",
            "60/60 [==============================] - 0s 5ms/step\n",
            "\n",
            "acc: 35.00%\n",
            "[[ 0  0 21]\n",
            " [ 0  0 18]\n",
            " [ 0  0 21]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        21\n",
            "           1       0.00      0.00      0.00        18\n",
            "           2       0.35      1.00      0.52        21\n",
            "\n",
            "    accuracy                           0.35        60\n",
            "   macro avg       0.12      0.33      0.17        60\n",
            "weighted avg       0.12      0.35      0.18        60\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_89 (Dense)             (None, 10)                30        \n",
            "_________________________________________________________________\n",
            "dense_90 (Dense)             (None, 20)                220       \n",
            "_________________________________________________________________\n",
            "dense_91 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_92 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_93 (Dense)             (None, 3)                 63        \n",
            "=================================================================\n",
            "Total params: 1,153\n",
            "Trainable params: 1,153\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 1.2198 - acc: 0.3000\n",
            "Epoch 2/100\n",
            "90/90 [==============================] - 0s 74us/step - loss: 1.2118 - acc: 0.3000\n",
            "Epoch 3/100\n",
            "90/90 [==============================] - 0s 54us/step - loss: 1.2041 - acc: 0.3000\n",
            "Epoch 4/100\n",
            "90/90 [==============================] - 0s 47us/step - loss: 1.1967 - acc: 0.3000\n",
            "Epoch 5/100\n",
            "90/90 [==============================] - 0s 40us/step - loss: 1.1898 - acc: 0.3000\n",
            "Epoch 6/100\n",
            "90/90 [==============================] - 0s 56us/step - loss: 1.1832 - acc: 0.3000\n",
            "Epoch 7/100\n",
            "90/90 [==============================] - 0s 56us/step - loss: 1.1769 - acc: 0.3000\n",
            "Epoch 8/100\n",
            "90/90 [==============================] - 0s 51us/step - loss: 1.1709 - acc: 0.3000\n",
            "Epoch 9/100\n",
            "90/90 [==============================] - 0s 51us/step - loss: 1.1651 - acc: 0.3111\n",
            "Epoch 10/100\n",
            "90/90 [==============================] - 0s 46us/step - loss: 1.1596 - acc: 0.3111\n",
            "Epoch 11/100\n",
            "90/90 [==============================] - 0s 60us/step - loss: 1.1543 - acc: 0.3111\n",
            "Epoch 12/100\n",
            "90/90 [==============================] - 0s 55us/step - loss: 1.1492 - acc: 0.3111\n",
            "Epoch 13/100\n",
            "90/90 [==============================] - 0s 55us/step - loss: 1.1444 - acc: 0.3111\n",
            "Epoch 14/100\n",
            "90/90 [==============================] - 0s 59us/step - loss: 1.1398 - acc: 0.3111\n",
            "Epoch 15/100\n",
            "90/90 [==============================] - 0s 62us/step - loss: 1.1354 - acc: 0.3111\n",
            "Epoch 16/100\n",
            "90/90 [==============================] - 0s 49us/step - loss: 1.1312 - acc: 0.3111\n",
            "Epoch 17/100\n",
            "90/90 [==============================] - 0s 54us/step - loss: 1.1271 - acc: 0.3222\n",
            "Epoch 18/100\n",
            "90/90 [==============================] - 0s 59us/step - loss: 1.1232 - acc: 0.3333\n",
            "Epoch 19/100\n",
            "90/90 [==============================] - 0s 46us/step - loss: 1.1194 - acc: 0.3333\n",
            "Epoch 20/100\n",
            "90/90 [==============================] - 0s 70us/step - loss: 1.1157 - acc: 0.3333\n",
            "Epoch 21/100\n",
            "90/90 [==============================] - 0s 60us/step - loss: 1.1122 - acc: 0.3333\n",
            "Epoch 22/100\n",
            "90/90 [==============================] - 0s 49us/step - loss: 1.1088 - acc: 0.3333\n",
            "Epoch 23/100\n",
            "90/90 [==============================] - 0s 57us/step - loss: 1.1054 - acc: 0.3333\n",
            "Epoch 24/100\n",
            "90/90 [==============================] - 0s 50us/step - loss: 1.1022 - acc: 0.3444\n",
            "Epoch 25/100\n",
            "90/90 [==============================] - 0s 61us/step - loss: 1.0990 - acc: 0.3556\n",
            "Epoch 26/100\n",
            "90/90 [==============================] - 0s 64us/step - loss: 1.0959 - acc: 0.3556\n",
            "Epoch 27/100\n",
            "90/90 [==============================] - 0s 56us/step - loss: 1.0929 - acc: 0.3556\n",
            "Epoch 28/100\n",
            "90/90 [==============================] - 0s 63us/step - loss: 1.0899 - acc: 0.3556\n",
            "Epoch 29/100\n",
            "90/90 [==============================] - 0s 56us/step - loss: 1.0869 - acc: 0.3556\n",
            "Epoch 30/100\n",
            "90/90 [==============================] - 0s 59us/step - loss: 1.0840 - acc: 0.3556\n",
            "Epoch 31/100\n",
            "90/90 [==============================] - 0s 74us/step - loss: 1.0811 - acc: 0.3444\n",
            "Epoch 32/100\n",
            "90/90 [==============================] - 0s 114us/step - loss: 1.0783 - acc: 0.3556\n",
            "Epoch 33/100\n",
            "90/90 [==============================] - 0s 75us/step - loss: 1.0756 - acc: 0.3444\n",
            "Epoch 34/100\n",
            "90/90 [==============================] - 0s 67us/step - loss: 1.0730 - acc: 0.3444\n",
            "Epoch 35/100\n",
            "90/90 [==============================] - 0s 73us/step - loss: 1.0704 - acc: 0.3444\n",
            "Epoch 36/100\n",
            "90/90 [==============================] - 0s 85us/step - loss: 1.0678 - acc: 0.3556\n",
            "Epoch 37/100\n",
            "90/90 [==============================] - 0s 70us/step - loss: 1.0653 - acc: 0.3667\n",
            "Epoch 38/100\n",
            "90/90 [==============================] - 0s 70us/step - loss: 1.0629 - acc: 0.3667\n",
            "Epoch 39/100\n",
            "90/90 [==============================] - 0s 48us/step - loss: 1.0605 - acc: 0.3778\n",
            "Epoch 40/100\n",
            "90/90 [==============================] - 0s 55us/step - loss: 1.0581 - acc: 0.3889\n",
            "Epoch 41/100\n",
            "90/90 [==============================] - 0s 55us/step - loss: 1.0558 - acc: 0.3889\n",
            "Epoch 42/100\n",
            "90/90 [==============================] - 0s 73us/step - loss: 1.0536 - acc: 0.3778\n",
            "Epoch 43/100\n",
            "90/90 [==============================] - 0s 55us/step - loss: 1.0515 - acc: 0.3889\n",
            "Epoch 44/100\n",
            "90/90 [==============================] - 0s 64us/step - loss: 1.0495 - acc: 0.3889\n",
            "Epoch 45/100\n",
            "90/90 [==============================] - 0s 67us/step - loss: 1.0474 - acc: 0.3889\n",
            "Epoch 46/100\n",
            "90/90 [==============================] - 0s 78us/step - loss: 1.0454 - acc: 0.3889\n",
            "Epoch 47/100\n",
            "90/90 [==============================] - 0s 72us/step - loss: 1.0435 - acc: 0.3889\n",
            "Epoch 48/100\n",
            "90/90 [==============================] - 0s 72us/step - loss: 1.0415 - acc: 0.4111\n",
            "Epoch 49/100\n",
            "90/90 [==============================] - 0s 75us/step - loss: 1.0395 - acc: 0.4111\n",
            "Epoch 50/100\n",
            "90/90 [==============================] - 0s 67us/step - loss: 1.0376 - acc: 0.4111\n",
            "Epoch 51/100\n",
            "90/90 [==============================] - 0s 65us/step - loss: 1.0357 - acc: 0.4222\n",
            "Epoch 52/100\n",
            "90/90 [==============================] - 0s 66us/step - loss: 1.0338 - acc: 0.4222\n",
            "Epoch 53/100\n",
            "90/90 [==============================] - 0s 72us/step - loss: 1.0320 - acc: 0.4333\n",
            "Epoch 54/100\n",
            "90/90 [==============================] - 0s 58us/step - loss: 1.0303 - acc: 0.4333\n",
            "Epoch 55/100\n",
            "90/90 [==============================] - 0s 57us/step - loss: 1.0286 - acc: 0.4333\n",
            "Epoch 56/100\n",
            "90/90 [==============================] - 0s 65us/step - loss: 1.0269 - acc: 0.4333\n",
            "Epoch 57/100\n",
            "90/90 [==============================] - 0s 58us/step - loss: 1.0252 - acc: 0.4333\n",
            "Epoch 58/100\n",
            "90/90 [==============================] - 0s 74us/step - loss: 1.0236 - acc: 0.4333\n",
            "Epoch 59/100\n",
            "90/90 [==============================] - 0s 50us/step - loss: 1.0220 - acc: 0.4556\n",
            "Epoch 60/100\n",
            "90/90 [==============================] - 0s 66us/step - loss: 1.0204 - acc: 0.4556\n",
            "Epoch 61/100\n",
            "90/90 [==============================] - 0s 74us/step - loss: 1.0188 - acc: 0.4556\n",
            "Epoch 62/100\n",
            "90/90 [==============================] - 0s 45us/step - loss: 1.0172 - acc: 0.4556\n",
            "Epoch 63/100\n",
            "90/90 [==============================] - 0s 64us/step - loss: 1.0157 - acc: 0.4556\n",
            "Epoch 64/100\n",
            "90/90 [==============================] - 0s 56us/step - loss: 1.0142 - acc: 0.4556\n",
            "Epoch 65/100\n",
            "90/90 [==============================] - 0s 62us/step - loss: 1.0127 - acc: 0.4556\n",
            "Epoch 66/100\n",
            "90/90 [==============================] - 0s 83us/step - loss: 1.0113 - acc: 0.4556\n",
            "Epoch 67/100\n",
            "90/90 [==============================] - 0s 51us/step - loss: 1.0099 - acc: 0.4556\n",
            "Epoch 68/100\n",
            "90/90 [==============================] - 0s 75us/step - loss: 1.0084 - acc: 0.4667\n",
            "Epoch 69/100\n",
            "90/90 [==============================] - 0s 42us/step - loss: 1.0071 - acc: 0.4778\n",
            "Epoch 70/100\n",
            "90/90 [==============================] - 0s 50us/step - loss: 1.0057 - acc: 0.4778\n",
            "Epoch 71/100\n",
            "90/90 [==============================] - 0s 90us/step - loss: 1.0043 - acc: 0.4889\n",
            "Epoch 72/100\n",
            "90/90 [==============================] - 0s 96us/step - loss: 1.0030 - acc: 0.4889\n",
            "Epoch 73/100\n",
            "90/90 [==============================] - 0s 89us/step - loss: 1.0017 - acc: 0.5000\n",
            "Epoch 74/100\n",
            "90/90 [==============================] - 0s 89us/step - loss: 1.0004 - acc: 0.5111\n",
            "Epoch 75/100\n",
            "90/90 [==============================] - 0s 76us/step - loss: 0.9992 - acc: 0.5333\n",
            "Epoch 76/100\n",
            "90/90 [==============================] - 0s 54us/step - loss: 0.9979 - acc: 0.5444\n",
            "Epoch 77/100\n",
            "90/90 [==============================] - 0s 71us/step - loss: 0.9967 - acc: 0.5444\n",
            "Epoch 78/100\n",
            "90/90 [==============================] - 0s 58us/step - loss: 0.9955 - acc: 0.5444\n",
            "Epoch 79/100\n",
            "90/90 [==============================] - 0s 69us/step - loss: 0.9943 - acc: 0.5556\n",
            "Epoch 80/100\n",
            "90/90 [==============================] - 0s 69us/step - loss: 0.9931 - acc: 0.5556\n",
            "Epoch 81/100\n",
            "90/90 [==============================] - 0s 38us/step - loss: 0.9919 - acc: 0.5556\n",
            "Epoch 82/100\n",
            "90/90 [==============================] - 0s 69us/step - loss: 0.9907 - acc: 0.5556\n",
            "Epoch 83/100\n",
            "90/90 [==============================] - 0s 54us/step - loss: 0.9895 - acc: 0.5556\n",
            "Epoch 84/100\n",
            "90/90 [==============================] - 0s 92us/step - loss: 0.9884 - acc: 0.5556\n",
            "Epoch 85/100\n",
            "90/90 [==============================] - 0s 54us/step - loss: 0.9872 - acc: 0.5556\n",
            "Epoch 86/100\n",
            "90/90 [==============================] - 0s 75us/step - loss: 0.9860 - acc: 0.5667\n",
            "Epoch 87/100\n",
            "90/90 [==============================] - 0s 80us/step - loss: 0.9848 - acc: 0.5667\n",
            "Epoch 88/100\n",
            "90/90 [==============================] - 0s 47us/step - loss: 0.9837 - acc: 0.5889\n",
            "Epoch 89/100\n",
            "90/90 [==============================] - 0s 52us/step - loss: 0.9826 - acc: 0.6000\n",
            "Epoch 90/100\n",
            "90/90 [==============================] - 0s 69us/step - loss: 0.9815 - acc: 0.6111\n",
            "Epoch 91/100\n",
            "90/90 [==============================] - 0s 75us/step - loss: 0.9803 - acc: 0.6111\n",
            "Epoch 92/100\n",
            "90/90 [==============================] - 0s 62us/step - loss: 0.9792 - acc: 0.6111\n",
            "Epoch 93/100\n",
            "90/90 [==============================] - 0s 63us/step - loss: 0.9782 - acc: 0.6111\n",
            "Epoch 94/100\n",
            "90/90 [==============================] - 0s 62us/step - loss: 0.9771 - acc: 0.6222\n",
            "Epoch 95/100\n",
            "90/90 [==============================] - 0s 53us/step - loss: 0.9760 - acc: 0.6222\n",
            "Epoch 96/100\n",
            "90/90 [==============================] - 0s 53us/step - loss: 0.9750 - acc: 0.6333\n",
            "Epoch 97/100\n",
            "90/90 [==============================] - 0s 56us/step - loss: 0.9739 - acc: 0.6222\n",
            "Epoch 98/100\n",
            "90/90 [==============================] - 0s 58us/step - loss: 0.9729 - acc: 0.6222\n",
            "Epoch 99/100\n",
            "90/90 [==============================] - 0s 45us/step - loss: 0.9718 - acc: 0.6222\n",
            "Epoch 100/100\n",
            "90/90 [==============================] - 0s 74us/step - loss: 0.9708 - acc: 0.6444\n",
            "60/60 [==============================] - 0s 5ms/step\n",
            "\n",
            "acc: 55.00%\n",
            "[[17  1  2]\n",
            " [11  6  0]\n",
            " [ 8  5 10]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.85      0.61        20\n",
            "           1       0.50      0.35      0.41        17\n",
            "           2       0.83      0.43      0.57        23\n",
            "\n",
            "    accuracy                           0.55        60\n",
            "   macro avg       0.60      0.55      0.53        60\n",
            "weighted avg       0.62      0.55      0.54        60\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_94 (Dense)             (None, 10)                30        \n",
            "_________________________________________________________________\n",
            "dense_95 (Dense)             (None, 20)                220       \n",
            "_________________________________________________________________\n",
            "dense_96 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_97 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_98 (Dense)             (None, 3)                 63        \n",
            "=================================================================\n",
            "Total params: 1,153\n",
            "Trainable params: 1,153\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 1.0976 - acc: 0.2667\n",
            "Epoch 2/100\n",
            "120/120 [==============================] - 0s 87us/step - loss: 1.0965 - acc: 0.3167\n",
            "Epoch 3/100\n",
            "120/120 [==============================] - 0s 86us/step - loss: 1.0954 - acc: 0.3167\n",
            "Epoch 4/100\n",
            "120/120 [==============================] - 0s 90us/step - loss: 1.0945 - acc: 0.3083\n",
            "Epoch 5/100\n",
            "120/120 [==============================] - 0s 97us/step - loss: 1.0934 - acc: 0.3917\n",
            "Epoch 6/100\n",
            "120/120 [==============================] - 0s 94us/step - loss: 1.0924 - acc: 0.4000\n",
            "Epoch 7/100\n",
            "120/120 [==============================] - 0s 99us/step - loss: 1.0915 - acc: 0.4417\n",
            "Epoch 8/100\n",
            "120/120 [==============================] - 0s 95us/step - loss: 1.0906 - acc: 0.4667\n",
            "Epoch 9/100\n",
            "120/120 [==============================] - 0s 100us/step - loss: 1.0897 - acc: 0.4500\n",
            "Epoch 10/100\n",
            "120/120 [==============================] - 0s 100us/step - loss: 1.0888 - acc: 0.4667\n",
            "Epoch 11/100\n",
            "120/120 [==============================] - 0s 91us/step - loss: 1.0879 - acc: 0.4667\n",
            "Epoch 12/100\n",
            "120/120 [==============================] - 0s 91us/step - loss: 1.0870 - acc: 0.4667\n",
            "Epoch 13/100\n",
            "120/120 [==============================] - 0s 84us/step - loss: 1.0861 - acc: 0.4667\n",
            "Epoch 14/100\n",
            "120/120 [==============================] - 0s 93us/step - loss: 1.0851 - acc: 0.4667\n",
            "Epoch 15/100\n",
            "120/120 [==============================] - 0s 82us/step - loss: 1.0843 - acc: 0.4833\n",
            "Epoch 16/100\n",
            "120/120 [==============================] - 0s 72us/step - loss: 1.0834 - acc: 0.5333\n",
            "Epoch 17/100\n",
            "120/120 [==============================] - 0s 79us/step - loss: 1.0826 - acc: 0.5500\n",
            "Epoch 18/100\n",
            "120/120 [==============================] - 0s 92us/step - loss: 1.0819 - acc: 0.5500\n",
            "Epoch 19/100\n",
            "120/120 [==============================] - 0s 110us/step - loss: 1.0811 - acc: 0.5167\n",
            "Epoch 20/100\n",
            "120/120 [==============================] - 0s 88us/step - loss: 1.0802 - acc: 0.5417\n",
            "Epoch 21/100\n",
            "120/120 [==============================] - 0s 89us/step - loss: 1.0794 - acc: 0.5583\n",
            "Epoch 22/100\n",
            "120/120 [==============================] - 0s 91us/step - loss: 1.0785 - acc: 0.5750\n",
            "Epoch 23/100\n",
            "120/120 [==============================] - 0s 85us/step - loss: 1.0776 - acc: 0.5750\n",
            "Epoch 24/100\n",
            "120/120 [==============================] - 0s 104us/step - loss: 1.0767 - acc: 0.5917\n",
            "Epoch 25/100\n",
            "120/120 [==============================] - 0s 80us/step - loss: 1.0758 - acc: 0.5917\n",
            "Epoch 26/100\n",
            "120/120 [==============================] - 0s 93us/step - loss: 1.0749 - acc: 0.5917\n",
            "Epoch 27/100\n",
            "120/120 [==============================] - 0s 108us/step - loss: 1.0739 - acc: 0.5917\n",
            "Epoch 28/100\n",
            "120/120 [==============================] - 0s 91us/step - loss: 1.0731 - acc: 0.5833\n",
            "Epoch 29/100\n",
            "120/120 [==============================] - 0s 86us/step - loss: 1.0721 - acc: 0.5833\n",
            "Epoch 30/100\n",
            "120/120 [==============================] - 0s 77us/step - loss: 1.0711 - acc: 0.5833\n",
            "Epoch 31/100\n",
            "120/120 [==============================] - 0s 81us/step - loss: 1.0701 - acc: 0.5833\n",
            "Epoch 32/100\n",
            "120/120 [==============================] - 0s 72us/step - loss: 1.0690 - acc: 0.5917\n",
            "Epoch 33/100\n",
            "120/120 [==============================] - 0s 106us/step - loss: 1.0679 - acc: 0.6167\n",
            "Epoch 34/100\n",
            "120/120 [==============================] - 0s 87us/step - loss: 1.0669 - acc: 0.6083\n",
            "Epoch 35/100\n",
            "120/120 [==============================] - 0s 102us/step - loss: 1.0659 - acc: 0.6000\n",
            "Epoch 36/100\n",
            "120/120 [==============================] - 0s 92us/step - loss: 1.0650 - acc: 0.5917\n",
            "Epoch 37/100\n",
            "120/120 [==============================] - 0s 92us/step - loss: 1.0638 - acc: 0.6000\n",
            "Epoch 38/100\n",
            "120/120 [==============================] - 0s 99us/step - loss: 1.0626 - acc: 0.5917\n",
            "Epoch 39/100\n",
            "120/120 [==============================] - 0s 97us/step - loss: 1.0615 - acc: 0.6167\n",
            "Epoch 40/100\n",
            "120/120 [==============================] - 0s 86us/step - loss: 1.0604 - acc: 0.6167\n",
            "Epoch 41/100\n",
            "120/120 [==============================] - 0s 112us/step - loss: 1.0593 - acc: 0.6250\n",
            "Epoch 42/100\n",
            "120/120 [==============================] - 0s 71us/step - loss: 1.0582 - acc: 0.6250\n",
            "Epoch 43/100\n",
            "120/120 [==============================] - 0s 96us/step - loss: 1.0571 - acc: 0.6333\n",
            "Epoch 44/100\n",
            "120/120 [==============================] - 0s 87us/step - loss: 1.0560 - acc: 0.6500\n",
            "Epoch 45/100\n",
            "120/120 [==============================] - 0s 83us/step - loss: 1.0549 - acc: 0.6833\n",
            "Epoch 46/100\n",
            "120/120 [==============================] - 0s 82us/step - loss: 1.0538 - acc: 0.6667\n",
            "Epoch 47/100\n",
            "120/120 [==============================] - 0s 82us/step - loss: 1.0527 - acc: 0.6833\n",
            "Epoch 48/100\n",
            "120/120 [==============================] - 0s 80us/step - loss: 1.0514 - acc: 0.6917\n",
            "Epoch 49/100\n",
            "120/120 [==============================] - 0s 83us/step - loss: 1.0504 - acc: 0.6917\n",
            "Epoch 50/100\n",
            "120/120 [==============================] - 0s 91us/step - loss: 1.0496 - acc: 0.6833\n",
            "Epoch 51/100\n",
            "120/120 [==============================] - 0s 85us/step - loss: 1.0487 - acc: 0.6917\n",
            "Epoch 52/100\n",
            "120/120 [==============================] - 0s 112us/step - loss: 1.0475 - acc: 0.6917\n",
            "Epoch 53/100\n",
            "120/120 [==============================] - 0s 98us/step - loss: 1.0466 - acc: 0.6833\n",
            "Epoch 54/100\n",
            "120/120 [==============================] - 0s 120us/step - loss: 1.0453 - acc: 0.7250\n",
            "Epoch 55/100\n",
            "120/120 [==============================] - 0s 140us/step - loss: 1.0443 - acc: 0.7083\n",
            "Epoch 56/100\n",
            "120/120 [==============================] - 0s 127us/step - loss: 1.0432 - acc: 0.7500\n",
            "Epoch 57/100\n",
            "120/120 [==============================] - 0s 130us/step - loss: 1.0423 - acc: 0.7500\n",
            "Epoch 58/100\n",
            "120/120 [==============================] - 0s 79us/step - loss: 1.0412 - acc: 0.7500\n",
            "Epoch 59/100\n",
            "120/120 [==============================] - 0s 116us/step - loss: 1.0401 - acc: 0.7500\n",
            "Epoch 60/100\n",
            "120/120 [==============================] - 0s 79us/step - loss: 1.0391 - acc: 0.7500\n",
            "Epoch 61/100\n",
            "120/120 [==============================] - 0s 100us/step - loss: 1.0381 - acc: 0.7500\n",
            "Epoch 62/100\n",
            "120/120 [==============================] - 0s 165us/step - loss: 1.0371 - acc: 0.7583\n",
            "Epoch 63/100\n",
            "120/120 [==============================] - 0s 134us/step - loss: 1.0360 - acc: 0.7750\n",
            "Epoch 64/100\n",
            "120/120 [==============================] - 0s 118us/step - loss: 1.0349 - acc: 0.7833\n",
            "Epoch 65/100\n",
            "120/120 [==============================] - 0s 116us/step - loss: 1.0338 - acc: 0.8000\n",
            "Epoch 66/100\n",
            "120/120 [==============================] - 0s 114us/step - loss: 1.0327 - acc: 0.8000\n",
            "Epoch 67/100\n",
            "120/120 [==============================] - 0s 98us/step - loss: 1.0316 - acc: 0.7833\n",
            "Epoch 68/100\n",
            "120/120 [==============================] - 0s 120us/step - loss: 1.0306 - acc: 0.7833\n",
            "Epoch 69/100\n",
            "120/120 [==============================] - 0s 102us/step - loss: 1.0295 - acc: 0.7833\n",
            "Epoch 70/100\n",
            "120/120 [==============================] - 0s 89us/step - loss: 1.0285 - acc: 0.7833\n",
            "Epoch 71/100\n",
            "120/120 [==============================] - 0s 89us/step - loss: 1.0273 - acc: 0.7917\n",
            "Epoch 72/100\n",
            "120/120 [==============================] - 0s 97us/step - loss: 1.0262 - acc: 0.7917\n",
            "Epoch 73/100\n",
            "120/120 [==============================] - 0s 90us/step - loss: 1.0250 - acc: 0.7917\n",
            "Epoch 74/100\n",
            "120/120 [==============================] - 0s 89us/step - loss: 1.0239 - acc: 0.7833\n",
            "Epoch 75/100\n",
            "120/120 [==============================] - 0s 89us/step - loss: 1.0227 - acc: 0.7667\n",
            "Epoch 76/100\n",
            "120/120 [==============================] - 0s 102us/step - loss: 1.0216 - acc: 0.7833\n",
            "Epoch 77/100\n",
            "120/120 [==============================] - 0s 86us/step - loss: 1.0204 - acc: 0.8000\n",
            "Epoch 78/100\n",
            "120/120 [==============================] - 0s 89us/step - loss: 1.0190 - acc: 0.7917\n",
            "Epoch 79/100\n",
            "120/120 [==============================] - 0s 103us/step - loss: 1.0178 - acc: 0.8000\n",
            "Epoch 80/100\n",
            "120/120 [==============================] - 0s 92us/step - loss: 1.0166 - acc: 0.8000\n",
            "Epoch 81/100\n",
            "120/120 [==============================] - 0s 98us/step - loss: 1.0152 - acc: 0.8250\n",
            "Epoch 82/100\n",
            "120/120 [==============================] - 0s 139us/step - loss: 1.0139 - acc: 0.8250\n",
            "Epoch 83/100\n",
            "120/120 [==============================] - 0s 98us/step - loss: 1.0127 - acc: 0.8250\n",
            "Epoch 84/100\n",
            "120/120 [==============================] - 0s 98us/step - loss: 1.0114 - acc: 0.8333\n",
            "Epoch 85/100\n",
            "120/120 [==============================] - 0s 87us/step - loss: 1.0103 - acc: 0.8333\n",
            "Epoch 86/100\n",
            "120/120 [==============================] - 0s 101us/step - loss: 1.0092 - acc: 0.8333\n",
            "Epoch 87/100\n",
            "120/120 [==============================] - 0s 106us/step - loss: 1.0079 - acc: 0.8167\n",
            "Epoch 88/100\n",
            "120/120 [==============================] - 0s 84us/step - loss: 1.0067 - acc: 0.8333\n",
            "Epoch 89/100\n",
            "120/120 [==============================] - 0s 90us/step - loss: 1.0055 - acc: 0.8333\n",
            "Epoch 90/100\n",
            "120/120 [==============================] - 0s 90us/step - loss: 1.0041 - acc: 0.8500\n",
            "Epoch 91/100\n",
            "120/120 [==============================] - 0s 104us/step - loss: 1.0027 - acc: 0.8500\n",
            "Epoch 92/100\n",
            "120/120 [==============================] - 0s 149us/step - loss: 1.0012 - acc: 0.8500\n",
            "Epoch 93/100\n",
            "120/120 [==============================] - 0s 103us/step - loss: 1.0000 - acc: 0.8500\n",
            "Epoch 94/100\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.9987 - acc: 0.8500\n",
            "Epoch 95/100\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.9971 - acc: 0.8500\n",
            "Epoch 96/100\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.9957 - acc: 0.8500\n",
            "Epoch 97/100\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.9944 - acc: 0.8500\n",
            "Epoch 98/100\n",
            "120/120 [==============================] - 0s 77us/step - loss: 0.9929 - acc: 0.8583\n",
            "Epoch 99/100\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.9915 - acc: 0.8583\n",
            "Epoch 100/100\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.9901 - acc: 0.8583\n",
            "60/60 [==============================] - 0s 5ms/step\n",
            "\n",
            "acc: 81.67%\n",
            "[[13  0  0]\n",
            " [ 4 22  1]\n",
            " [ 4  2 14]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      1.00      0.76        13\n",
            "           1       0.92      0.81      0.86        27\n",
            "           2       0.93      0.70      0.80        20\n",
            "\n",
            "    accuracy                           0.82        60\n",
            "   macro avg       0.82      0.84      0.81        60\n",
            "weighted avg       0.86      0.82      0.82        60\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_99 (Dense)             (None, 10)                30        \n",
            "_________________________________________________________________\n",
            "dense_100 (Dense)            (None, 20)                220       \n",
            "_________________________________________________________________\n",
            "dense_101 (Dense)            (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_102 (Dense)            (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_103 (Dense)            (None, 3)                 63        \n",
            "=================================================================\n",
            "Total params: 1,153\n",
            "Trainable params: 1,153\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "150/150 [==============================] - 1s 6ms/step - loss: 1.1828 - acc: 0.4067\n",
            "Epoch 2/100\n",
            "150/150 [==============================] - 0s 92us/step - loss: 1.1676 - acc: 0.4067\n",
            "Epoch 3/100\n",
            "150/150 [==============================] - 0s 72us/step - loss: 1.1525 - acc: 0.4067\n",
            "Epoch 4/100\n",
            "150/150 [==============================] - 0s 82us/step - loss: 1.1384 - acc: 0.4067\n",
            "Epoch 5/100\n",
            "150/150 [==============================] - 0s 75us/step - loss: 1.1250 - acc: 0.4067\n",
            "Epoch 6/100\n",
            "150/150 [==============================] - 0s 68us/step - loss: 1.1120 - acc: 0.4067\n",
            "Epoch 7/100\n",
            "150/150 [==============================] - 0s 71us/step - loss: 1.0992 - acc: 0.4067\n",
            "Epoch 8/100\n",
            "150/150 [==============================] - 0s 83us/step - loss: 1.0870 - acc: 0.4067\n",
            "Epoch 9/100\n",
            "150/150 [==============================] - 0s 63us/step - loss: 1.0755 - acc: 0.4067\n",
            "Epoch 10/100\n",
            "150/150 [==============================] - 0s 58us/step - loss: 1.0646 - acc: 0.4067\n",
            "Epoch 11/100\n",
            "150/150 [==============================] - 0s 67us/step - loss: 1.0546 - acc: 0.4067\n",
            "Epoch 12/100\n",
            "150/150 [==============================] - 0s 81us/step - loss: 1.0448 - acc: 0.4067\n",
            "Epoch 13/100\n",
            "150/150 [==============================] - 0s 70us/step - loss: 1.0352 - acc: 0.4067\n",
            "Epoch 14/100\n",
            "150/150 [==============================] - 0s 79us/step - loss: 1.0261 - acc: 0.4067\n",
            "Epoch 15/100\n",
            "150/150 [==============================] - 0s 67us/step - loss: 1.0173 - acc: 0.4067\n",
            "Epoch 16/100\n",
            "150/150 [==============================] - 0s 65us/step - loss: 1.0084 - acc: 0.4067\n",
            "Epoch 17/100\n",
            "150/150 [==============================] - 0s 74us/step - loss: 1.0002 - acc: 0.4067\n",
            "Epoch 18/100\n",
            "150/150 [==============================] - 0s 75us/step - loss: 0.9921 - acc: 0.4067\n",
            "Epoch 19/100\n",
            "150/150 [==============================] - 0s 73us/step - loss: 0.9843 - acc: 0.4067\n",
            "Epoch 20/100\n",
            "150/150 [==============================] - 0s 75us/step - loss: 0.9769 - acc: 0.4067\n",
            "Epoch 21/100\n",
            "150/150 [==============================] - 0s 90us/step - loss: 0.9700 - acc: 0.4067\n",
            "Epoch 22/100\n",
            "150/150 [==============================] - 0s 67us/step - loss: 0.9632 - acc: 0.4067\n",
            "Epoch 23/100\n",
            "150/150 [==============================] - 0s 140us/step - loss: 0.9563 - acc: 0.4067\n",
            "Epoch 24/100\n",
            "150/150 [==============================] - 0s 80us/step - loss: 0.9497 - acc: 0.4067\n",
            "Epoch 25/100\n",
            "150/150 [==============================] - 0s 81us/step - loss: 0.9434 - acc: 0.4600\n",
            "Epoch 26/100\n",
            "150/150 [==============================] - 0s 84us/step - loss: 0.9373 - acc: 0.4800\n",
            "Epoch 27/100\n",
            "150/150 [==============================] - 0s 91us/step - loss: 0.9311 - acc: 0.5133\n",
            "Epoch 28/100\n",
            "150/150 [==============================] - 0s 78us/step - loss: 0.9250 - acc: 0.5333\n",
            "Epoch 29/100\n",
            "150/150 [==============================] - 0s 75us/step - loss: 0.9191 - acc: 0.5533\n",
            "Epoch 30/100\n",
            "150/150 [==============================] - 0s 75us/step - loss: 0.9134 - acc: 0.5667\n",
            "Epoch 31/100\n",
            "150/150 [==============================] - 0s 61us/step - loss: 0.9079 - acc: 0.5867\n",
            "Epoch 32/100\n",
            "150/150 [==============================] - 0s 63us/step - loss: 0.9022 - acc: 0.6000\n",
            "Epoch 33/100\n",
            "150/150 [==============================] - 0s 98us/step - loss: 0.8967 - acc: 0.6267\n",
            "Epoch 34/100\n",
            "150/150 [==============================] - 0s 78us/step - loss: 0.8914 - acc: 0.6333\n",
            "Epoch 35/100\n",
            "150/150 [==============================] - 0s 76us/step - loss: 0.8863 - acc: 0.6400\n",
            "Epoch 36/100\n",
            "150/150 [==============================] - 0s 62us/step - loss: 0.8811 - acc: 0.6400\n",
            "Epoch 37/100\n",
            "150/150 [==============================] - 0s 85us/step - loss: 0.8761 - acc: 0.6400\n",
            "Epoch 38/100\n",
            "150/150 [==============================] - 0s 70us/step - loss: 0.8713 - acc: 0.6533\n",
            "Epoch 39/100\n",
            "150/150 [==============================] - 0s 76us/step - loss: 0.8665 - acc: 0.6533\n",
            "Epoch 40/100\n",
            "150/150 [==============================] - 0s 68us/step - loss: 0.8618 - acc: 0.6533\n",
            "Epoch 41/100\n",
            "150/150 [==============================] - 0s 63us/step - loss: 0.8574 - acc: 0.6533\n",
            "Epoch 42/100\n",
            "150/150 [==============================] - 0s 82us/step - loss: 0.8528 - acc: 0.6533\n",
            "Epoch 43/100\n",
            "150/150 [==============================] - 0s 76us/step - loss: 0.8483 - acc: 0.6533\n",
            "Epoch 44/100\n",
            "150/150 [==============================] - 0s 80us/step - loss: 0.8441 - acc: 0.6533\n",
            "Epoch 45/100\n",
            "150/150 [==============================] - 0s 82us/step - loss: 0.8396 - acc: 0.6533\n",
            "Epoch 46/100\n",
            "150/150 [==============================] - 0s 100us/step - loss: 0.8354 - acc: 0.6533\n",
            "Epoch 47/100\n",
            "150/150 [==============================] - 0s 75us/step - loss: 0.8314 - acc: 0.6533\n",
            "Epoch 48/100\n",
            "150/150 [==============================] - 0s 79us/step - loss: 0.8274 - acc: 0.6533\n",
            "Epoch 49/100\n",
            "150/150 [==============================] - 0s 78us/step - loss: 0.8235 - acc: 0.6600\n",
            "Epoch 50/100\n",
            "150/150 [==============================] - 0s 77us/step - loss: 0.8196 - acc: 0.6667\n",
            "Epoch 51/100\n",
            "150/150 [==============================] - 0s 86us/step - loss: 0.8157 - acc: 0.6667\n",
            "Epoch 52/100\n",
            "150/150 [==============================] - 0s 88us/step - loss: 0.8120 - acc: 0.6667\n",
            "Epoch 53/100\n",
            "150/150 [==============================] - 0s 134us/step - loss: 0.8084 - acc: 0.6667\n",
            "Epoch 54/100\n",
            "150/150 [==============================] - 0s 75us/step - loss: 0.8049 - acc: 0.6667\n",
            "Epoch 55/100\n",
            "150/150 [==============================] - 0s 63us/step - loss: 0.8014 - acc: 0.6667\n",
            "Epoch 56/100\n",
            "150/150 [==============================] - 0s 67us/step - loss: 0.7980 - acc: 0.6733\n",
            "Epoch 57/100\n",
            "150/150 [==============================] - 0s 72us/step - loss: 0.7947 - acc: 0.6733\n",
            "Epoch 58/100\n",
            "150/150 [==============================] - 0s 62us/step - loss: 0.7915 - acc: 0.6733\n",
            "Epoch 59/100\n",
            "150/150 [==============================] - 0s 73us/step - loss: 0.7884 - acc: 0.6800\n",
            "Epoch 60/100\n",
            "150/150 [==============================] - 0s 69us/step - loss: 0.7852 - acc: 0.6800\n",
            "Epoch 61/100\n",
            "150/150 [==============================] - 0s 71us/step - loss: 0.7822 - acc: 0.6800\n",
            "Epoch 62/100\n",
            "150/150 [==============================] - 0s 74us/step - loss: 0.7791 - acc: 0.6800\n",
            "Epoch 63/100\n",
            "150/150 [==============================] - 0s 67us/step - loss: 0.7762 - acc: 0.6800\n",
            "Epoch 64/100\n",
            "150/150 [==============================] - 0s 61us/step - loss: 0.7732 - acc: 0.6800\n",
            "Epoch 65/100\n",
            "150/150 [==============================] - 0s 82us/step - loss: 0.7703 - acc: 0.6800\n",
            "Epoch 66/100\n",
            "150/150 [==============================] - 0s 60us/step - loss: 0.7675 - acc: 0.6800\n",
            "Epoch 67/100\n",
            "150/150 [==============================] - 0s 61us/step - loss: 0.7647 - acc: 0.6800\n",
            "Epoch 68/100\n",
            "150/150 [==============================] - 0s 73us/step - loss: 0.7621 - acc: 0.6800\n",
            "Epoch 69/100\n",
            "150/150 [==============================] - 0s 74us/step - loss: 0.7595 - acc: 0.6800\n",
            "Epoch 70/100\n",
            "150/150 [==============================] - 0s 63us/step - loss: 0.7569 - acc: 0.6800\n",
            "Epoch 71/100\n",
            "150/150 [==============================] - 0s 68us/step - loss: 0.7543 - acc: 0.6800\n",
            "Epoch 72/100\n",
            "150/150 [==============================] - 0s 67us/step - loss: 0.7517 - acc: 0.6800\n",
            "Epoch 73/100\n",
            "150/150 [==============================] - 0s 67us/step - loss: 0.7493 - acc: 0.6867\n",
            "Epoch 74/100\n",
            "150/150 [==============================] - 0s 71us/step - loss: 0.7468 - acc: 0.6867\n",
            "Epoch 75/100\n",
            "150/150 [==============================] - 0s 66us/step - loss: 0.7444 - acc: 0.6867\n",
            "Epoch 76/100\n",
            "150/150 [==============================] - 0s 59us/step - loss: 0.7420 - acc: 0.6867\n",
            "Epoch 77/100\n",
            "150/150 [==============================] - 0s 61us/step - loss: 0.7397 - acc: 0.6867\n",
            "Epoch 78/100\n",
            "150/150 [==============================] - 0s 94us/step - loss: 0.7375 - acc: 0.6867\n",
            "Epoch 79/100\n",
            "150/150 [==============================] - 0s 78us/step - loss: 0.7352 - acc: 0.6867\n",
            "Epoch 80/100\n",
            "150/150 [==============================] - 0s 84us/step - loss: 0.7330 - acc: 0.6867\n",
            "Epoch 81/100\n",
            "150/150 [==============================] - 0s 75us/step - loss: 0.7310 - acc: 0.6867\n",
            "Epoch 82/100\n",
            "150/150 [==============================] - 0s 72us/step - loss: 0.7288 - acc: 0.6867\n",
            "Epoch 83/100\n",
            "150/150 [==============================] - 0s 123us/step - loss: 0.7268 - acc: 0.6867\n",
            "Epoch 84/100\n",
            "150/150 [==============================] - 0s 86us/step - loss: 0.7247 - acc: 0.6867\n",
            "Epoch 85/100\n",
            "150/150 [==============================] - 0s 80us/step - loss: 0.7227 - acc: 0.6933\n",
            "Epoch 86/100\n",
            "150/150 [==============================] - 0s 68us/step - loss: 0.7207 - acc: 0.6933\n",
            "Epoch 87/100\n",
            "150/150 [==============================] - 0s 65us/step - loss: 0.7187 - acc: 0.6933\n",
            "Epoch 88/100\n",
            "150/150 [==============================] - 0s 68us/step - loss: 0.7168 - acc: 0.6933\n",
            "Epoch 89/100\n",
            "150/150 [==============================] - 0s 73us/step - loss: 0.7149 - acc: 0.6933\n",
            "Epoch 90/100\n",
            "150/150 [==============================] - 0s 72us/step - loss: 0.7130 - acc: 0.6933\n",
            "Epoch 91/100\n",
            "150/150 [==============================] - 0s 62us/step - loss: 0.7111 - acc: 0.6933\n",
            "Epoch 92/100\n",
            "150/150 [==============================] - 0s 84us/step - loss: 0.7092 - acc: 0.6933\n",
            "Epoch 93/100\n",
            "150/150 [==============================] - 0s 54us/step - loss: 0.7074 - acc: 0.6933\n",
            "Epoch 94/100\n",
            "150/150 [==============================] - 0s 71us/step - loss: 0.7056 - acc: 0.6933\n",
            "Epoch 95/100\n",
            "150/150 [==============================] - 0s 85us/step - loss: 0.7038 - acc: 0.6933\n",
            "Epoch 96/100\n",
            "150/150 [==============================] - 0s 67us/step - loss: 0.7020 - acc: 0.6933\n",
            "Epoch 97/100\n",
            "150/150 [==============================] - 0s 84us/step - loss: 0.7002 - acc: 0.6933\n",
            "Epoch 98/100\n",
            "150/150 [==============================] - 0s 74us/step - loss: 0.6985 - acc: 0.6933\n",
            "Epoch 99/100\n",
            "150/150 [==============================] - 0s 77us/step - loss: 0.6969 - acc: 0.6933\n",
            "Epoch 100/100\n",
            "150/150 [==============================] - 0s 74us/step - loss: 0.6952 - acc: 0.6933\n",
            "60/60 [==============================] - 0s 5ms/step\n",
            "\n",
            "acc: 61.67%\n",
            "[[16  3  0]\n",
            " [ 0 21  0]\n",
            " [19  1  0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.84      0.59        19\n",
            "           1       0.84      1.00      0.91        21\n",
            "           2       0.00      0.00      0.00        20\n",
            "\n",
            "    accuracy                           0.62        60\n",
            "   macro avg       0.43      0.61      0.50        60\n",
            "weighted avg       0.44      0.62      0.51        60\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_104 (Dense)            (None, 10)                30        \n",
            "_________________________________________________________________\n",
            "dense_105 (Dense)            (None, 20)                220       \n",
            "_________________________________________________________________\n",
            "dense_106 (Dense)            (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_107 (Dense)            (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_108 (Dense)            (None, 3)                 63        \n",
            "=================================================================\n",
            "Total params: 1,153\n",
            "Trainable params: 1,153\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "180/180 [==============================] - 1s 5ms/step - loss: 1.1146 - acc: 0.3667\n",
            "Epoch 2/100\n",
            "180/180 [==============================] - 0s 59us/step - loss: 1.1123 - acc: 0.3667\n",
            "Epoch 3/100\n",
            "180/180 [==============================] - 0s 59us/step - loss: 1.1100 - acc: 0.3667\n",
            "Epoch 4/100\n",
            "180/180 [==============================] - 0s 60us/step - loss: 1.1078 - acc: 0.3667\n",
            "Epoch 5/100\n",
            "180/180 [==============================] - 0s 54us/step - loss: 1.1057 - acc: 0.3667\n",
            "Epoch 6/100\n",
            "180/180 [==============================] - 0s 48us/step - loss: 1.1035 - acc: 0.3667\n",
            "Epoch 7/100\n",
            "180/180 [==============================] - 0s 58us/step - loss: 1.1016 - acc: 0.3667\n",
            "Epoch 8/100\n",
            "180/180 [==============================] - 0s 55us/step - loss: 1.0995 - acc: 0.3667\n",
            "Epoch 9/100\n",
            "180/180 [==============================] - 0s 55us/step - loss: 1.0976 - acc: 0.3667\n",
            "Epoch 10/100\n",
            "180/180 [==============================] - 0s 51us/step - loss: 1.0959 - acc: 0.3667\n",
            "Epoch 11/100\n",
            "180/180 [==============================] - 0s 55us/step - loss: 1.0938 - acc: 0.3667\n",
            "Epoch 12/100\n",
            "180/180 [==============================] - 0s 51us/step - loss: 1.0919 - acc: 0.3667\n",
            "Epoch 13/100\n",
            "180/180 [==============================] - 0s 57us/step - loss: 1.0901 - acc: 0.3667\n",
            "Epoch 14/100\n",
            "180/180 [==============================] - 0s 56us/step - loss: 1.0884 - acc: 0.3667\n",
            "Epoch 15/100\n",
            "180/180 [==============================] - 0s 57us/step - loss: 1.0867 - acc: 0.3667\n",
            "Epoch 16/100\n",
            "180/180 [==============================] - 0s 53us/step - loss: 1.0850 - acc: 0.3667\n",
            "Epoch 17/100\n",
            "180/180 [==============================] - 0s 61us/step - loss: 1.0833 - acc: 0.3667\n",
            "Epoch 18/100\n",
            "180/180 [==============================] - 0s 68us/step - loss: 1.0816 - acc: 0.3667\n",
            "Epoch 19/100\n",
            "180/180 [==============================] - 0s 58us/step - loss: 1.0800 - acc: 0.3667\n",
            "Epoch 20/100\n",
            "180/180 [==============================] - 0s 49us/step - loss: 1.0784 - acc: 0.3667\n",
            "Epoch 21/100\n",
            "180/180 [==============================] - 0s 57us/step - loss: 1.0772 - acc: 0.3667\n",
            "Epoch 22/100\n",
            "180/180 [==============================] - 0s 74us/step - loss: 1.0753 - acc: 0.3667\n",
            "Epoch 23/100\n",
            "180/180 [==============================] - 0s 70us/step - loss: 1.0736 - acc: 0.3667\n",
            "Epoch 24/100\n",
            "180/180 [==============================] - 0s 70us/step - loss: 1.0719 - acc: 0.3667\n",
            "Epoch 25/100\n",
            "180/180 [==============================] - 0s 62us/step - loss: 1.0704 - acc: 0.3667\n",
            "Epoch 26/100\n",
            "180/180 [==============================] - 0s 55us/step - loss: 1.0688 - acc: 0.3667\n",
            "Epoch 27/100\n",
            "180/180 [==============================] - 0s 74us/step - loss: 1.0674 - acc: 0.3667\n",
            "Epoch 28/100\n",
            "180/180 [==============================] - 0s 67us/step - loss: 1.0656 - acc: 0.3667\n",
            "Epoch 29/100\n",
            "180/180 [==============================] - 0s 76us/step - loss: 1.0640 - acc: 0.3667\n",
            "Epoch 30/100\n",
            "180/180 [==============================] - 0s 72us/step - loss: 1.0623 - acc: 0.3667\n",
            "Epoch 31/100\n",
            "180/180 [==============================] - 0s 54us/step - loss: 1.0607 - acc: 0.3778\n",
            "Epoch 32/100\n",
            "180/180 [==============================] - 0s 55us/step - loss: 1.0590 - acc: 0.3778\n",
            "Epoch 33/100\n",
            "180/180 [==============================] - 0s 57us/step - loss: 1.0573 - acc: 0.3889\n",
            "Epoch 34/100\n",
            "180/180 [==============================] - 0s 87us/step - loss: 1.0557 - acc: 0.4000\n",
            "Epoch 35/100\n",
            "180/180 [==============================] - 0s 64us/step - loss: 1.0540 - acc: 0.4000\n",
            "Epoch 36/100\n",
            "180/180 [==============================] - 0s 73us/step - loss: 1.0524 - acc: 0.4000\n",
            "Epoch 37/100\n",
            "180/180 [==============================] - 0s 76us/step - loss: 1.0508 - acc: 0.4056\n",
            "Epoch 38/100\n",
            "180/180 [==============================] - 0s 64us/step - loss: 1.0490 - acc: 0.4056\n",
            "Epoch 39/100\n",
            "180/180 [==============================] - 0s 75us/step - loss: 1.0474 - acc: 0.4222\n",
            "Epoch 40/100\n",
            "180/180 [==============================] - 0s 74us/step - loss: 1.0458 - acc: 0.4278\n",
            "Epoch 41/100\n",
            "180/180 [==============================] - 0s 65us/step - loss: 1.0440 - acc: 0.4389\n",
            "Epoch 42/100\n",
            "180/180 [==============================] - 0s 85us/step - loss: 1.0424 - acc: 0.4389\n",
            "Epoch 43/100\n",
            "180/180 [==============================] - 0s 74us/step - loss: 1.0405 - acc: 0.4444\n",
            "Epoch 44/100\n",
            "180/180 [==============================] - 0s 60us/step - loss: 1.0389 - acc: 0.4444\n",
            "Epoch 45/100\n",
            "180/180 [==============================] - 0s 68us/step - loss: 1.0372 - acc: 0.4500\n",
            "Epoch 46/100\n",
            "180/180 [==============================] - 0s 65us/step - loss: 1.0354 - acc: 0.4444\n",
            "Epoch 47/100\n",
            "180/180 [==============================] - 0s 76us/step - loss: 1.0335 - acc: 0.4500\n",
            "Epoch 48/100\n",
            "180/180 [==============================] - 0s 90us/step - loss: 1.0318 - acc: 0.4500\n",
            "Epoch 49/100\n",
            "180/180 [==============================] - 0s 69us/step - loss: 1.0301 - acc: 0.4500\n",
            "Epoch 50/100\n",
            "180/180 [==============================] - 0s 75us/step - loss: 1.0281 - acc: 0.4611\n",
            "Epoch 51/100\n",
            "180/180 [==============================] - 0s 62us/step - loss: 1.0263 - acc: 0.4611\n",
            "Epoch 52/100\n",
            "180/180 [==============================] - 0s 81us/step - loss: 1.0245 - acc: 0.4667\n",
            "Epoch 53/100\n",
            "180/180 [==============================] - 0s 63us/step - loss: 1.0226 - acc: 0.4667\n",
            "Epoch 54/100\n",
            "180/180 [==============================] - 0s 73us/step - loss: 1.0207 - acc: 0.4667\n",
            "Epoch 55/100\n",
            "180/180 [==============================] - 0s 96us/step - loss: 1.0189 - acc: 0.4667\n",
            "Epoch 56/100\n",
            "180/180 [==============================] - 0s 66us/step - loss: 1.0169 - acc: 0.4667\n",
            "Epoch 57/100\n",
            "180/180 [==============================] - 0s 67us/step - loss: 1.0151 - acc: 0.4667\n",
            "Epoch 58/100\n",
            "180/180 [==============================] - 0s 55us/step - loss: 1.0131 - acc: 0.4722\n",
            "Epoch 59/100\n",
            "180/180 [==============================] - 0s 61us/step - loss: 1.0112 - acc: 0.4722\n",
            "Epoch 60/100\n",
            "180/180 [==============================] - 0s 59us/step - loss: 1.0092 - acc: 0.4722\n",
            "Epoch 61/100\n",
            "180/180 [==============================] - 0s 66us/step - loss: 1.0072 - acc: 0.4833\n",
            "Epoch 62/100\n",
            "180/180 [==============================] - 0s 69us/step - loss: 1.0053 - acc: 0.4944\n",
            "Epoch 63/100\n",
            "180/180 [==============================] - 0s 65us/step - loss: 1.0033 - acc: 0.5000\n",
            "Epoch 64/100\n",
            "180/180 [==============================] - 0s 75us/step - loss: 1.0013 - acc: 0.5000\n",
            "Epoch 65/100\n",
            "180/180 [==============================] - 0s 61us/step - loss: 0.9992 - acc: 0.5000\n",
            "Epoch 66/100\n",
            "180/180 [==============================] - 0s 55us/step - loss: 0.9972 - acc: 0.5000\n",
            "Epoch 67/100\n",
            "180/180 [==============================] - 0s 55us/step - loss: 0.9951 - acc: 0.5056\n",
            "Epoch 68/100\n",
            "180/180 [==============================] - 0s 64us/step - loss: 0.9931 - acc: 0.5056\n",
            "Epoch 69/100\n",
            "180/180 [==============================] - 0s 63us/step - loss: 0.9909 - acc: 0.5111\n",
            "Epoch 70/100\n",
            "180/180 [==============================] - 0s 77us/step - loss: 0.9889 - acc: 0.5167\n",
            "Epoch 71/100\n",
            "180/180 [==============================] - 0s 70us/step - loss: 0.9867 - acc: 0.5222\n",
            "Epoch 72/100\n",
            "180/180 [==============================] - 0s 75us/step - loss: 0.9847 - acc: 0.5167\n",
            "Epoch 73/100\n",
            "180/180 [==============================] - 0s 79us/step - loss: 0.9824 - acc: 0.5222\n",
            "Epoch 74/100\n",
            "180/180 [==============================] - 0s 62us/step - loss: 0.9803 - acc: 0.5222\n",
            "Epoch 75/100\n",
            "180/180 [==============================] - 0s 60us/step - loss: 0.9783 - acc: 0.5222\n",
            "Epoch 76/100\n",
            "180/180 [==============================] - 0s 60us/step - loss: 0.9761 - acc: 0.5222\n",
            "Epoch 77/100\n",
            "180/180 [==============================] - 0s 49us/step - loss: 0.9739 - acc: 0.5333\n",
            "Epoch 78/100\n",
            "180/180 [==============================] - 0s 72us/step - loss: 0.9718 - acc: 0.5389\n",
            "Epoch 79/100\n",
            "180/180 [==============================] - 0s 69us/step - loss: 0.9697 - acc: 0.5500\n",
            "Epoch 80/100\n",
            "180/180 [==============================] - 0s 66us/step - loss: 0.9676 - acc: 0.5667\n",
            "Epoch 81/100\n",
            "180/180 [==============================] - 0s 69us/step - loss: 0.9653 - acc: 0.5556\n",
            "Epoch 82/100\n",
            "180/180 [==============================] - 0s 70us/step - loss: 0.9630 - acc: 0.5556\n",
            "Epoch 83/100\n",
            "180/180 [==============================] - 0s 66us/step - loss: 0.9609 - acc: 0.5667\n",
            "Epoch 84/100\n",
            "180/180 [==============================] - 0s 69us/step - loss: 0.9587 - acc: 0.5667\n",
            "Epoch 85/100\n",
            "180/180 [==============================] - 0s 80us/step - loss: 0.9564 - acc: 0.5667\n",
            "Epoch 86/100\n",
            "180/180 [==============================] - 0s 68us/step - loss: 0.9540 - acc: 0.5722\n",
            "Epoch 87/100\n",
            "180/180 [==============================] - 0s 64us/step - loss: 0.9517 - acc: 0.5778\n",
            "Epoch 88/100\n",
            "180/180 [==============================] - 0s 58us/step - loss: 0.9494 - acc: 0.5778\n",
            "Epoch 89/100\n",
            "180/180 [==============================] - 0s 51us/step - loss: 0.9470 - acc: 0.5778\n",
            "Epoch 90/100\n",
            "180/180 [==============================] - 0s 64us/step - loss: 0.9446 - acc: 0.5778\n",
            "Epoch 91/100\n",
            "180/180 [==============================] - 0s 62us/step - loss: 0.9423 - acc: 0.5833\n",
            "Epoch 92/100\n",
            "180/180 [==============================] - 0s 62us/step - loss: 0.9397 - acc: 0.5889\n",
            "Epoch 93/100\n",
            "180/180 [==============================] - 0s 63us/step - loss: 0.9374 - acc: 0.5944\n",
            "Epoch 94/100\n",
            "180/180 [==============================] - 0s 66us/step - loss: 0.9348 - acc: 0.6111\n",
            "Epoch 95/100\n",
            "180/180 [==============================] - 0s 61us/step - loss: 0.9324 - acc: 0.6167\n",
            "Epoch 96/100\n",
            "180/180 [==============================] - 0s 56us/step - loss: 0.9298 - acc: 0.6333\n",
            "Epoch 97/100\n",
            "180/180 [==============================] - 0s 59us/step - loss: 0.9273 - acc: 0.6333\n",
            "Epoch 98/100\n",
            "180/180 [==============================] - 0s 55us/step - loss: 0.9248 - acc: 0.6389\n",
            "Epoch 99/100\n",
            "180/180 [==============================] - 0s 69us/step - loss: 0.9223 - acc: 0.6444\n",
            "Epoch 100/100\n",
            "180/180 [==============================] - 0s 53us/step - loss: 0.9198 - acc: 0.6500\n",
            "60/60 [==============================] - 0s 6ms/step\n",
            "\n",
            "acc: 63.33%\n",
            "[[ 6 10  2]\n",
            " [ 0 21  0]\n",
            " [ 0 10 11]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.33      0.50        18\n",
            "           1       0.51      1.00      0.68        21\n",
            "           2       0.85      0.52      0.65        21\n",
            "\n",
            "    accuracy                           0.63        60\n",
            "   macro avg       0.79      0.62      0.61        60\n",
            "weighted avg       0.78      0.63      0.61        60\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_109 (Dense)            (None, 10)                30        \n",
            "_________________________________________________________________\n",
            "dense_110 (Dense)            (None, 20)                220       \n",
            "_________________________________________________________________\n",
            "dense_111 (Dense)            (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_112 (Dense)            (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_113 (Dense)            (None, 3)                 63        \n",
            "=================================================================\n",
            "Total params: 1,153\n",
            "Trainable params: 1,153\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 1.1068 - acc: 0.3619\n",
            "Epoch 2/100\n",
            "210/210 [==============================] - 0s 70us/step - loss: 1.0953 - acc: 0.3714\n",
            "Epoch 3/100\n",
            "210/210 [==============================] - 0s 70us/step - loss: 1.0829 - acc: 0.3857\n",
            "Epoch 4/100\n",
            "210/210 [==============================] - 0s 69us/step - loss: 1.0720 - acc: 0.4333\n",
            "Epoch 5/100\n",
            "210/210 [==============================] - 0s 67us/step - loss: 1.0624 - acc: 0.4762\n",
            "Epoch 6/100\n",
            "210/210 [==============================] - 0s 69us/step - loss: 1.0527 - acc: 0.5143\n",
            "Epoch 7/100\n",
            "210/210 [==============================] - 0s 66us/step - loss: 1.0443 - acc: 0.5619\n",
            "Epoch 8/100\n",
            "210/210 [==============================] - 0s 67us/step - loss: 1.0375 - acc: 0.6524\n",
            "Epoch 9/100\n",
            "210/210 [==============================] - 0s 67us/step - loss: 1.0302 - acc: 0.6429\n",
            "Epoch 10/100\n",
            "210/210 [==============================] - 0s 64us/step - loss: 1.0236 - acc: 0.6619\n",
            "Epoch 11/100\n",
            "210/210 [==============================] - 0s 66us/step - loss: 1.0173 - acc: 0.6905\n",
            "Epoch 12/100\n",
            "210/210 [==============================] - 0s 62us/step - loss: 1.0111 - acc: 0.6905\n",
            "Epoch 13/100\n",
            "210/210 [==============================] - 0s 81us/step - loss: 1.0048 - acc: 0.6905\n",
            "Epoch 14/100\n",
            "210/210 [==============================] - 0s 97us/step - loss: 0.9999 - acc: 0.6810\n",
            "Epoch 15/100\n",
            "210/210 [==============================] - 0s 62us/step - loss: 0.9943 - acc: 0.6857\n",
            "Epoch 16/100\n",
            "210/210 [==============================] - 0s 73us/step - loss: 0.9897 - acc: 0.6905\n",
            "Epoch 17/100\n",
            "210/210 [==============================] - 0s 62us/step - loss: 0.9845 - acc: 0.7048\n",
            "Epoch 18/100\n",
            "210/210 [==============================] - 0s 69us/step - loss: 0.9792 - acc: 0.6857\n",
            "Epoch 19/100\n",
            "210/210 [==============================] - 0s 67us/step - loss: 0.9741 - acc: 0.7143\n",
            "Epoch 20/100\n",
            "210/210 [==============================] - 0s 71us/step - loss: 0.9686 - acc: 0.7000\n",
            "Epoch 21/100\n",
            "210/210 [==============================] - 0s 80us/step - loss: 0.9627 - acc: 0.6810\n",
            "Epoch 22/100\n",
            "210/210 [==============================] - 0s 70us/step - loss: 0.9570 - acc: 0.6762\n",
            "Epoch 23/100\n",
            "210/210 [==============================] - 0s 55us/step - loss: 0.9517 - acc: 0.6762\n",
            "Epoch 24/100\n",
            "210/210 [==============================] - 0s 73us/step - loss: 0.9461 - acc: 0.6905\n",
            "Epoch 25/100\n",
            "210/210 [==============================] - 0s 61us/step - loss: 0.9410 - acc: 0.6857\n",
            "Epoch 26/100\n",
            "210/210 [==============================] - 0s 62us/step - loss: 0.9358 - acc: 0.7048\n",
            "Epoch 27/100\n",
            "210/210 [==============================] - 0s 62us/step - loss: 0.9301 - acc: 0.7000\n",
            "Epoch 28/100\n",
            "210/210 [==============================] - 0s 78us/step - loss: 0.9246 - acc: 0.6905\n",
            "Epoch 29/100\n",
            "210/210 [==============================] - 0s 76us/step - loss: 0.9198 - acc: 0.7000\n",
            "Epoch 30/100\n",
            "210/210 [==============================] - 0s 98us/step - loss: 0.9152 - acc: 0.7000\n",
            "Epoch 31/100\n",
            "210/210 [==============================] - 0s 70us/step - loss: 0.9100 - acc: 0.6952\n",
            "Epoch 32/100\n",
            "210/210 [==============================] - 0s 68us/step - loss: 0.9051 - acc: 0.6952\n",
            "Epoch 33/100\n",
            "210/210 [==============================] - 0s 59us/step - loss: 0.9004 - acc: 0.7095\n",
            "Epoch 34/100\n",
            "210/210 [==============================] - 0s 68us/step - loss: 0.8957 - acc: 0.7095\n",
            "Epoch 35/100\n",
            "210/210 [==============================] - 0s 77us/step - loss: 0.8908 - acc: 0.7095\n",
            "Epoch 36/100\n",
            "210/210 [==============================] - 0s 69us/step - loss: 0.8857 - acc: 0.7048\n",
            "Epoch 37/100\n",
            "210/210 [==============================] - 0s 87us/step - loss: 0.8807 - acc: 0.7048\n",
            "Epoch 38/100\n",
            "210/210 [==============================] - 0s 77us/step - loss: 0.8759 - acc: 0.7095\n",
            "Epoch 39/100\n",
            "210/210 [==============================] - 0s 70us/step - loss: 0.8711 - acc: 0.7095\n",
            "Epoch 40/100\n",
            "210/210 [==============================] - 0s 89us/step - loss: 0.8666 - acc: 0.7095\n",
            "Epoch 41/100\n",
            "210/210 [==============================] - 0s 73us/step - loss: 0.8620 - acc: 0.7095\n",
            "Epoch 42/100\n",
            "210/210 [==============================] - 0s 66us/step - loss: 0.8570 - acc: 0.7095\n",
            "Epoch 43/100\n",
            "210/210 [==============================] - 0s 71us/step - loss: 0.8523 - acc: 0.7095\n",
            "Epoch 44/100\n",
            "210/210 [==============================] - 0s 68us/step - loss: 0.8482 - acc: 0.7095\n",
            "Epoch 45/100\n",
            "210/210 [==============================] - 0s 69us/step - loss: 0.8433 - acc: 0.7095\n",
            "Epoch 46/100\n",
            "210/210 [==============================] - 0s 78us/step - loss: 0.8390 - acc: 0.7095\n",
            "Epoch 47/100\n",
            "210/210 [==============================] - 0s 81us/step - loss: 0.8345 - acc: 0.7095\n",
            "Epoch 48/100\n",
            "210/210 [==============================] - 0s 72us/step - loss: 0.8301 - acc: 0.7095\n",
            "Epoch 49/100\n",
            "210/210 [==============================] - 0s 80us/step - loss: 0.8257 - acc: 0.7095\n",
            "Epoch 50/100\n",
            "210/210 [==============================] - 0s 70us/step - loss: 0.8214 - acc: 0.7048\n",
            "Epoch 51/100\n",
            "210/210 [==============================] - 0s 84us/step - loss: 0.8168 - acc: 0.7095\n",
            "Epoch 52/100\n",
            "210/210 [==============================] - 0s 73us/step - loss: 0.8128 - acc: 0.7095\n",
            "Epoch 53/100\n",
            "210/210 [==============================] - 0s 72us/step - loss: 0.8088 - acc: 0.7095\n",
            "Epoch 54/100\n",
            "210/210 [==============================] - 0s 71us/step - loss: 0.8050 - acc: 0.7095\n",
            "Epoch 55/100\n",
            "210/210 [==============================] - 0s 99us/step - loss: 0.8010 - acc: 0.7095\n",
            "Epoch 56/100\n",
            "210/210 [==============================] - 0s 71us/step - loss: 0.7968 - acc: 0.7095\n",
            "Epoch 57/100\n",
            "210/210 [==============================] - 0s 76us/step - loss: 0.7931 - acc: 0.7095\n",
            "Epoch 58/100\n",
            "210/210 [==============================] - 0s 72us/step - loss: 0.7889 - acc: 0.7095\n",
            "Epoch 59/100\n",
            "210/210 [==============================] - 0s 77us/step - loss: 0.7853 - acc: 0.7095\n",
            "Epoch 60/100\n",
            "210/210 [==============================] - 0s 64us/step - loss: 0.7811 - acc: 0.7095\n",
            "Epoch 61/100\n",
            "210/210 [==============================] - 0s 62us/step - loss: 0.7777 - acc: 0.7095\n",
            "Epoch 62/100\n",
            "210/210 [==============================] - 0s 83us/step - loss: 0.7746 - acc: 0.7095\n",
            "Epoch 63/100\n",
            "210/210 [==============================] - 0s 72us/step - loss: 0.7710 - acc: 0.7095\n",
            "Epoch 64/100\n",
            "210/210 [==============================] - 0s 81us/step - loss: 0.7674 - acc: 0.7095\n",
            "Epoch 65/100\n",
            "210/210 [==============================] - 0s 87us/step - loss: 0.7639 - acc: 0.7095\n",
            "Epoch 66/100\n",
            "210/210 [==============================] - 0s 74us/step - loss: 0.7601 - acc: 0.7095\n",
            "Epoch 67/100\n",
            "210/210 [==============================] - 0s 68us/step - loss: 0.7563 - acc: 0.7095\n",
            "Epoch 68/100\n",
            "210/210 [==============================] - 0s 66us/step - loss: 0.7529 - acc: 0.7095\n",
            "Epoch 69/100\n",
            "210/210 [==============================] - 0s 64us/step - loss: 0.7503 - acc: 0.7143\n",
            "Epoch 70/100\n",
            "210/210 [==============================] - 0s 62us/step - loss: 0.7471 - acc: 0.7143\n",
            "Epoch 71/100\n",
            "210/210 [==============================] - 0s 67us/step - loss: 0.7439 - acc: 0.7143\n",
            "Epoch 72/100\n",
            "210/210 [==============================] - 0s 63us/step - loss: 0.7405 - acc: 0.7095\n",
            "Epoch 73/100\n",
            "210/210 [==============================] - 0s 60us/step - loss: 0.7376 - acc: 0.7095\n",
            "Epoch 74/100\n",
            "210/210 [==============================] - 0s 67us/step - loss: 0.7346 - acc: 0.7095\n",
            "Epoch 75/100\n",
            "210/210 [==============================] - 0s 75us/step - loss: 0.7320 - acc: 0.7095\n",
            "Epoch 76/100\n",
            "210/210 [==============================] - 0s 99us/step - loss: 0.7295 - acc: 0.7000\n",
            "Epoch 77/100\n",
            "210/210 [==============================] - 0s 82us/step - loss: 0.7265 - acc: 0.6952\n",
            "Epoch 78/100\n",
            "210/210 [==============================] - 0s 68us/step - loss: 0.7232 - acc: 0.7095\n",
            "Epoch 79/100\n",
            "210/210 [==============================] - 0s 66us/step - loss: 0.7206 - acc: 0.7000\n",
            "Epoch 80/100\n",
            "210/210 [==============================] - 0s 88us/step - loss: 0.7170 - acc: 0.7095\n",
            "Epoch 81/100\n",
            "210/210 [==============================] - 0s 90us/step - loss: 0.7142 - acc: 0.7095\n",
            "Epoch 82/100\n",
            "210/210 [==============================] - 0s 80us/step - loss: 0.7115 - acc: 0.7048\n",
            "Epoch 83/100\n",
            "210/210 [==============================] - 0s 75us/step - loss: 0.7080 - acc: 0.7095\n",
            "Epoch 84/100\n",
            "210/210 [==============================] - 0s 68us/step - loss: 0.7052 - acc: 0.7095\n",
            "Epoch 85/100\n",
            "210/210 [==============================] - 0s 57us/step - loss: 0.7022 - acc: 0.7095\n",
            "Epoch 86/100\n",
            "210/210 [==============================] - 0s 61us/step - loss: 0.6995 - acc: 0.7095\n",
            "Epoch 87/100\n",
            "210/210 [==============================] - 0s 61us/step - loss: 0.6965 - acc: 0.7095\n",
            "Epoch 88/100\n",
            "210/210 [==============================] - 0s 66us/step - loss: 0.6939 - acc: 0.7095\n",
            "Epoch 89/100\n",
            "210/210 [==============================] - 0s 75us/step - loss: 0.6910 - acc: 0.7095\n",
            "Epoch 90/100\n",
            "210/210 [==============================] - 0s 66us/step - loss: 0.6882 - acc: 0.7095\n",
            "Epoch 91/100\n",
            "210/210 [==============================] - 0s 69us/step - loss: 0.6855 - acc: 0.7095\n",
            "Epoch 92/100\n",
            "210/210 [==============================] - 0s 61us/step - loss: 0.6825 - acc: 0.7143\n",
            "Epoch 93/100\n",
            "210/210 [==============================] - 0s 75us/step - loss: 0.6798 - acc: 0.7143\n",
            "Epoch 94/100\n",
            "210/210 [==============================] - 0s 75us/step - loss: 0.6770 - acc: 0.7143\n",
            "Epoch 95/100\n",
            "210/210 [==============================] - 0s 79us/step - loss: 0.6745 - acc: 0.7143\n",
            "Epoch 96/100\n",
            "210/210 [==============================] - 0s 89us/step - loss: 0.6720 - acc: 0.7143\n",
            "Epoch 97/100\n",
            "210/210 [==============================] - 0s 70us/step - loss: 0.6695 - acc: 0.7143\n",
            "Epoch 98/100\n",
            "210/210 [==============================] - 0s 72us/step - loss: 0.6672 - acc: 0.7143\n",
            "Epoch 99/100\n",
            "210/210 [==============================] - 0s 72us/step - loss: 0.6647 - acc: 0.7143\n",
            "Epoch 100/100\n",
            "210/210 [==============================] - 0s 79us/step - loss: 0.6625 - acc: 0.7143\n",
            "60/60 [==============================] - 0s 6ms/step\n",
            "\n",
            "acc: 58.33%\n",
            "[[16  0  4]\n",
            " [20  0  1]\n",
            " [ 0  0 19]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.80      0.57        20\n",
            "           1       0.00      0.00      0.00        21\n",
            "           2       0.79      1.00      0.88        19\n",
            "\n",
            "    accuracy                           0.58        60\n",
            "   macro avg       0.41      0.60      0.49        60\n",
            "weighted avg       0.40      0.58      0.47        60\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_114 (Dense)            (None, 10)                30        \n",
            "_________________________________________________________________\n",
            "dense_115 (Dense)            (None, 20)                220       \n",
            "_________________________________________________________________\n",
            "dense_116 (Dense)            (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_117 (Dense)            (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_118 (Dense)            (None, 3)                 63        \n",
            "=================================================================\n",
            "Total params: 1,153\n",
            "Trainable params: 1,153\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 1.0673 - acc: 0.4958\n",
            "Epoch 2/100\n",
            "240/240 [==============================] - 0s 72us/step - loss: 1.0622 - acc: 0.4958\n",
            "Epoch 3/100\n",
            "240/240 [==============================] - 0s 60us/step - loss: 1.0573 - acc: 0.5167\n",
            "Epoch 4/100\n",
            "240/240 [==============================] - 0s 60us/step - loss: 1.0525 - acc: 0.5208\n",
            "Epoch 5/100\n",
            "240/240 [==============================] - 0s 54us/step - loss: 1.0478 - acc: 0.5292\n",
            "Epoch 6/100\n",
            "240/240 [==============================] - 0s 57us/step - loss: 1.0436 - acc: 0.5333\n",
            "Epoch 7/100\n",
            "240/240 [==============================] - 0s 55us/step - loss: 1.0394 - acc: 0.5417\n",
            "Epoch 8/100\n",
            "240/240 [==============================] - 0s 59us/step - loss: 1.0355 - acc: 0.5500\n",
            "Epoch 9/100\n",
            "240/240 [==============================] - 0s 53us/step - loss: 1.0317 - acc: 0.5625\n",
            "Epoch 10/100\n",
            "240/240 [==============================] - 0s 51us/step - loss: 1.0276 - acc: 0.5958\n",
            "Epoch 11/100\n",
            "240/240 [==============================] - 0s 57us/step - loss: 1.0234 - acc: 0.6417\n",
            "Epoch 12/100\n",
            "240/240 [==============================] - 0s 68us/step - loss: 1.0194 - acc: 0.6708\n",
            "Epoch 13/100\n",
            "240/240 [==============================] - 0s 61us/step - loss: 1.0156 - acc: 0.7000\n",
            "Epoch 14/100\n",
            "240/240 [==============================] - 0s 57us/step - loss: 1.0118 - acc: 0.7208\n",
            "Epoch 15/100\n",
            "240/240 [==============================] - 0s 60us/step - loss: 1.0081 - acc: 0.7542\n",
            "Epoch 16/100\n",
            "240/240 [==============================] - 0s 62us/step - loss: 1.0039 - acc: 0.7917\n",
            "Epoch 17/100\n",
            "240/240 [==============================] - 0s 67us/step - loss: 0.9996 - acc: 0.7833\n",
            "Epoch 18/100\n",
            "240/240 [==============================] - 0s 97us/step - loss: 0.9954 - acc: 0.7875\n",
            "Epoch 19/100\n",
            "240/240 [==============================] - 0s 60us/step - loss: 0.9912 - acc: 0.7875\n",
            "Epoch 20/100\n",
            "240/240 [==============================] - 0s 61us/step - loss: 0.9869 - acc: 0.7958\n",
            "Epoch 21/100\n",
            "240/240 [==============================] - 0s 65us/step - loss: 0.9827 - acc: 0.8000\n",
            "Epoch 22/100\n",
            "240/240 [==============================] - 0s 65us/step - loss: 0.9778 - acc: 0.8042\n",
            "Epoch 23/100\n",
            "240/240 [==============================] - 0s 66us/step - loss: 0.9730 - acc: 0.8042\n",
            "Epoch 24/100\n",
            "240/240 [==============================] - 0s 57us/step - loss: 0.9686 - acc: 0.7958\n",
            "Epoch 25/100\n",
            "240/240 [==============================] - 0s 66us/step - loss: 0.9638 - acc: 0.7917\n",
            "Epoch 26/100\n",
            "240/240 [==============================] - 0s 66us/step - loss: 0.9593 - acc: 0.7833\n",
            "Epoch 27/100\n",
            "240/240 [==============================] - 0s 61us/step - loss: 0.9546 - acc: 0.7792\n",
            "Epoch 28/100\n",
            "240/240 [==============================] - 0s 55us/step - loss: 0.9500 - acc: 0.7875\n",
            "Epoch 29/100\n",
            "240/240 [==============================] - 0s 69us/step - loss: 0.9453 - acc: 0.7833\n",
            "Epoch 30/100\n",
            "240/240 [==============================] - 0s 64us/step - loss: 0.9406 - acc: 0.7875\n",
            "Epoch 31/100\n",
            "240/240 [==============================] - 0s 57us/step - loss: 0.9356 - acc: 0.7917\n",
            "Epoch 32/100\n",
            "240/240 [==============================] - 0s 61us/step - loss: 0.9309 - acc: 0.7875\n",
            "Epoch 33/100\n",
            "240/240 [==============================] - 0s 56us/step - loss: 0.9261 - acc: 0.7833\n",
            "Epoch 34/100\n",
            "240/240 [==============================] - 0s 63us/step - loss: 0.9212 - acc: 0.7792\n",
            "Epoch 35/100\n",
            "240/240 [==============================] - 0s 69us/step - loss: 0.9168 - acc: 0.7750\n",
            "Epoch 36/100\n",
            "240/240 [==============================] - 0s 60us/step - loss: 0.9118 - acc: 0.7833\n",
            "Epoch 37/100\n",
            "240/240 [==============================] - 0s 54us/step - loss: 0.9067 - acc: 0.7792\n",
            "Epoch 38/100\n",
            "240/240 [==============================] - 0s 58us/step - loss: 0.9017 - acc: 0.7792\n",
            "Epoch 39/100\n",
            "240/240 [==============================] - 0s 64us/step - loss: 0.8969 - acc: 0.7792\n",
            "Epoch 40/100\n",
            "240/240 [==============================] - 0s 71us/step - loss: 0.8920 - acc: 0.7750\n",
            "Epoch 41/100\n",
            "240/240 [==============================] - 0s 54us/step - loss: 0.8872 - acc: 0.7750\n",
            "Epoch 42/100\n",
            "240/240 [==============================] - 0s 61us/step - loss: 0.8820 - acc: 0.7667\n",
            "Epoch 43/100\n",
            "240/240 [==============================] - 0s 70us/step - loss: 0.8771 - acc: 0.7667\n",
            "Epoch 44/100\n",
            "240/240 [==============================] - 0s 76us/step - loss: 0.8721 - acc: 0.7583\n",
            "Epoch 45/100\n",
            "240/240 [==============================] - 0s 54us/step - loss: 0.8672 - acc: 0.7583\n",
            "Epoch 46/100\n",
            "240/240 [==============================] - 0s 55us/step - loss: 0.8621 - acc: 0.7583\n",
            "Epoch 47/100\n",
            "240/240 [==============================] - 0s 51us/step - loss: 0.8569 - acc: 0.7542\n",
            "Epoch 48/100\n",
            "240/240 [==============================] - 0s 58us/step - loss: 0.8519 - acc: 0.7667\n",
            "Epoch 49/100\n",
            "240/240 [==============================] - 0s 60us/step - loss: 0.8467 - acc: 0.7542\n",
            "Epoch 50/100\n",
            "240/240 [==============================] - 0s 58us/step - loss: 0.8415 - acc: 0.7458\n",
            "Epoch 51/100\n",
            "240/240 [==============================] - 0s 60us/step - loss: 0.8363 - acc: 0.7500\n",
            "Epoch 52/100\n",
            "240/240 [==============================] - 0s 59us/step - loss: 0.8311 - acc: 0.7500\n",
            "Epoch 53/100\n",
            "240/240 [==============================] - 0s 69us/step - loss: 0.8257 - acc: 0.7500\n",
            "Epoch 54/100\n",
            "240/240 [==============================] - 0s 65us/step - loss: 0.8205 - acc: 0.7500\n",
            "Epoch 55/100\n",
            "240/240 [==============================] - 0s 63us/step - loss: 0.8151 - acc: 0.7625\n",
            "Epoch 56/100\n",
            "240/240 [==============================] - 0s 62us/step - loss: 0.8098 - acc: 0.7583\n",
            "Epoch 57/100\n",
            "240/240 [==============================] - 0s 58us/step - loss: 0.8047 - acc: 0.7625\n",
            "Epoch 58/100\n",
            "240/240 [==============================] - 0s 72us/step - loss: 0.7990 - acc: 0.7625\n",
            "Epoch 59/100\n",
            "240/240 [==============================] - 0s 56us/step - loss: 0.7936 - acc: 0.7625\n",
            "Epoch 60/100\n",
            "240/240 [==============================] - 0s 62us/step - loss: 0.7882 - acc: 0.7625\n",
            "Epoch 61/100\n",
            "240/240 [==============================] - 0s 60us/step - loss: 0.7828 - acc: 0.7625\n",
            "Epoch 62/100\n",
            "240/240 [==============================] - 0s 56us/step - loss: 0.7774 - acc: 0.7625\n",
            "Epoch 63/100\n",
            "240/240 [==============================] - 0s 59us/step - loss: 0.7721 - acc: 0.7583\n",
            "Epoch 64/100\n",
            "240/240 [==============================] - 0s 56us/step - loss: 0.7669 - acc: 0.7583\n",
            "Epoch 65/100\n",
            "240/240 [==============================] - 0s 56us/step - loss: 0.7613 - acc: 0.7625\n",
            "Epoch 66/100\n",
            "240/240 [==============================] - 0s 71us/step - loss: 0.7559 - acc: 0.7625\n",
            "Epoch 67/100\n",
            "240/240 [==============================] - 0s 62us/step - loss: 0.7503 - acc: 0.7625\n",
            "Epoch 68/100\n",
            "240/240 [==============================] - 0s 56us/step - loss: 0.7447 - acc: 0.7625\n",
            "Epoch 69/100\n",
            "240/240 [==============================] - 0s 52us/step - loss: 0.7391 - acc: 0.7625\n",
            "Epoch 70/100\n",
            "240/240 [==============================] - 0s 69us/step - loss: 0.7333 - acc: 0.7708\n",
            "Epoch 71/100\n",
            "240/240 [==============================] - 0s 53us/step - loss: 0.7273 - acc: 0.7708\n",
            "Epoch 72/100\n",
            "240/240 [==============================] - 0s 68us/step - loss: 0.7206 - acc: 0.7875\n",
            "Epoch 73/100\n",
            "240/240 [==============================] - 0s 65us/step - loss: 0.7139 - acc: 0.7958\n",
            "Epoch 74/100\n",
            "240/240 [==============================] - 0s 55us/step - loss: 0.7067 - acc: 0.8083\n",
            "Epoch 75/100\n",
            "240/240 [==============================] - 0s 59us/step - loss: 0.6996 - acc: 0.8167\n",
            "Epoch 76/100\n",
            "240/240 [==============================] - 0s 54us/step - loss: 0.6931 - acc: 0.8250\n",
            "Epoch 77/100\n",
            "240/240 [==============================] - 0s 53us/step - loss: 0.6863 - acc: 0.8208\n",
            "Epoch 78/100\n",
            "240/240 [==============================] - 0s 60us/step - loss: 0.6794 - acc: 0.8208\n",
            "Epoch 79/100\n",
            "240/240 [==============================] - 0s 70us/step - loss: 0.6727 - acc: 0.8208\n",
            "Epoch 80/100\n",
            "240/240 [==============================] - 0s 62us/step - loss: 0.6658 - acc: 0.8208\n",
            "Epoch 81/100\n",
            "240/240 [==============================] - 0s 58us/step - loss: 0.6588 - acc: 0.8250\n",
            "Epoch 82/100\n",
            "240/240 [==============================] - 0s 79us/step - loss: 0.6519 - acc: 0.8417\n",
            "Epoch 83/100\n",
            "240/240 [==============================] - 0s 84us/step - loss: 0.6451 - acc: 0.8417\n",
            "Epoch 84/100\n",
            "240/240 [==============================] - 0s 73us/step - loss: 0.6380 - acc: 0.8500\n",
            "Epoch 85/100\n",
            "240/240 [==============================] - 0s 67us/step - loss: 0.6318 - acc: 0.8583\n",
            "Epoch 86/100\n",
            "240/240 [==============================] - 0s 64us/step - loss: 0.6252 - acc: 0.8583\n",
            "Epoch 87/100\n",
            "240/240 [==============================] - 0s 80us/step - loss: 0.6189 - acc: 0.8583\n",
            "Epoch 88/100\n",
            "240/240 [==============================] - 0s 81us/step - loss: 0.6123 - acc: 0.8583\n",
            "Epoch 89/100\n",
            "240/240 [==============================] - 0s 89us/step - loss: 0.6061 - acc: 0.8583\n",
            "Epoch 90/100\n",
            "240/240 [==============================] - 0s 65us/step - loss: 0.5996 - acc: 0.8583\n",
            "Epoch 91/100\n",
            "240/240 [==============================] - 0s 59us/step - loss: 0.5935 - acc: 0.8583\n",
            "Epoch 92/100\n",
            "240/240 [==============================] - 0s 57us/step - loss: 0.5874 - acc: 0.8625\n",
            "Epoch 93/100\n",
            "240/240 [==============================] - 0s 55us/step - loss: 0.5814 - acc: 0.8625\n",
            "Epoch 94/100\n",
            "240/240 [==============================] - 0s 64us/step - loss: 0.5755 - acc: 0.8625\n",
            "Epoch 95/100\n",
            "240/240 [==============================] - 0s 64us/step - loss: 0.5696 - acc: 0.8625\n",
            "Epoch 96/100\n",
            "240/240 [==============================] - 0s 57us/step - loss: 0.5639 - acc: 0.8625\n",
            "Epoch 97/100\n",
            "240/240 [==============================] - 0s 62us/step - loss: 0.5581 - acc: 0.8625\n",
            "Epoch 98/100\n",
            "240/240 [==============================] - 0s 55us/step - loss: 0.5527 - acc: 0.8625\n",
            "Epoch 99/100\n",
            "240/240 [==============================] - 0s 65us/step - loss: 0.5474 - acc: 0.8625\n",
            "Epoch 100/100\n",
            "240/240 [==============================] - 0s 58us/step - loss: 0.5418 - acc: 0.8667\n",
            "60/60 [==============================] - 0s 6ms/step\n",
            "\n",
            "acc: 83.33%\n",
            "[[10  2  2]\n",
            " [ 1 20  0]\n",
            " [ 5  0 20]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.71      0.67        14\n",
            "           1       0.91      0.95      0.93        21\n",
            "           2       0.91      0.80      0.85        25\n",
            "\n",
            "    accuracy                           0.83        60\n",
            "   macro avg       0.81      0.82      0.82        60\n",
            "weighted avg       0.84      0.83      0.84        60\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_119 (Dense)            (None, 10)                30        \n",
            "_________________________________________________________________\n",
            "dense_120 (Dense)            (None, 20)                220       \n",
            "_________________________________________________________________\n",
            "dense_121 (Dense)            (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_122 (Dense)            (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_123 (Dense)            (None, 3)                 63        \n",
            "=================================================================\n",
            "Total params: 1,153\n",
            "Trainable params: 1,153\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 1.1419 - acc: 0.3407\n",
            "Epoch 2/100\n",
            "270/270 [==============================] - 0s 58us/step - loss: 1.1328 - acc: 0.4926\n",
            "Epoch 3/100\n",
            "270/270 [==============================] - 0s 58us/step - loss: 1.1246 - acc: 0.5111\n",
            "Epoch 4/100\n",
            "270/270 [==============================] - 0s 49us/step - loss: 1.1172 - acc: 0.4963\n",
            "Epoch 5/100\n",
            "270/270 [==============================] - 0s 56us/step - loss: 1.1105 - acc: 0.4926\n",
            "Epoch 6/100\n",
            "270/270 [==============================] - 0s 48us/step - loss: 1.1039 - acc: 0.4815\n",
            "Epoch 7/100\n",
            "270/270 [==============================] - 0s 49us/step - loss: 1.0981 - acc: 0.4926\n",
            "Epoch 8/100\n",
            "270/270 [==============================] - 0s 59us/step - loss: 1.0925 - acc: 0.5000\n",
            "Epoch 9/100\n",
            "270/270 [==============================] - 0s 55us/step - loss: 1.0872 - acc: 0.5111\n",
            "Epoch 10/100\n",
            "270/270 [==============================] - 0s 51us/step - loss: 1.0817 - acc: 0.5148\n",
            "Epoch 11/100\n",
            "270/270 [==============================] - 0s 64us/step - loss: 1.0765 - acc: 0.5148\n",
            "Epoch 12/100\n",
            "270/270 [==============================] - 0s 52us/step - loss: 1.0714 - acc: 0.5519\n",
            "Epoch 13/100\n",
            "270/270 [==============================] - 0s 50us/step - loss: 1.0665 - acc: 0.5630\n",
            "Epoch 14/100\n",
            "270/270 [==============================] - 0s 51us/step - loss: 1.0612 - acc: 0.6037\n",
            "Epoch 15/100\n",
            "270/270 [==============================] - 0s 60us/step - loss: 1.0562 - acc: 0.6593\n",
            "Epoch 16/100\n",
            "270/270 [==============================] - 0s 49us/step - loss: 1.0513 - acc: 0.6519\n",
            "Epoch 17/100\n",
            "270/270 [==============================] - 0s 57us/step - loss: 1.0464 - acc: 0.6852\n",
            "Epoch 18/100\n",
            "270/270 [==============================] - 0s 55us/step - loss: 1.0415 - acc: 0.7000\n",
            "Epoch 19/100\n",
            "270/270 [==============================] - 0s 51us/step - loss: 1.0368 - acc: 0.7037\n",
            "Epoch 20/100\n",
            "270/270 [==============================] - 0s 51us/step - loss: 1.0321 - acc: 0.6963\n",
            "Epoch 21/100\n",
            "270/270 [==============================] - 0s 57us/step - loss: 1.0275 - acc: 0.7037\n",
            "Epoch 22/100\n",
            "270/270 [==============================] - 0s 62us/step - loss: 1.0233 - acc: 0.6963\n",
            "Epoch 23/100\n",
            "270/270 [==============================] - 0s 51us/step - loss: 1.0190 - acc: 0.6963\n",
            "Epoch 24/100\n",
            "270/270 [==============================] - 0s 55us/step - loss: 1.0145 - acc: 0.6815\n",
            "Epoch 25/100\n",
            "270/270 [==============================] - 0s 53us/step - loss: 1.0102 - acc: 0.6926\n",
            "Epoch 26/100\n",
            "270/270 [==============================] - 0s 45us/step - loss: 1.0060 - acc: 0.6926\n",
            "Epoch 27/100\n",
            "270/270 [==============================] - 0s 50us/step - loss: 1.0017 - acc: 0.6852\n",
            "Epoch 28/100\n",
            "270/270 [==============================] - 0s 52us/step - loss: 0.9976 - acc: 0.6852\n",
            "Epoch 29/100\n",
            "270/270 [==============================] - 0s 55us/step - loss: 0.9933 - acc: 0.6852\n",
            "Epoch 30/100\n",
            "270/270 [==============================] - 0s 47us/step - loss: 0.9890 - acc: 0.6852\n",
            "Epoch 31/100\n",
            "270/270 [==============================] - 0s 61us/step - loss: 0.9847 - acc: 0.6815\n",
            "Epoch 32/100\n",
            "270/270 [==============================] - 0s 53us/step - loss: 0.9804 - acc: 0.6815\n",
            "Epoch 33/100\n",
            "270/270 [==============================] - 0s 56us/step - loss: 0.9759 - acc: 0.6815\n",
            "Epoch 34/100\n",
            "270/270 [==============================] - 0s 73us/step - loss: 0.9714 - acc: 0.6852\n",
            "Epoch 35/100\n",
            "270/270 [==============================] - 0s 87us/step - loss: 0.9668 - acc: 0.6889\n",
            "Epoch 36/100\n",
            "270/270 [==============================] - 0s 63us/step - loss: 0.9621 - acc: 0.6852\n",
            "Epoch 37/100\n",
            "270/270 [==============================] - 0s 57us/step - loss: 0.9574 - acc: 0.6926\n",
            "Epoch 38/100\n",
            "270/270 [==============================] - 0s 70us/step - loss: 0.9525 - acc: 0.6926\n",
            "Epoch 39/100\n",
            "270/270 [==============================] - 0s 58us/step - loss: 0.9477 - acc: 0.6926\n",
            "Epoch 40/100\n",
            "270/270 [==============================] - 0s 61us/step - loss: 0.9428 - acc: 0.6963\n",
            "Epoch 41/100\n",
            "270/270 [==============================] - 0s 56us/step - loss: 0.9375 - acc: 0.7000\n",
            "Epoch 42/100\n",
            "270/270 [==============================] - 0s 64us/step - loss: 0.9324 - acc: 0.7111\n",
            "Epoch 43/100\n",
            "270/270 [==============================] - 0s 56us/step - loss: 0.9270 - acc: 0.7111\n",
            "Epoch 44/100\n",
            "270/270 [==============================] - 0s 83us/step - loss: 0.9217 - acc: 0.7148\n",
            "Epoch 45/100\n",
            "270/270 [==============================] - 0s 52us/step - loss: 0.9163 - acc: 0.7185\n",
            "Epoch 46/100\n",
            "270/270 [==============================] - 0s 55us/step - loss: 0.9109 - acc: 0.7185\n",
            "Epoch 47/100\n",
            "270/270 [==============================] - 0s 49us/step - loss: 0.9052 - acc: 0.7185\n",
            "Epoch 48/100\n",
            "270/270 [==============================] - 0s 59us/step - loss: 0.8995 - acc: 0.7222\n",
            "Epoch 49/100\n",
            "270/270 [==============================] - 0s 59us/step - loss: 0.8937 - acc: 0.7259\n",
            "Epoch 50/100\n",
            "270/270 [==============================] - 0s 58us/step - loss: 0.8877 - acc: 0.7259\n",
            "Epoch 51/100\n",
            "270/270 [==============================] - 0s 56us/step - loss: 0.8816 - acc: 0.7407\n",
            "Epoch 52/100\n",
            "270/270 [==============================] - 0s 59us/step - loss: 0.8755 - acc: 0.7556\n",
            "Epoch 53/100\n",
            "270/270 [==============================] - 0s 59us/step - loss: 0.8692 - acc: 0.7593\n",
            "Epoch 54/100\n",
            "270/270 [==============================] - 0s 57us/step - loss: 0.8629 - acc: 0.7556\n",
            "Epoch 55/100\n",
            "270/270 [==============================] - 0s 57us/step - loss: 0.8565 - acc: 0.7593\n",
            "Epoch 56/100\n",
            "270/270 [==============================] - 0s 50us/step - loss: 0.8500 - acc: 0.7593\n",
            "Epoch 57/100\n",
            "270/270 [==============================] - 0s 57us/step - loss: 0.8434 - acc: 0.7778\n",
            "Epoch 58/100\n",
            "270/270 [==============================] - 0s 57us/step - loss: 0.8366 - acc: 0.7889\n",
            "Epoch 59/100\n",
            "270/270 [==============================] - 0s 63us/step - loss: 0.8297 - acc: 0.7889\n",
            "Epoch 60/100\n",
            "270/270 [==============================] - 0s 65us/step - loss: 0.8228 - acc: 0.8000\n",
            "Epoch 61/100\n",
            "270/270 [==============================] - 0s 53us/step - loss: 0.8157 - acc: 0.8037\n",
            "Epoch 62/100\n",
            "270/270 [==============================] - 0s 59us/step - loss: 0.8086 - acc: 0.8296\n",
            "Epoch 63/100\n",
            "270/270 [==============================] - 0s 53us/step - loss: 0.8014 - acc: 0.8296\n",
            "Epoch 64/100\n",
            "270/270 [==============================] - 0s 55us/step - loss: 0.7942 - acc: 0.8333\n",
            "Epoch 65/100\n",
            "270/270 [==============================] - 0s 62us/step - loss: 0.7870 - acc: 0.8444\n",
            "Epoch 66/100\n",
            "270/270 [==============================] - 0s 77us/step - loss: 0.7793 - acc: 0.8407\n",
            "Epoch 67/100\n",
            "270/270 [==============================] - 0s 51us/step - loss: 0.7720 - acc: 0.8519\n",
            "Epoch 68/100\n",
            "270/270 [==============================] - 0s 48us/step - loss: 0.7642 - acc: 0.8519\n",
            "Epoch 69/100\n",
            "270/270 [==============================] - 0s 60us/step - loss: 0.7566 - acc: 0.8556\n",
            "Epoch 70/100\n",
            "270/270 [==============================] - 0s 49us/step - loss: 0.7490 - acc: 0.8593\n",
            "Epoch 71/100\n",
            "270/270 [==============================] - 0s 68us/step - loss: 0.7413 - acc: 0.8630\n",
            "Epoch 72/100\n",
            "270/270 [==============================] - 0s 53us/step - loss: 0.7335 - acc: 0.8630\n",
            "Epoch 73/100\n",
            "270/270 [==============================] - 0s 57us/step - loss: 0.7256 - acc: 0.8667\n",
            "Epoch 74/100\n",
            "270/270 [==============================] - 0s 60us/step - loss: 0.7177 - acc: 0.8630\n",
            "Epoch 75/100\n",
            "270/270 [==============================] - 0s 69us/step - loss: 0.7098 - acc: 0.8630\n",
            "Epoch 76/100\n",
            "270/270 [==============================] - 0s 59us/step - loss: 0.7019 - acc: 0.8630\n",
            "Epoch 77/100\n",
            "270/270 [==============================] - 0s 62us/step - loss: 0.6939 - acc: 0.8704\n",
            "Epoch 78/100\n",
            "270/270 [==============================] - 0s 65us/step - loss: 0.6860 - acc: 0.8741\n",
            "Epoch 79/100\n",
            "270/270 [==============================] - 0s 49us/step - loss: 0.6781 - acc: 0.8741\n",
            "Epoch 80/100\n",
            "270/270 [==============================] - 0s 63us/step - loss: 0.6703 - acc: 0.8741\n",
            "Epoch 81/100\n",
            "270/270 [==============================] - 0s 64us/step - loss: 0.6626 - acc: 0.8741\n",
            "Epoch 82/100\n",
            "270/270 [==============================] - 0s 49us/step - loss: 0.6547 - acc: 0.8741\n",
            "Epoch 83/100\n",
            "270/270 [==============================] - 0s 54us/step - loss: 0.6470 - acc: 0.8815\n",
            "Epoch 84/100\n",
            "270/270 [==============================] - 0s 56us/step - loss: 0.6393 - acc: 0.8815\n",
            "Epoch 85/100\n",
            "270/270 [==============================] - 0s 52us/step - loss: 0.6317 - acc: 0.8815\n",
            "Epoch 86/100\n",
            "270/270 [==============================] - 0s 53us/step - loss: 0.6240 - acc: 0.8778\n",
            "Epoch 87/100\n",
            "270/270 [==============================] - 0s 50us/step - loss: 0.6165 - acc: 0.8778\n",
            "Epoch 88/100\n",
            "270/270 [==============================] - 0s 59us/step - loss: 0.6090 - acc: 0.8815\n",
            "Epoch 89/100\n",
            "270/270 [==============================] - 0s 70us/step - loss: 0.6015 - acc: 0.8778\n",
            "Epoch 90/100\n",
            "270/270 [==============================] - 0s 58us/step - loss: 0.5942 - acc: 0.8815\n",
            "Epoch 91/100\n",
            "270/270 [==============================] - 0s 71us/step - loss: 0.5869 - acc: 0.8815\n",
            "Epoch 92/100\n",
            "270/270 [==============================] - 0s 69us/step - loss: 0.5800 - acc: 0.8852\n",
            "Epoch 93/100\n",
            "270/270 [==============================] - 0s 65us/step - loss: 0.5730 - acc: 0.8852\n",
            "Epoch 94/100\n",
            "270/270 [==============================] - 0s 96us/step - loss: 0.5661 - acc: 0.8815\n",
            "Epoch 95/100\n",
            "270/270 [==============================] - 0s 49us/step - loss: 0.5593 - acc: 0.8852\n",
            "Epoch 96/100\n",
            "270/270 [==============================] - 0s 53us/step - loss: 0.5527 - acc: 0.8852\n",
            "Epoch 97/100\n",
            "270/270 [==============================] - 0s 54us/step - loss: 0.5463 - acc: 0.8852\n",
            "Epoch 98/100\n",
            "270/270 [==============================] - 0s 55us/step - loss: 0.5398 - acc: 0.8852\n",
            "Epoch 99/100\n",
            "270/270 [==============================] - 0s 58us/step - loss: 0.5335 - acc: 0.8815\n",
            "Epoch 100/100\n",
            "270/270 [==============================] - 0s 60us/step - loss: 0.5273 - acc: 0.8815\n",
            "60/60 [==============================] - 0s 7ms/step\n",
            "\n",
            "acc: 83.33%\n",
            "[[18  2  4]\n",
            " [ 1 16  2]\n",
            " [ 0  1 16]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.75      0.84        24\n",
            "           1       0.84      0.84      0.84        19\n",
            "           2       0.73      0.94      0.82        17\n",
            "\n",
            "    accuracy                           0.83        60\n",
            "   macro avg       0.84      0.84      0.83        60\n",
            "weighted avg       0.85      0.83      0.83        60\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_124 (Dense)            (None, 10)                30        \n",
            "_________________________________________________________________\n",
            "dense_125 (Dense)            (None, 20)                220       \n",
            "_________________________________________________________________\n",
            "dense_126 (Dense)            (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_127 (Dense)            (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_128 (Dense)            (None, 3)                 63        \n",
            "=================================================================\n",
            "Total params: 1,153\n",
            "Trainable params: 1,153\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 1.1073 - acc: 0.3233\n",
            "Epoch 2/100\n",
            "300/300 [==============================] - 0s 49us/step - loss: 1.1052 - acc: 0.3200\n",
            "Epoch 3/100\n",
            "300/300 [==============================] - 0s 46us/step - loss: 1.1031 - acc: 0.3233\n",
            "Epoch 4/100\n",
            "300/300 [==============================] - 0s 51us/step - loss: 1.1010 - acc: 0.3233\n",
            "Epoch 5/100\n",
            "300/300 [==============================] - 0s 49us/step - loss: 1.0989 - acc: 0.3533\n",
            "Epoch 6/100\n",
            "300/300 [==============================] - 0s 46us/step - loss: 1.0970 - acc: 0.3633\n",
            "Epoch 7/100\n",
            "300/300 [==============================] - 0s 47us/step - loss: 1.0951 - acc: 0.3633\n",
            "Epoch 8/100\n",
            "300/300 [==============================] - 0s 42us/step - loss: 1.0933 - acc: 0.3767\n",
            "Epoch 9/100\n",
            "300/300 [==============================] - 0s 46us/step - loss: 1.0914 - acc: 0.3833\n",
            "Epoch 10/100\n",
            "300/300 [==============================] - 0s 39us/step - loss: 1.0897 - acc: 0.3767\n",
            "Epoch 11/100\n",
            "300/300 [==============================] - 0s 45us/step - loss: 1.0879 - acc: 0.4067\n",
            "Epoch 12/100\n",
            "300/300 [==============================] - 0s 46us/step - loss: 1.0861 - acc: 0.4133\n",
            "Epoch 13/100\n",
            "300/300 [==============================] - 0s 45us/step - loss: 1.0844 - acc: 0.4233\n",
            "Epoch 14/100\n",
            "300/300 [==============================] - 0s 51us/step - loss: 1.0827 - acc: 0.4300\n",
            "Epoch 15/100\n",
            "300/300 [==============================] - 0s 53us/step - loss: 1.0810 - acc: 0.4467\n",
            "Epoch 16/100\n",
            "300/300 [==============================] - 0s 53us/step - loss: 1.0792 - acc: 0.4667\n",
            "Epoch 17/100\n",
            "300/300 [==============================] - 0s 51us/step - loss: 1.0775 - acc: 0.4800\n",
            "Epoch 18/100\n",
            "300/300 [==============================] - 0s 52us/step - loss: 1.0759 - acc: 0.4933\n",
            "Epoch 19/100\n",
            "300/300 [==============================] - 0s 57us/step - loss: 1.0742 - acc: 0.5033\n",
            "Epoch 20/100\n",
            "300/300 [==============================] - 0s 41us/step - loss: 1.0725 - acc: 0.5233\n",
            "Epoch 21/100\n",
            "300/300 [==============================] - 0s 48us/step - loss: 1.0709 - acc: 0.5467\n",
            "Epoch 22/100\n",
            "300/300 [==============================] - 0s 42us/step - loss: 1.0693 - acc: 0.5633\n",
            "Epoch 23/100\n",
            "300/300 [==============================] - 0s 54us/step - loss: 1.0677 - acc: 0.5833\n",
            "Epoch 24/100\n",
            "300/300 [==============================] - 0s 57us/step - loss: 1.0661 - acc: 0.5833\n",
            "Epoch 25/100\n",
            "300/300 [==============================] - 0s 45us/step - loss: 1.0645 - acc: 0.5967\n",
            "Epoch 26/100\n",
            "300/300 [==============================] - 0s 56us/step - loss: 1.0628 - acc: 0.6033\n",
            "Epoch 27/100\n",
            "300/300 [==============================] - 0s 51us/step - loss: 1.0612 - acc: 0.6000\n",
            "Epoch 28/100\n",
            "300/300 [==============================] - 0s 57us/step - loss: 1.0596 - acc: 0.6067\n",
            "Epoch 29/100\n",
            "300/300 [==============================] - 0s 54us/step - loss: 1.0579 - acc: 0.6167\n",
            "Epoch 30/100\n",
            "300/300 [==============================] - 0s 49us/step - loss: 1.0563 - acc: 0.6233\n",
            "Epoch 31/100\n",
            "300/300 [==============================] - 0s 52us/step - loss: 1.0547 - acc: 0.6200\n",
            "Epoch 32/100\n",
            "300/300 [==============================] - 0s 57us/step - loss: 1.0531 - acc: 0.6233\n",
            "Epoch 33/100\n",
            "300/300 [==============================] - 0s 56us/step - loss: 1.0515 - acc: 0.6200\n",
            "Epoch 34/100\n",
            "300/300 [==============================] - 0s 46us/step - loss: 1.0499 - acc: 0.6267\n",
            "Epoch 35/100\n",
            "300/300 [==============================] - 0s 51us/step - loss: 1.0482 - acc: 0.6267\n",
            "Epoch 36/100\n",
            "300/300 [==============================] - 0s 50us/step - loss: 1.0465 - acc: 0.6300\n",
            "Epoch 37/100\n",
            "300/300 [==============================] - 0s 51us/step - loss: 1.0450 - acc: 0.6300\n",
            "Epoch 38/100\n",
            "300/300 [==============================] - 0s 60us/step - loss: 1.0433 - acc: 0.6333\n",
            "Epoch 39/100\n",
            "300/300 [==============================] - 0s 78us/step - loss: 1.0417 - acc: 0.6400\n",
            "Epoch 40/100\n",
            "300/300 [==============================] - 0s 50us/step - loss: 1.0399 - acc: 0.6400\n",
            "Epoch 41/100\n",
            "300/300 [==============================] - 0s 49us/step - loss: 1.0381 - acc: 0.6400\n",
            "Epoch 42/100\n",
            "300/300 [==============================] - 0s 49us/step - loss: 1.0365 - acc: 0.6433\n",
            "Epoch 43/100\n",
            "300/300 [==============================] - 0s 80us/step - loss: 1.0346 - acc: 0.6433\n",
            "Epoch 44/100\n",
            "300/300 [==============================] - 0s 52us/step - loss: 1.0329 - acc: 0.6467\n",
            "Epoch 45/100\n",
            "300/300 [==============================] - 0s 55us/step - loss: 1.0311 - acc: 0.6467\n",
            "Epoch 46/100\n",
            "300/300 [==============================] - 0s 54us/step - loss: 1.0293 - acc: 0.6533\n",
            "Epoch 47/100\n",
            "300/300 [==============================] - 0s 61us/step - loss: 1.0275 - acc: 0.6567\n",
            "Epoch 48/100\n",
            "300/300 [==============================] - 0s 54us/step - loss: 1.0256 - acc: 0.6633\n",
            "Epoch 49/100\n",
            "300/300 [==============================] - 0s 50us/step - loss: 1.0236 - acc: 0.6733\n",
            "Epoch 50/100\n",
            "300/300 [==============================] - 0s 43us/step - loss: 1.0218 - acc: 0.6767\n",
            "Epoch 51/100\n",
            "300/300 [==============================] - 0s 52us/step - loss: 1.0199 - acc: 0.6767\n",
            "Epoch 52/100\n",
            "300/300 [==============================] - 0s 53us/step - loss: 1.0179 - acc: 0.6833\n",
            "Epoch 53/100\n",
            "300/300 [==============================] - 0s 50us/step - loss: 1.0160 - acc: 0.6900\n",
            "Epoch 54/100\n",
            "300/300 [==============================] - 0s 46us/step - loss: 1.0139 - acc: 0.6933\n",
            "Epoch 55/100\n",
            "300/300 [==============================] - 0s 47us/step - loss: 1.0119 - acc: 0.6933\n",
            "Epoch 56/100\n",
            "300/300 [==============================] - 0s 45us/step - loss: 1.0099 - acc: 0.6900\n",
            "Epoch 57/100\n",
            "300/300 [==============================] - 0s 54us/step - loss: 1.0079 - acc: 0.7000\n",
            "Epoch 58/100\n",
            "300/300 [==============================] - 0s 55us/step - loss: 1.0057 - acc: 0.6967\n",
            "Epoch 59/100\n",
            "300/300 [==============================] - 0s 40us/step - loss: 1.0037 - acc: 0.6967\n",
            "Epoch 60/100\n",
            "300/300 [==============================] - 0s 37us/step - loss: 1.0015 - acc: 0.6967\n",
            "Epoch 61/100\n",
            "300/300 [==============================] - 0s 40us/step - loss: 0.9997 - acc: 0.7033\n",
            "Epoch 62/100\n",
            "300/300 [==============================] - 0s 57us/step - loss: 0.9971 - acc: 0.7033\n",
            "Epoch 63/100\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.9950 - acc: 0.7067\n",
            "Epoch 64/100\n",
            "300/300 [==============================] - 0s 53us/step - loss: 0.9927 - acc: 0.7100\n",
            "Epoch 65/100\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.9904 - acc: 0.7100\n",
            "Epoch 66/100\n",
            "300/300 [==============================] - 0s 56us/step - loss: 0.9882 - acc: 0.7100\n",
            "Epoch 67/100\n",
            "300/300 [==============================] - 0s 52us/step - loss: 0.9860 - acc: 0.7133\n",
            "Epoch 68/100\n",
            "300/300 [==============================] - 0s 45us/step - loss: 0.9837 - acc: 0.7100\n",
            "Epoch 69/100\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.9811 - acc: 0.7100\n",
            "Epoch 70/100\n",
            "300/300 [==============================] - 0s 58us/step - loss: 0.9788 - acc: 0.7100\n",
            "Epoch 71/100\n",
            "300/300 [==============================] - 0s 46us/step - loss: 0.9764 - acc: 0.7200\n",
            "Epoch 72/100\n",
            "300/300 [==============================] - 0s 53us/step - loss: 0.9739 - acc: 0.7200\n",
            "Epoch 73/100\n",
            "300/300 [==============================] - 0s 53us/step - loss: 0.9715 - acc: 0.7200\n",
            "Epoch 74/100\n",
            "300/300 [==============================] - 0s 49us/step - loss: 0.9690 - acc: 0.7233\n",
            "Epoch 75/100\n",
            "300/300 [==============================] - 0s 54us/step - loss: 0.9668 - acc: 0.7233\n",
            "Epoch 76/100\n",
            "300/300 [==============================] - 0s 54us/step - loss: 0.9641 - acc: 0.7233\n",
            "Epoch 77/100\n",
            "300/300 [==============================] - 0s 43us/step - loss: 0.9615 - acc: 0.7300\n",
            "Epoch 78/100\n",
            "300/300 [==============================] - 0s 56us/step - loss: 0.9590 - acc: 0.7267\n",
            "Epoch 79/100\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.9563 - acc: 0.7333\n",
            "Epoch 80/100\n",
            "300/300 [==============================] - 0s 55us/step - loss: 0.9537 - acc: 0.7333\n",
            "Epoch 81/100\n",
            "300/300 [==============================] - 0s 58us/step - loss: 0.9511 - acc: 0.7333\n",
            "Epoch 82/100\n",
            "300/300 [==============================] - 0s 48us/step - loss: 0.9485 - acc: 0.7333\n",
            "Epoch 83/100\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.9459 - acc: 0.7433\n",
            "Epoch 84/100\n",
            "300/300 [==============================] - 0s 47us/step - loss: 0.9430 - acc: 0.7400\n",
            "Epoch 85/100\n",
            "300/300 [==============================] - 0s 52us/step - loss: 0.9404 - acc: 0.7400\n",
            "Epoch 86/100\n",
            "300/300 [==============================] - 0s 54us/step - loss: 0.9376 - acc: 0.7400\n",
            "Epoch 87/100\n",
            "300/300 [==============================] - 0s 43us/step - loss: 0.9348 - acc: 0.7433\n",
            "Epoch 88/100\n",
            "300/300 [==============================] - 0s 51us/step - loss: 0.9319 - acc: 0.7400\n",
            "Epoch 89/100\n",
            "300/300 [==============================] - 0s 44us/step - loss: 0.9291 - acc: 0.7400\n",
            "Epoch 90/100\n",
            "300/300 [==============================] - 0s 48us/step - loss: 0.9263 - acc: 0.7400\n",
            "Epoch 91/100\n",
            "300/300 [==============================] - 0s 55us/step - loss: 0.9235 - acc: 0.7367\n",
            "Epoch 92/100\n",
            "300/300 [==============================] - 0s 53us/step - loss: 0.9208 - acc: 0.7433\n",
            "Epoch 93/100\n",
            "300/300 [==============================] - 0s 55us/step - loss: 0.9178 - acc: 0.7400\n",
            "Epoch 94/100\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.9148 - acc: 0.7400\n",
            "Epoch 95/100\n",
            "300/300 [==============================] - 0s 48us/step - loss: 0.9120 - acc: 0.7400\n",
            "Epoch 96/100\n",
            "300/300 [==============================] - 0s 49us/step - loss: 0.9089 - acc: 0.7400\n",
            "Epoch 97/100\n",
            "300/300 [==============================] - 0s 57us/step - loss: 0.9059 - acc: 0.7500\n",
            "Epoch 98/100\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.9029 - acc: 0.7467\n",
            "Epoch 99/100\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.9000 - acc: 0.7467\n",
            "Epoch 100/100\n",
            "300/300 [==============================] - 0s 53us/step - loss: 0.8969 - acc: 0.7500\n",
            "60/60 [==============================] - 0s 7ms/step\n",
            "\n",
            "acc: 73.33%\n",
            "[[18  3  3]\n",
            " [ 2 15  0]\n",
            " [ 7  1 11]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.75      0.71        24\n",
            "           1       0.79      0.88      0.83        17\n",
            "           2       0.79      0.58      0.67        19\n",
            "\n",
            "    accuracy                           0.73        60\n",
            "   macro avg       0.75      0.74      0.74        60\n",
            "weighted avg       0.74      0.73      0.73        60\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9DF-ZipPHRk",
        "colab_type": "code",
        "outputId": "e4d0c3c9-f278-428f-d077-876723724786",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201530
        }
      },
      "source": [
        "Nepochs_acc=[]\n",
        "for element in Nepochs:\n",
        "  model, mean_train, stddev_train = trainModel(40, 3, element)\n",
        "  accurancy, CM = testModel(model, 20, mean_train, stddev_train)\n",
        "  Nepochs_acc.append(accurancy)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_129 (Dense)            (None, 10)                30        \n",
            "_________________________________________________________________\n",
            "dense_130 (Dense)            (None, 20)                220       \n",
            "_________________________________________________________________\n",
            "dense_131 (Dense)            (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_132 (Dense)            (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_133 (Dense)            (None, 3)                 63        \n",
            "=================================================================\n",
            "Total params: 1,153\n",
            "Trainable params: 1,153\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 1.0555 - acc: 0.3833\n",
            "Epoch 2/100\n",
            "120/120 [==============================] - 0s 113us/step - loss: 1.0514 - acc: 0.3667\n",
            "Epoch 3/100\n",
            "120/120 [==============================] - 0s 96us/step - loss: 1.0472 - acc: 0.3833\n",
            "Epoch 4/100\n",
            "120/120 [==============================] - 0s 87us/step - loss: 1.0427 - acc: 0.3667\n",
            "Epoch 5/100\n",
            "120/120 [==============================] - 0s 95us/step - loss: 1.0387 - acc: 0.3667\n",
            "Epoch 6/100\n",
            "120/120 [==============================] - 0s 105us/step - loss: 1.0346 - acc: 0.3667\n",
            "Epoch 7/100\n",
            "120/120 [==============================] - 0s 99us/step - loss: 1.0304 - acc: 0.3667\n",
            "Epoch 8/100\n",
            "120/120 [==============================] - 0s 92us/step - loss: 1.0264 - acc: 0.3583\n",
            "Epoch 9/100\n",
            "120/120 [==============================] - 0s 96us/step - loss: 1.0226 - acc: 0.3583\n",
            "Epoch 10/100\n",
            "120/120 [==============================] - 0s 104us/step - loss: 1.0188 - acc: 0.3667\n",
            "Epoch 11/100\n",
            "120/120 [==============================] - 0s 100us/step - loss: 1.0148 - acc: 0.3583\n",
            "Epoch 12/100\n",
            "120/120 [==============================] - 0s 88us/step - loss: 1.0111 - acc: 0.3583\n",
            "Epoch 13/100\n",
            "120/120 [==============================] - 0s 80us/step - loss: 1.0073 - acc: 0.3667\n",
            "Epoch 14/100\n",
            "120/120 [==============================] - 0s 83us/step - loss: 1.0035 - acc: 0.3667\n",
            "Epoch 15/100\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.9996 - acc: 0.3667\n",
            "Epoch 16/100\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.9958 - acc: 0.3750\n",
            "Epoch 17/100\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.9917 - acc: 0.3917\n",
            "Epoch 18/100\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.9879 - acc: 0.4000\n",
            "Epoch 19/100\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.9841 - acc: 0.4500\n",
            "Epoch 20/100\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.9806 - acc: 0.4750\n",
            "Epoch 21/100\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.9770 - acc: 0.4583\n",
            "Epoch 22/100\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.9731 - acc: 0.4167\n",
            "Epoch 23/100\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.9694 - acc: 0.4333\n",
            "Epoch 24/100\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.9654 - acc: 0.4583\n",
            "Epoch 25/100\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.9617 - acc: 0.4917\n",
            "Epoch 26/100\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.9580 - acc: 0.5167\n",
            "Epoch 27/100\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.9540 - acc: 0.5333\n",
            "Epoch 28/100\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.9501 - acc: 0.5417\n",
            "Epoch 29/100\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.9460 - acc: 0.5333\n",
            "Epoch 30/100\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.9418 - acc: 0.5583\n",
            "Epoch 31/100\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.9376 - acc: 0.5750\n",
            "Epoch 32/100\n",
            "120/120 [==============================] - 0s 71us/step - loss: 0.9336 - acc: 0.5833\n",
            "Epoch 33/100\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.9294 - acc: 0.6083\n",
            "Epoch 34/100\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.9252 - acc: 0.6083\n",
            "Epoch 35/100\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.9208 - acc: 0.6000\n",
            "Epoch 36/100\n",
            "120/120 [==============================] - 0s 119us/step - loss: 0.9161 - acc: 0.6000\n",
            "Epoch 37/100\n",
            "120/120 [==============================] - 0s 127us/step - loss: 0.9116 - acc: 0.6083\n",
            "Epoch 38/100\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.9071 - acc: 0.6083\n",
            "Epoch 39/100\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.9026 - acc: 0.6167\n",
            "Epoch 40/100\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.8980 - acc: 0.6083\n",
            "Epoch 41/100\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.8934 - acc: 0.6250\n",
            "Epoch 42/100\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.8890 - acc: 0.6500\n",
            "Epoch 43/100\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.8846 - acc: 0.6583\n",
            "Epoch 44/100\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.8805 - acc: 0.6833\n",
            "Epoch 45/100\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.8760 - acc: 0.7083\n",
            "Epoch 46/100\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.8715 - acc: 0.7083\n",
            "Epoch 47/100\n",
            "120/120 [==============================] - 0s 128us/step - loss: 0.8670 - acc: 0.7167\n",
            "Epoch 48/100\n",
            "120/120 [==============================] - 0s 176us/step - loss: 0.8622 - acc: 0.7167\n",
            "Epoch 49/100\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.8578 - acc: 0.7250\n",
            "Epoch 50/100\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.8534 - acc: 0.7250\n",
            "Epoch 51/100\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.8490 - acc: 0.7500\n",
            "Epoch 52/100\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.8446 - acc: 0.7583\n",
            "Epoch 53/100\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.8400 - acc: 0.7667\n",
            "Epoch 54/100\n",
            "120/120 [==============================] - 0s 115us/step - loss: 0.8354 - acc: 0.7667\n",
            "Epoch 55/100\n",
            "120/120 [==============================] - 0s 139us/step - loss: 0.8311 - acc: 0.7667\n",
            "Epoch 56/100\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.8263 - acc: 0.7667\n",
            "Epoch 57/100\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.8216 - acc: 0.7667\n",
            "Epoch 58/100\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.8170 - acc: 0.7667\n",
            "Epoch 59/100\n",
            "120/120 [==============================] - 0s 165us/step - loss: 0.8127 - acc: 0.7667\n",
            "Epoch 60/100\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.8079 - acc: 0.7583\n",
            "Epoch 61/100\n",
            "120/120 [==============================] - 0s 136us/step - loss: 0.8033 - acc: 0.7667\n",
            "Epoch 62/100\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.7988 - acc: 0.7833\n",
            "Epoch 63/100\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.7943 - acc: 0.7917\n",
            "Epoch 64/100\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.7899 - acc: 0.8083\n",
            "Epoch 65/100\n",
            "120/120 [==============================] - 0s 119us/step - loss: 0.7852 - acc: 0.8083\n",
            "Epoch 66/100\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.7807 - acc: 0.8083\n",
            "Epoch 67/100\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.7761 - acc: 0.8083\n",
            "Epoch 68/100\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.7713 - acc: 0.8167\n",
            "Epoch 69/100\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.7667 - acc: 0.8167\n",
            "Epoch 70/100\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.7624 - acc: 0.8083\n",
            "Epoch 71/100\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.7580 - acc: 0.8083\n",
            "Epoch 72/100\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.7536 - acc: 0.8167\n",
            "Epoch 73/100\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.7493 - acc: 0.8167\n",
            "Epoch 74/100\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.7449 - acc: 0.8167\n",
            "Epoch 75/100\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.7404 - acc: 0.8417\n",
            "Epoch 76/100\n",
            "120/120 [==============================] - 0s 117us/step - loss: 0.7359 - acc: 0.8500\n",
            "Epoch 77/100\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.7316 - acc: 0.8500\n",
            "Epoch 78/100\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.7271 - acc: 0.8417\n",
            "Epoch 79/100\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.7227 - acc: 0.8417\n",
            "Epoch 80/100\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.7180 - acc: 0.8583\n",
            "Epoch 81/100\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.7136 - acc: 0.8667\n",
            "Epoch 82/100\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.7094 - acc: 0.8667\n",
            "Epoch 83/100\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.7051 - acc: 0.8667\n",
            "Epoch 84/100\n",
            "120/120 [==============================] - 0s 127us/step - loss: 0.7007 - acc: 0.8667\n",
            "Epoch 85/100\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.6963 - acc: 0.8667\n",
            "Epoch 86/100\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.6920 - acc: 0.8667\n",
            "Epoch 87/100\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.6875 - acc: 0.8750\n",
            "Epoch 88/100\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.6833 - acc: 0.8833\n",
            "Epoch 89/100\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.6788 - acc: 0.8833\n",
            "Epoch 90/100\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.6745 - acc: 0.8833\n",
            "Epoch 91/100\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.6698 - acc: 0.8833\n",
            "Epoch 92/100\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.6654 - acc: 0.8833\n",
            "Epoch 93/100\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.6611 - acc: 0.8750\n",
            "Epoch 94/100\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.6569 - acc: 0.8833\n",
            "Epoch 95/100\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.6525 - acc: 0.8750\n",
            "Epoch 96/100\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.6484 - acc: 0.8750\n",
            "Epoch 97/100\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.6443 - acc: 0.8833\n",
            "Epoch 98/100\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.6399 - acc: 0.8833\n",
            "Epoch 99/100\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.6356 - acc: 0.8833\n",
            "Epoch 100/100\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.6315 - acc: 0.8917\n",
            "60/60 [==============================] - 0s 8ms/step\n",
            "\n",
            "acc: 86.67%\n",
            "[[20  1  2]\n",
            " [ 1 16  0]\n",
            " [ 4  0 16]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.87      0.83        23\n",
            "           1       0.94      0.94      0.94        17\n",
            "           2       0.89      0.80      0.84        20\n",
            "\n",
            "    accuracy                           0.87        60\n",
            "   macro avg       0.88      0.87      0.87        60\n",
            "weighted avg       0.87      0.87      0.87        60\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_134 (Dense)            (None, 10)                30        \n",
            "_________________________________________________________________\n",
            "dense_135 (Dense)            (None, 20)                220       \n",
            "_________________________________________________________________\n",
            "dense_136 (Dense)            (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_137 (Dense)            (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_138 (Dense)            (None, 3)                 63        \n",
            "=================================================================\n",
            "Total params: 1,153\n",
            "Trainable params: 1,153\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 1.0857 - acc: 0.3500\n",
            "Epoch 2/200\n",
            "120/120 [==============================] - 0s 119us/step - loss: 1.0831 - acc: 0.3667\n",
            "Epoch 3/200\n",
            "120/120 [==============================] - 0s 103us/step - loss: 1.0802 - acc: 0.4167\n",
            "Epoch 4/200\n",
            "120/120 [==============================] - 0s 92us/step - loss: 1.0784 - acc: 0.4250\n",
            "Epoch 5/200\n",
            "120/120 [==============================] - 0s 91us/step - loss: 1.0763 - acc: 0.4500\n",
            "Epoch 6/200\n",
            "120/120 [==============================] - 0s 88us/step - loss: 1.0739 - acc: 0.4667\n",
            "Epoch 7/200\n",
            "120/120 [==============================] - 0s 75us/step - loss: 1.0714 - acc: 0.4917\n",
            "Epoch 8/200\n",
            "120/120 [==============================] - 0s 92us/step - loss: 1.0696 - acc: 0.4917\n",
            "Epoch 9/200\n",
            "120/120 [==============================] - 0s 77us/step - loss: 1.0675 - acc: 0.4917\n",
            "Epoch 10/200\n",
            "120/120 [==============================] - 0s 79us/step - loss: 1.0656 - acc: 0.4917\n",
            "Epoch 11/200\n",
            "120/120 [==============================] - 0s 84us/step - loss: 1.0641 - acc: 0.4833\n",
            "Epoch 12/200\n",
            "120/120 [==============================] - 0s 95us/step - loss: 1.0626 - acc: 0.5083\n",
            "Epoch 13/200\n",
            "120/120 [==============================] - 0s 88us/step - loss: 1.0610 - acc: 0.5000\n",
            "Epoch 14/200\n",
            "120/120 [==============================] - 0s 80us/step - loss: 1.0595 - acc: 0.5000\n",
            "Epoch 15/200\n",
            "120/120 [==============================] - 0s 87us/step - loss: 1.0580 - acc: 0.5083\n",
            "Epoch 16/200\n",
            "120/120 [==============================] - 0s 99us/step - loss: 1.0564 - acc: 0.5083\n",
            "Epoch 17/200\n",
            "120/120 [==============================] - 0s 98us/step - loss: 1.0548 - acc: 0.5250\n",
            "Epoch 18/200\n",
            "120/120 [==============================] - 0s 93us/step - loss: 1.0530 - acc: 0.5417\n",
            "Epoch 19/200\n",
            "120/120 [==============================] - 0s 100us/step - loss: 1.0516 - acc: 0.5583\n",
            "Epoch 20/200\n",
            "120/120 [==============================] - 0s 98us/step - loss: 1.0500 - acc: 0.5583\n",
            "Epoch 21/200\n",
            "120/120 [==============================] - 0s 77us/step - loss: 1.0486 - acc: 0.5667\n",
            "Epoch 22/200\n",
            "120/120 [==============================] - 0s 90us/step - loss: 1.0471 - acc: 0.5667\n",
            "Epoch 23/200\n",
            "120/120 [==============================] - 0s 97us/step - loss: 1.0455 - acc: 0.5667\n",
            "Epoch 24/200\n",
            "120/120 [==============================] - 0s 102us/step - loss: 1.0436 - acc: 0.5667\n",
            "Epoch 25/200\n",
            "120/120 [==============================] - 0s 102us/step - loss: 1.0417 - acc: 0.5750\n",
            "Epoch 26/200\n",
            "120/120 [==============================] - 0s 93us/step - loss: 1.0398 - acc: 0.5667\n",
            "Epoch 27/200\n",
            "120/120 [==============================] - 0s 121us/step - loss: 1.0381 - acc: 0.5667\n",
            "Epoch 28/200\n",
            "120/120 [==============================] - 0s 96us/step - loss: 1.0362 - acc: 0.5667\n",
            "Epoch 29/200\n",
            "120/120 [==============================] - 0s 130us/step - loss: 1.0341 - acc: 0.5667\n",
            "Epoch 30/200\n",
            "120/120 [==============================] - 0s 103us/step - loss: 1.0320 - acc: 0.5750\n",
            "Epoch 31/200\n",
            "120/120 [==============================] - 0s 93us/step - loss: 1.0300 - acc: 0.5833\n",
            "Epoch 32/200\n",
            "120/120 [==============================] - 0s 96us/step - loss: 1.0276 - acc: 0.5833\n",
            "Epoch 33/200\n",
            "120/120 [==============================] - 0s 97us/step - loss: 1.0253 - acc: 0.5833\n",
            "Epoch 34/200\n",
            "120/120 [==============================] - 0s 93us/step - loss: 1.0229 - acc: 0.5917\n",
            "Epoch 35/200\n",
            "120/120 [==============================] - 0s 93us/step - loss: 1.0208 - acc: 0.5917\n",
            "Epoch 36/200\n",
            "120/120 [==============================] - 0s 93us/step - loss: 1.0186 - acc: 0.6083\n",
            "Epoch 37/200\n",
            "120/120 [==============================] - 0s 90us/step - loss: 1.0165 - acc: 0.6083\n",
            "Epoch 38/200\n",
            "120/120 [==============================] - 0s 93us/step - loss: 1.0147 - acc: 0.6083\n",
            "Epoch 39/200\n",
            "120/120 [==============================] - 0s 106us/step - loss: 1.0124 - acc: 0.6083\n",
            "Epoch 40/200\n",
            "120/120 [==============================] - 0s 91us/step - loss: 1.0103 - acc: 0.6083\n",
            "Epoch 41/200\n",
            "120/120 [==============================] - 0s 78us/step - loss: 1.0081 - acc: 0.6083\n",
            "Epoch 42/200\n",
            "120/120 [==============================] - 0s 87us/step - loss: 1.0055 - acc: 0.6167\n",
            "Epoch 43/200\n",
            "120/120 [==============================] - 0s 88us/step - loss: 1.0036 - acc: 0.6167\n",
            "Epoch 44/200\n",
            "120/120 [==============================] - 0s 99us/step - loss: 1.0013 - acc: 0.6167\n",
            "Epoch 45/200\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.9991 - acc: 0.6167\n",
            "Epoch 46/200\n",
            "120/120 [==============================] - 0s 76us/step - loss: 0.9969 - acc: 0.6167\n",
            "Epoch 47/200\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.9946 - acc: 0.6167\n",
            "Epoch 48/200\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.9922 - acc: 0.6167\n",
            "Epoch 49/200\n",
            "120/120 [==============================] - 0s 129us/step - loss: 0.9903 - acc: 0.6167\n",
            "Epoch 50/200\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.9881 - acc: 0.6167\n",
            "Epoch 51/200\n",
            "120/120 [==============================] - 0s 138us/step - loss: 0.9861 - acc: 0.6167\n",
            "Epoch 52/200\n",
            "120/120 [==============================] - 0s 126us/step - loss: 0.9839 - acc: 0.6167\n",
            "Epoch 53/200\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.9818 - acc: 0.6167\n",
            "Epoch 54/200\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.9797 - acc: 0.6167\n",
            "Epoch 55/200\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.9774 - acc: 0.6167\n",
            "Epoch 56/200\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.9752 - acc: 0.6167\n",
            "Epoch 57/200\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.9728 - acc: 0.6167\n",
            "Epoch 58/200\n",
            "120/120 [==============================] - 0s 139us/step - loss: 0.9705 - acc: 0.6167\n",
            "Epoch 59/200\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.9679 - acc: 0.6167\n",
            "Epoch 60/200\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.9657 - acc: 0.6167\n",
            "Epoch 61/200\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.9632 - acc: 0.6167\n",
            "Epoch 62/200\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.9605 - acc: 0.6167\n",
            "Epoch 63/200\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.9578 - acc: 0.6167\n",
            "Epoch 64/200\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.9552 - acc: 0.6167\n",
            "Epoch 65/200\n",
            "120/120 [==============================] - 0s 170us/step - loss: 0.9523 - acc: 0.6167\n",
            "Epoch 66/200\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.9500 - acc: 0.6167\n",
            "Epoch 67/200\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.9473 - acc: 0.6167\n",
            "Epoch 68/200\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.9445 - acc: 0.6167\n",
            "Epoch 69/200\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.9419 - acc: 0.6167\n",
            "Epoch 70/200\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.9390 - acc: 0.6167\n",
            "Epoch 71/200\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.9362 - acc: 0.6167\n",
            "Epoch 72/200\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.9333 - acc: 0.6167\n",
            "Epoch 73/200\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.9306 - acc: 0.6250\n",
            "Epoch 74/200\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.9280 - acc: 0.6250\n",
            "Epoch 75/200\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.9247 - acc: 0.6250\n",
            "Epoch 76/200\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.9217 - acc: 0.6250\n",
            "Epoch 77/200\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.9183 - acc: 0.6250\n",
            "Epoch 78/200\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.9153 - acc: 0.6250\n",
            "Epoch 79/200\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.9124 - acc: 0.6250\n",
            "Epoch 80/200\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.9092 - acc: 0.6250\n",
            "Epoch 81/200\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.9063 - acc: 0.6250\n",
            "Epoch 82/200\n",
            "120/120 [==============================] - 0s 76us/step - loss: 0.9033 - acc: 0.6250\n",
            "Epoch 83/200\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.9001 - acc: 0.6250\n",
            "Epoch 84/200\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.8971 - acc: 0.6417\n",
            "Epoch 85/200\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.8939 - acc: 0.6417\n",
            "Epoch 86/200\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.8903 - acc: 0.6417\n",
            "Epoch 87/200\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.8869 - acc: 0.6417\n",
            "Epoch 88/200\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.8839 - acc: 0.6417\n",
            "Epoch 89/200\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.8806 - acc: 0.6417\n",
            "Epoch 90/200\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.8771 - acc: 0.6417\n",
            "Epoch 91/200\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.8738 - acc: 0.6417\n",
            "Epoch 92/200\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.8703 - acc: 0.6417\n",
            "Epoch 93/200\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.8674 - acc: 0.6417\n",
            "Epoch 94/200\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.8640 - acc: 0.6417\n",
            "Epoch 95/200\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.8603 - acc: 0.6417\n",
            "Epoch 96/200\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.8567 - acc: 0.6417\n",
            "Epoch 97/200\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.8533 - acc: 0.6417\n",
            "Epoch 98/200\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.8498 - acc: 0.6417\n",
            "Epoch 99/200\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.8467 - acc: 0.6417\n",
            "Epoch 100/200\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.8434 - acc: 0.6500\n",
            "Epoch 101/200\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.8400 - acc: 0.6500\n",
            "Epoch 102/200\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.8364 - acc: 0.6500\n",
            "Epoch 103/200\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.8330 - acc: 0.6500\n",
            "Epoch 104/200\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.8298 - acc: 0.6500\n",
            "Epoch 105/200\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.8262 - acc: 0.6500\n",
            "Epoch 106/200\n",
            "120/120 [==============================] - 0s 131us/step - loss: 0.8226 - acc: 0.6583\n",
            "Epoch 107/200\n",
            "120/120 [==============================] - 0s 128us/step - loss: 0.8190 - acc: 0.6583\n",
            "Epoch 108/200\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.8157 - acc: 0.6583\n",
            "Epoch 109/200\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.8125 - acc: 0.6583\n",
            "Epoch 110/200\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.8088 - acc: 0.6583\n",
            "Epoch 111/200\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.8050 - acc: 0.6583\n",
            "Epoch 112/200\n",
            "120/120 [==============================] - 0s 75us/step - loss: 0.8013 - acc: 0.6583\n",
            "Epoch 113/200\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.7978 - acc: 0.6583\n",
            "Epoch 114/200\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.7948 - acc: 0.6583\n",
            "Epoch 115/200\n",
            "120/120 [==============================] - 0s 119us/step - loss: 0.7914 - acc: 0.6583\n",
            "Epoch 116/200\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.7878 - acc: 0.6583\n",
            "Epoch 117/200\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.7841 - acc: 0.6583\n",
            "Epoch 118/200\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.7804 - acc: 0.6583\n",
            "Epoch 119/200\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.7769 - acc: 0.6583\n",
            "Epoch 120/200\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.7733 - acc: 0.6583\n",
            "Epoch 121/200\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.7696 - acc: 0.6583\n",
            "Epoch 122/200\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.7658 - acc: 0.6583\n",
            "Epoch 123/200\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.7625 - acc: 0.6583\n",
            "Epoch 124/200\n",
            "120/120 [==============================] - 0s 75us/step - loss: 0.7591 - acc: 0.6583\n",
            "Epoch 125/200\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.7560 - acc: 0.6583\n",
            "Epoch 126/200\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.7527 - acc: 0.6583\n",
            "Epoch 127/200\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.7493 - acc: 0.6583\n",
            "Epoch 128/200\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.7461 - acc: 0.6583\n",
            "Epoch 129/200\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.7431 - acc: 0.6583\n",
            "Epoch 130/200\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.7397 - acc: 0.6583\n",
            "Epoch 131/200\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.7365 - acc: 0.6583\n",
            "Epoch 132/200\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.7330 - acc: 0.6583\n",
            "Epoch 133/200\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.7299 - acc: 0.6667\n",
            "Epoch 134/200\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.7263 - acc: 0.6667\n",
            "Epoch 135/200\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.7228 - acc: 0.6667\n",
            "Epoch 136/200\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.7197 - acc: 0.6667\n",
            "Epoch 137/200\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.7163 - acc: 0.6667\n",
            "Epoch 138/200\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.7133 - acc: 0.6667\n",
            "Epoch 139/200\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.7099 - acc: 0.6833\n",
            "Epoch 140/200\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.7067 - acc: 0.6833\n",
            "Epoch 141/200\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.7035 - acc: 0.6750\n",
            "Epoch 142/200\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.7001 - acc: 0.6750\n",
            "Epoch 143/200\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.6969 - acc: 0.6833\n",
            "Epoch 144/200\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.6936 - acc: 0.6833\n",
            "Epoch 145/200\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.6905 - acc: 0.6833\n",
            "Epoch 146/200\n",
            "120/120 [==============================] - 0s 138us/step - loss: 0.6875 - acc: 0.6917\n",
            "Epoch 147/200\n",
            "120/120 [==============================] - 0s 126us/step - loss: 0.6843 - acc: 0.6917\n",
            "Epoch 148/200\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.6812 - acc: 0.6917\n",
            "Epoch 149/200\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.6781 - acc: 0.6917\n",
            "Epoch 150/200\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.6751 - acc: 0.6917\n",
            "Epoch 151/200\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.6718 - acc: 0.6833\n",
            "Epoch 152/200\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.6689 - acc: 0.6833\n",
            "Epoch 153/200\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.6659 - acc: 0.6833\n",
            "Epoch 154/200\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.6630 - acc: 0.6833\n",
            "Epoch 155/200\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.6604 - acc: 0.6833\n",
            "Epoch 156/200\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.6577 - acc: 0.6917\n",
            "Epoch 157/200\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.6549 - acc: 0.6833\n",
            "Epoch 158/200\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.6522 - acc: 0.6833\n",
            "Epoch 159/200\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.6491 - acc: 0.6917\n",
            "Epoch 160/200\n",
            "120/120 [==============================] - 0s 126us/step - loss: 0.6464 - acc: 0.7000\n",
            "Epoch 161/200\n",
            "120/120 [==============================] - 0s 120us/step - loss: 0.6437 - acc: 0.6917\n",
            "Epoch 162/200\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.6411 - acc: 0.7000\n",
            "Epoch 163/200\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.6386 - acc: 0.7000\n",
            "Epoch 164/200\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.6357 - acc: 0.6917\n",
            "Epoch 165/200\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.6329 - acc: 0.6917\n",
            "Epoch 166/200\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.6302 - acc: 0.6833\n",
            "Epoch 167/200\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.6278 - acc: 0.6917\n",
            "Epoch 168/200\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.6251 - acc: 0.6917\n",
            "Epoch 169/200\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.6224 - acc: 0.6833\n",
            "Epoch 170/200\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.6201 - acc: 0.6917\n",
            "Epoch 171/200\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.6179 - acc: 0.6917\n",
            "Epoch 172/200\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.6153 - acc: 0.7000\n",
            "Epoch 173/200\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.6129 - acc: 0.7000\n",
            "Epoch 174/200\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.6107 - acc: 0.7000\n",
            "Epoch 175/200\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.6081 - acc: 0.7000\n",
            "Epoch 176/200\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.6059 - acc: 0.7000\n",
            "Epoch 177/200\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.6036 - acc: 0.7000\n",
            "Epoch 178/200\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.6013 - acc: 0.7000\n",
            "Epoch 179/200\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.5991 - acc: 0.7000\n",
            "Epoch 180/200\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.5969 - acc: 0.7000\n",
            "Epoch 181/200\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.5947 - acc: 0.7000\n",
            "Epoch 182/200\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.5922 - acc: 0.7000\n",
            "Epoch 183/200\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.5901 - acc: 0.7000\n",
            "Epoch 184/200\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.5882 - acc: 0.7000\n",
            "Epoch 185/200\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.5861 - acc: 0.7000\n",
            "Epoch 186/200\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.5838 - acc: 0.7000\n",
            "Epoch 187/200\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.5819 - acc: 0.7167\n",
            "Epoch 188/200\n",
            "120/120 [==============================] - 0s 119us/step - loss: 0.5798 - acc: 0.7083\n",
            "Epoch 189/200\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.5777 - acc: 0.7167\n",
            "Epoch 190/200\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.5757 - acc: 0.7250\n",
            "Epoch 191/200\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.5736 - acc: 0.7167\n",
            "Epoch 192/200\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.5716 - acc: 0.7250\n",
            "Epoch 193/200\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.5697 - acc: 0.7083\n",
            "Epoch 194/200\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.5679 - acc: 0.7083\n",
            "Epoch 195/200\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.5660 - acc: 0.7083\n",
            "Epoch 196/200\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.5639 - acc: 0.7167\n",
            "Epoch 197/200\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.5620 - acc: 0.7167\n",
            "Epoch 198/200\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.5601 - acc: 0.7167\n",
            "Epoch 199/200\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.5583 - acc: 0.7167\n",
            "Epoch 200/200\n",
            "120/120 [==============================] - 0s 77us/step - loss: 0.5568 - acc: 0.7167\n",
            "60/60 [==============================] - 0s 8ms/step\n",
            "\n",
            "acc: 70.00%\n",
            "[[ 5 12  6]\n",
            " [ 0 22  0]\n",
            " [ 0  0 15]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.22      0.36        23\n",
            "           1       0.65      1.00      0.79        22\n",
            "           2       0.71      1.00      0.83        15\n",
            "\n",
            "    accuracy                           0.70        60\n",
            "   macro avg       0.79      0.74      0.66        60\n",
            "weighted avg       0.80      0.70      0.63        60\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_139 (Dense)            (None, 10)                30        \n",
            "_________________________________________________________________\n",
            "dense_140 (Dense)            (None, 20)                220       \n",
            "_________________________________________________________________\n",
            "dense_141 (Dense)            (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_142 (Dense)            (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_143 (Dense)            (None, 3)                 63        \n",
            "=================================================================\n",
            "Total params: 1,153\n",
            "Trainable params: 1,153\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/300\n",
            "120/120 [==============================] - 1s 11ms/step - loss: 1.0921 - acc: 0.3083\n",
            "Epoch 2/300\n",
            "120/120 [==============================] - 0s 87us/step - loss: 1.0904 - acc: 0.3667\n",
            "Epoch 3/300\n",
            "120/120 [==============================] - 0s 101us/step - loss: 1.0885 - acc: 0.3500\n",
            "Epoch 4/300\n",
            "120/120 [==============================] - 0s 81us/step - loss: 1.0869 - acc: 0.3583\n",
            "Epoch 5/300\n",
            "120/120 [==============================] - 0s 80us/step - loss: 1.0849 - acc: 0.3750\n",
            "Epoch 6/300\n",
            "120/120 [==============================] - 0s 84us/step - loss: 1.0829 - acc: 0.3833\n",
            "Epoch 7/300\n",
            "120/120 [==============================] - 0s 76us/step - loss: 1.0808 - acc: 0.3750\n",
            "Epoch 8/300\n",
            "120/120 [==============================] - 0s 80us/step - loss: 1.0788 - acc: 0.3917\n",
            "Epoch 9/300\n",
            "120/120 [==============================] - 0s 81us/step - loss: 1.0767 - acc: 0.3917\n",
            "Epoch 10/300\n",
            "120/120 [==============================] - 0s 98us/step - loss: 1.0750 - acc: 0.3917\n",
            "Epoch 11/300\n",
            "120/120 [==============================] - 0s 78us/step - loss: 1.0733 - acc: 0.3917\n",
            "Epoch 12/300\n",
            "120/120 [==============================] - 0s 85us/step - loss: 1.0717 - acc: 0.3917\n",
            "Epoch 13/300\n",
            "120/120 [==============================] - 0s 75us/step - loss: 1.0702 - acc: 0.3917\n",
            "Epoch 14/300\n",
            "120/120 [==============================] - 0s 69us/step - loss: 1.0686 - acc: 0.3917\n",
            "Epoch 15/300\n",
            "120/120 [==============================] - 0s 72us/step - loss: 1.0669 - acc: 0.3917\n",
            "Epoch 16/300\n",
            "120/120 [==============================] - 0s 81us/step - loss: 1.0652 - acc: 0.3917\n",
            "Epoch 17/300\n",
            "120/120 [==============================] - 0s 77us/step - loss: 1.0637 - acc: 0.3917\n",
            "Epoch 18/300\n",
            "120/120 [==============================] - 0s 77us/step - loss: 1.0621 - acc: 0.3917\n",
            "Epoch 19/300\n",
            "120/120 [==============================] - 0s 77us/step - loss: 1.0605 - acc: 0.3917\n",
            "Epoch 20/300\n",
            "120/120 [==============================] - 0s 80us/step - loss: 1.0587 - acc: 0.3917\n",
            "Epoch 21/300\n",
            "120/120 [==============================] - 0s 88us/step - loss: 1.0571 - acc: 0.3917\n",
            "Epoch 22/300\n",
            "120/120 [==============================] - 0s 87us/step - loss: 1.0557 - acc: 0.3917\n",
            "Epoch 23/300\n",
            "120/120 [==============================] - 0s 76us/step - loss: 1.0541 - acc: 0.3917\n",
            "Epoch 24/300\n",
            "120/120 [==============================] - 0s 105us/step - loss: 1.0527 - acc: 0.3917\n",
            "Epoch 25/300\n",
            "120/120 [==============================] - 0s 84us/step - loss: 1.0514 - acc: 0.3917\n",
            "Epoch 26/300\n",
            "120/120 [==============================] - 0s 79us/step - loss: 1.0501 - acc: 0.3917\n",
            "Epoch 27/300\n",
            "120/120 [==============================] - 0s 82us/step - loss: 1.0487 - acc: 0.3917\n",
            "Epoch 28/300\n",
            "120/120 [==============================] - 0s 86us/step - loss: 1.0470 - acc: 0.3917\n",
            "Epoch 29/300\n",
            "120/120 [==============================] - 0s 89us/step - loss: 1.0456 - acc: 0.3917\n",
            "Epoch 30/300\n",
            "120/120 [==============================] - 0s 84us/step - loss: 1.0440 - acc: 0.3917\n",
            "Epoch 31/300\n",
            "120/120 [==============================] - 0s 153us/step - loss: 1.0425 - acc: 0.3917\n",
            "Epoch 32/300\n",
            "120/120 [==============================] - 0s 130us/step - loss: 1.0407 - acc: 0.3917\n",
            "Epoch 33/300\n",
            "120/120 [==============================] - 0s 93us/step - loss: 1.0393 - acc: 0.3917\n",
            "Epoch 34/300\n",
            "120/120 [==============================] - 0s 98us/step - loss: 1.0378 - acc: 0.3917\n",
            "Epoch 35/300\n",
            "120/120 [==============================] - 0s 89us/step - loss: 1.0364 - acc: 0.3917\n",
            "Epoch 36/300\n",
            "120/120 [==============================] - 0s 103us/step - loss: 1.0347 - acc: 0.3917\n",
            "Epoch 37/300\n",
            "120/120 [==============================] - 0s 115us/step - loss: 1.0332 - acc: 0.3917\n",
            "Epoch 38/300\n",
            "120/120 [==============================] - 0s 99us/step - loss: 1.0318 - acc: 0.3917\n",
            "Epoch 39/300\n",
            "120/120 [==============================] - 0s 111us/step - loss: 1.0301 - acc: 0.3917\n",
            "Epoch 40/300\n",
            "120/120 [==============================] - 0s 100us/step - loss: 1.0286 - acc: 0.3917\n",
            "Epoch 41/300\n",
            "120/120 [==============================] - 0s 87us/step - loss: 1.0268 - acc: 0.3917\n",
            "Epoch 42/300\n",
            "120/120 [==============================] - 0s 92us/step - loss: 1.0251 - acc: 0.3917\n",
            "Epoch 43/300\n",
            "120/120 [==============================] - 0s 98us/step - loss: 1.0236 - acc: 0.3917\n",
            "Epoch 44/300\n",
            "120/120 [==============================] - 0s 91us/step - loss: 1.0221 - acc: 0.3917\n",
            "Epoch 45/300\n",
            "120/120 [==============================] - 0s 105us/step - loss: 1.0205 - acc: 0.3917\n",
            "Epoch 46/300\n",
            "120/120 [==============================] - 0s 89us/step - loss: 1.0190 - acc: 0.3917\n",
            "Epoch 47/300\n",
            "120/120 [==============================] - 0s 91us/step - loss: 1.0175 - acc: 0.3917\n",
            "Epoch 48/300\n",
            "120/120 [==============================] - 0s 121us/step - loss: 1.0158 - acc: 0.3917\n",
            "Epoch 49/300\n",
            "120/120 [==============================] - 0s 115us/step - loss: 1.0140 - acc: 0.3917\n",
            "Epoch 50/300\n",
            "120/120 [==============================] - 0s 101us/step - loss: 1.0124 - acc: 0.3917\n",
            "Epoch 51/300\n",
            "120/120 [==============================] - 0s 101us/step - loss: 1.0109 - acc: 0.3917\n",
            "Epoch 52/300\n",
            "120/120 [==============================] - 0s 94us/step - loss: 1.0093 - acc: 0.3917\n",
            "Epoch 53/300\n",
            "120/120 [==============================] - 0s 97us/step - loss: 1.0076 - acc: 0.3917\n",
            "Epoch 54/300\n",
            "120/120 [==============================] - 0s 140us/step - loss: 1.0060 - acc: 0.3917\n",
            "Epoch 55/300\n",
            "120/120 [==============================] - 0s 93us/step - loss: 1.0043 - acc: 0.3917\n",
            "Epoch 56/300\n",
            "120/120 [==============================] - 0s 103us/step - loss: 1.0025 - acc: 0.3917\n",
            "Epoch 57/300\n",
            "120/120 [==============================] - 0s 96us/step - loss: 1.0007 - acc: 0.3917\n",
            "Epoch 58/300\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.9991 - acc: 0.3917\n",
            "Epoch 59/300\n",
            "120/120 [==============================] - 0s 150us/step - loss: 0.9973 - acc: 0.3917\n",
            "Epoch 60/300\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.9955 - acc: 0.3917\n",
            "Epoch 61/300\n",
            "120/120 [==============================] - 0s 184us/step - loss: 0.9937 - acc: 0.3917\n",
            "Epoch 62/300\n",
            "120/120 [==============================] - 0s 144us/step - loss: 0.9917 - acc: 0.3917\n",
            "Epoch 63/300\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.9900 - acc: 0.3917\n",
            "Epoch 64/300\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.9882 - acc: 0.3917\n",
            "Epoch 65/300\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.9865 - acc: 0.3917\n",
            "Epoch 66/300\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.9847 - acc: 0.3917\n",
            "Epoch 67/300\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.9828 - acc: 0.3917\n",
            "Epoch 68/300\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.9811 - acc: 0.3917\n",
            "Epoch 69/300\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.9792 - acc: 0.3917\n",
            "Epoch 70/300\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.9774 - acc: 0.3917\n",
            "Epoch 71/300\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.9755 - acc: 0.3917\n",
            "Epoch 72/300\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.9732 - acc: 0.3917\n",
            "Epoch 73/300\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.9713 - acc: 0.3917\n",
            "Epoch 74/300\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.9694 - acc: 0.3917\n",
            "Epoch 75/300\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.9675 - acc: 0.3917\n",
            "Epoch 76/300\n",
            "120/120 [==============================] - 0s 76us/step - loss: 0.9657 - acc: 0.3917\n",
            "Epoch 77/300\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.9636 - acc: 0.3917\n",
            "Epoch 78/300\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.9617 - acc: 0.3833\n",
            "Epoch 79/300\n",
            "120/120 [==============================] - 0s 121us/step - loss: 0.9596 - acc: 0.3917\n",
            "Epoch 80/300\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.9574 - acc: 0.3917\n",
            "Epoch 81/300\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.9554 - acc: 0.4000\n",
            "Epoch 82/300\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.9534 - acc: 0.4000\n",
            "Epoch 83/300\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.9512 - acc: 0.4333\n",
            "Epoch 84/300\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.9493 - acc: 0.4417\n",
            "Epoch 85/300\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.9472 - acc: 0.4500\n",
            "Epoch 86/300\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.9450 - acc: 0.4750\n",
            "Epoch 87/300\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.9428 - acc: 0.4750\n",
            "Epoch 88/300\n",
            "120/120 [==============================] - 0s 129us/step - loss: 0.9407 - acc: 0.4833\n",
            "Epoch 89/300\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.9384 - acc: 0.5167\n",
            "Epoch 90/300\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.9362 - acc: 0.5167\n",
            "Epoch 91/300\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.9341 - acc: 0.5083\n",
            "Epoch 92/300\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.9317 - acc: 0.5167\n",
            "Epoch 93/300\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.9295 - acc: 0.5167\n",
            "Epoch 94/300\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.9271 - acc: 0.5167\n",
            "Epoch 95/300\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.9248 - acc: 0.5167\n",
            "Epoch 96/300\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.9226 - acc: 0.5167\n",
            "Epoch 97/300\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.9205 - acc: 0.5250\n",
            "Epoch 98/300\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.9184 - acc: 0.5333\n",
            "Epoch 99/300\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.9159 - acc: 0.5333\n",
            "Epoch 100/300\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.9137 - acc: 0.5250\n",
            "Epoch 101/300\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.9114 - acc: 0.5333\n",
            "Epoch 102/300\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.9093 - acc: 0.5333\n",
            "Epoch 103/300\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.9068 - acc: 0.5500\n",
            "Epoch 104/300\n",
            "120/120 [==============================] - 0s 121us/step - loss: 0.9044 - acc: 0.5667\n",
            "Epoch 105/300\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.9020 - acc: 0.5667\n",
            "Epoch 106/300\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.8995 - acc: 0.5667\n",
            "Epoch 107/300\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.8970 - acc: 0.5667\n",
            "Epoch 108/300\n",
            "120/120 [==============================] - 0s 134us/step - loss: 0.8945 - acc: 0.5750\n",
            "Epoch 109/300\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.8916 - acc: 0.5833\n",
            "Epoch 110/300\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.8890 - acc: 0.5917\n",
            "Epoch 111/300\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.8866 - acc: 0.5917\n",
            "Epoch 112/300\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.8840 - acc: 0.5833\n",
            "Epoch 113/300\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.8815 - acc: 0.5833\n",
            "Epoch 114/300\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.8790 - acc: 0.5833\n",
            "Epoch 115/300\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.8766 - acc: 0.5917\n",
            "Epoch 116/300\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.8739 - acc: 0.5917\n",
            "Epoch 117/300\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.8712 - acc: 0.5917\n",
            "Epoch 118/300\n",
            "120/120 [==============================] - 0s 77us/step - loss: 0.8684 - acc: 0.5917\n",
            "Epoch 119/300\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.8659 - acc: 0.5917\n",
            "Epoch 120/300\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.8634 - acc: 0.6000\n",
            "Epoch 121/300\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.8607 - acc: 0.6000\n",
            "Epoch 122/300\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.8580 - acc: 0.6000\n",
            "Epoch 123/300\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.8550 - acc: 0.6000\n",
            "Epoch 124/300\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.8520 - acc: 0.6000\n",
            "Epoch 125/300\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.8490 - acc: 0.6000\n",
            "Epoch 126/300\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.8461 - acc: 0.6083\n",
            "Epoch 127/300\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.8431 - acc: 0.6167\n",
            "Epoch 128/300\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.8404 - acc: 0.6167\n",
            "Epoch 129/300\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.8376 - acc: 0.6333\n",
            "Epoch 130/300\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.8348 - acc: 0.6333\n",
            "Epoch 131/300\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.8320 - acc: 0.6333\n",
            "Epoch 132/300\n",
            "120/120 [==============================] - 0s 133us/step - loss: 0.8292 - acc: 0.6333\n",
            "Epoch 133/300\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.8262 - acc: 0.6333\n",
            "Epoch 134/300\n",
            "120/120 [==============================] - 0s 138us/step - loss: 0.8232 - acc: 0.6333\n",
            "Epoch 135/300\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.8204 - acc: 0.6417\n",
            "Epoch 136/300\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.8175 - acc: 0.6417\n",
            "Epoch 137/300\n",
            "120/120 [==============================] - 0s 138us/step - loss: 0.8146 - acc: 0.6417\n",
            "Epoch 138/300\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.8117 - acc: 0.6417\n",
            "Epoch 139/300\n",
            "120/120 [==============================] - 0s 148us/step - loss: 0.8089 - acc: 0.6500\n",
            "Epoch 140/300\n",
            "120/120 [==============================] - 0s 161us/step - loss: 0.8061 - acc: 0.6667\n",
            "Epoch 141/300\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.8034 - acc: 0.6833\n",
            "Epoch 142/300\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.8005 - acc: 0.6833\n",
            "Epoch 143/300\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.7978 - acc: 0.6833\n",
            "Epoch 144/300\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.7949 - acc: 0.6833\n",
            "Epoch 145/300\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.7920 - acc: 0.6833\n",
            "Epoch 146/300\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.7892 - acc: 0.6833\n",
            "Epoch 147/300\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.7867 - acc: 0.6833\n",
            "Epoch 148/300\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.7837 - acc: 0.6917\n",
            "Epoch 149/300\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.7807 - acc: 0.6833\n",
            "Epoch 150/300\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.7779 - acc: 0.6917\n",
            "Epoch 151/300\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.7752 - acc: 0.6833\n",
            "Epoch 152/300\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.7721 - acc: 0.7000\n",
            "Epoch 153/300\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.7692 - acc: 0.7000\n",
            "Epoch 154/300\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.7659 - acc: 0.7417\n",
            "Epoch 155/300\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.7628 - acc: 0.7333\n",
            "Epoch 156/300\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.7597 - acc: 0.7417\n",
            "Epoch 157/300\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.7568 - acc: 0.7500\n",
            "Epoch 158/300\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.7537 - acc: 0.7583\n",
            "Epoch 159/300\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.7507 - acc: 0.7833\n",
            "Epoch 160/300\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.7476 - acc: 0.7750\n",
            "Epoch 161/300\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.7446 - acc: 0.7833\n",
            "Epoch 162/300\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.7413 - acc: 0.7833\n",
            "Epoch 163/300\n",
            "120/120 [==============================] - 0s 115us/step - loss: 0.7385 - acc: 0.7833\n",
            "Epoch 164/300\n",
            "120/120 [==============================] - 0s 115us/step - loss: 0.7353 - acc: 0.7833\n",
            "Epoch 165/300\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.7321 - acc: 0.7833\n",
            "Epoch 166/300\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.7290 - acc: 0.7833\n",
            "Epoch 167/300\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.7257 - acc: 0.7917\n",
            "Epoch 168/300\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.7228 - acc: 0.8083\n",
            "Epoch 169/300\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.7196 - acc: 0.8083\n",
            "Epoch 170/300\n",
            "120/120 [==============================] - 0s 119us/step - loss: 0.7163 - acc: 0.8083\n",
            "Epoch 171/300\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.7133 - acc: 0.8083\n",
            "Epoch 172/300\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.7100 - acc: 0.8083\n",
            "Epoch 173/300\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.7071 - acc: 0.8083\n",
            "Epoch 174/300\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.7038 - acc: 0.8083\n",
            "Epoch 175/300\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.7003 - acc: 0.8167\n",
            "Epoch 176/300\n",
            "120/120 [==============================] - 0s 134us/step - loss: 0.6969 - acc: 0.8167\n",
            "Epoch 177/300\n",
            "120/120 [==============================] - 0s 127us/step - loss: 0.6932 - acc: 0.8167\n",
            "Epoch 178/300\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.6899 - acc: 0.8167\n",
            "Epoch 179/300\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.6866 - acc: 0.8250\n",
            "Epoch 180/300\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.6831 - acc: 0.8250\n",
            "Epoch 181/300\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.6796 - acc: 0.8333\n",
            "Epoch 182/300\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.6761 - acc: 0.8250\n",
            "Epoch 183/300\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.6727 - acc: 0.8333\n",
            "Epoch 184/300\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.6692 - acc: 0.8417\n",
            "Epoch 185/300\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.6657 - acc: 0.8583\n",
            "Epoch 186/300\n",
            "120/120 [==============================] - 0s 126us/step - loss: 0.6621 - acc: 0.8583\n",
            "Epoch 187/300\n",
            "120/120 [==============================] - 0s 117us/step - loss: 0.6588 - acc: 0.8583\n",
            "Epoch 188/300\n",
            "120/120 [==============================] - 0s 140us/step - loss: 0.6556 - acc: 0.8583\n",
            "Epoch 189/300\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.6523 - acc: 0.8500\n",
            "Epoch 190/300\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.6491 - acc: 0.8583\n",
            "Epoch 191/300\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.6460 - acc: 0.8500\n",
            "Epoch 192/300\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.6429 - acc: 0.8500\n",
            "Epoch 193/300\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.6394 - acc: 0.8500\n",
            "Epoch 194/300\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.6359 - acc: 0.8583\n",
            "Epoch 195/300\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.6324 - acc: 0.8583\n",
            "Epoch 196/300\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.6291 - acc: 0.8583\n",
            "Epoch 197/300\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.6258 - acc: 0.8583\n",
            "Epoch 198/300\n",
            "120/120 [==============================] - 0s 139us/step - loss: 0.6220 - acc: 0.8667\n",
            "Epoch 199/300\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.6186 - acc: 0.8667\n",
            "Epoch 200/300\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.6149 - acc: 0.8667\n",
            "Epoch 201/300\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.6115 - acc: 0.8667\n",
            "Epoch 202/300\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.6081 - acc: 0.8667\n",
            "Epoch 203/300\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.6044 - acc: 0.8667\n",
            "Epoch 204/300\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.6011 - acc: 0.8667\n",
            "Epoch 205/300\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.5975 - acc: 0.8750\n",
            "Epoch 206/300\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.5940 - acc: 0.8833\n",
            "Epoch 207/300\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.5906 - acc: 0.8833\n",
            "Epoch 208/300\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.5876 - acc: 0.8833\n",
            "Epoch 209/300\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.5844 - acc: 0.8833\n",
            "Epoch 210/300\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.5813 - acc: 0.8833\n",
            "Epoch 211/300\n",
            "120/120 [==============================] - 0s 141us/step - loss: 0.5781 - acc: 0.8833\n",
            "Epoch 212/300\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.5748 - acc: 0.8833\n",
            "Epoch 213/300\n",
            "120/120 [==============================] - 0s 120us/step - loss: 0.5716 - acc: 0.8833\n",
            "Epoch 214/300\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.5683 - acc: 0.8833\n",
            "Epoch 215/300\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.5647 - acc: 0.8833\n",
            "Epoch 216/300\n",
            "120/120 [==============================] - 0s 132us/step - loss: 0.5613 - acc: 0.8833\n",
            "Epoch 217/300\n",
            "120/120 [==============================] - 0s 141us/step - loss: 0.5576 - acc: 0.8833\n",
            "Epoch 218/300\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.5545 - acc: 0.8833\n",
            "Epoch 219/300\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.5510 - acc: 0.8833\n",
            "Epoch 220/300\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.5476 - acc: 0.8833\n",
            "Epoch 221/300\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.5447 - acc: 0.8833\n",
            "Epoch 222/300\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.5414 - acc: 0.8833\n",
            "Epoch 223/300\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.5378 - acc: 0.8833\n",
            "Epoch 224/300\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.5344 - acc: 0.8833\n",
            "Epoch 225/300\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.5314 - acc: 0.8833\n",
            "Epoch 226/300\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.5284 - acc: 0.8833\n",
            "Epoch 227/300\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.5256 - acc: 0.8833\n",
            "Epoch 228/300\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.5227 - acc: 0.8833\n",
            "Epoch 229/300\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.5195 - acc: 0.8833\n",
            "Epoch 230/300\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.5166 - acc: 0.8833\n",
            "Epoch 231/300\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.5136 - acc: 0.8917\n",
            "Epoch 232/300\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.5107 - acc: 0.8917\n",
            "Epoch 233/300\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.5077 - acc: 0.8917\n",
            "Epoch 234/300\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.5047 - acc: 0.8917\n",
            "Epoch 235/300\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.5013 - acc: 0.8917\n",
            "Epoch 236/300\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.4980 - acc: 0.8917\n",
            "Epoch 237/300\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.4950 - acc: 0.8917\n",
            "Epoch 238/300\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.4923 - acc: 0.8917\n",
            "Epoch 239/300\n",
            "120/120 [==============================] - 0s 119us/step - loss: 0.4891 - acc: 0.8917\n",
            "Epoch 240/300\n",
            "120/120 [==============================] - 0s 119us/step - loss: 0.4859 - acc: 0.8917\n",
            "Epoch 241/300\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.4828 - acc: 0.8917\n",
            "Epoch 242/300\n",
            "120/120 [==============================] - 0s 143us/step - loss: 0.4796 - acc: 0.8917\n",
            "Epoch 243/300\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.4764 - acc: 0.8917\n",
            "Epoch 244/300\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.4733 - acc: 0.8917\n",
            "Epoch 245/300\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.4703 - acc: 0.8917\n",
            "Epoch 246/300\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.4677 - acc: 0.8917\n",
            "Epoch 247/300\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.4650 - acc: 0.8917\n",
            "Epoch 248/300\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.4623 - acc: 0.8917\n",
            "Epoch 249/300\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.4596 - acc: 0.8917\n",
            "Epoch 250/300\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.4567 - acc: 0.8917\n",
            "Epoch 251/300\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.4539 - acc: 0.8917\n",
            "Epoch 252/300\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.4508 - acc: 0.8917\n",
            "Epoch 253/300\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.4476 - acc: 0.8917\n",
            "Epoch 254/300\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.4449 - acc: 0.8917\n",
            "Epoch 255/300\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.4423 - acc: 0.8917\n",
            "Epoch 256/300\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.4396 - acc: 0.8917\n",
            "Epoch 257/300\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.4369 - acc: 0.8917\n",
            "Epoch 258/300\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.4346 - acc: 0.8917\n",
            "Epoch 259/300\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.4322 - acc: 0.8917\n",
            "Epoch 260/300\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.4300 - acc: 0.8917\n",
            "Epoch 261/300\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.4273 - acc: 0.8917\n",
            "Epoch 262/300\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.4247 - acc: 0.8917\n",
            "Epoch 263/300\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.4223 - acc: 0.8917\n",
            "Epoch 264/300\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.4199 - acc: 0.8917\n",
            "Epoch 265/300\n",
            "120/120 [==============================] - 0s 115us/step - loss: 0.4174 - acc: 0.8917\n",
            "Epoch 266/300\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.4150 - acc: 0.8917\n",
            "Epoch 267/300\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.4126 - acc: 0.8917\n",
            "Epoch 268/300\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.4103 - acc: 0.8917\n",
            "Epoch 269/300\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.4077 - acc: 0.8917\n",
            "Epoch 270/300\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.4052 - acc: 0.8917\n",
            "Epoch 271/300\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.4031 - acc: 0.8917\n",
            "Epoch 272/300\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.4009 - acc: 0.8917\n",
            "Epoch 273/300\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.3986 - acc: 0.8917\n",
            "Epoch 274/300\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.3966 - acc: 0.8917\n",
            "Epoch 275/300\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.3946 - acc: 0.8917\n",
            "Epoch 276/300\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.3926 - acc: 0.8833\n",
            "Epoch 277/300\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.3906 - acc: 0.8833\n",
            "Epoch 278/300\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.3887 - acc: 0.8833\n",
            "Epoch 279/300\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.3867 - acc: 0.8833\n",
            "Epoch 280/300\n",
            "120/120 [==============================] - 0s 125us/step - loss: 0.3846 - acc: 0.8833\n",
            "Epoch 281/300\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.3830 - acc: 0.8833\n",
            "Epoch 282/300\n",
            "120/120 [==============================] - 0s 134us/step - loss: 0.3813 - acc: 0.8833\n",
            "Epoch 283/300\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.3799 - acc: 0.8917\n",
            "Epoch 284/300\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.3778 - acc: 0.8833\n",
            "Epoch 285/300\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.3758 - acc: 0.8833\n",
            "Epoch 286/300\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.3740 - acc: 0.8833\n",
            "Epoch 287/300\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.3722 - acc: 0.8833\n",
            "Epoch 288/300\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.3706 - acc: 0.8833\n",
            "Epoch 289/300\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.3691 - acc: 0.8833\n",
            "Epoch 290/300\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.3676 - acc: 0.8833\n",
            "Epoch 291/300\n",
            "120/120 [==============================] - 0s 157us/step - loss: 0.3658 - acc: 0.8833\n",
            "Epoch 292/300\n",
            "120/120 [==============================] - 0s 135us/step - loss: 0.3641 - acc: 0.8833\n",
            "Epoch 293/300\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.3624 - acc: 0.8833\n",
            "Epoch 294/300\n",
            "120/120 [==============================] - 0s 121us/step - loss: 0.3606 - acc: 0.8833\n",
            "Epoch 295/300\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.3591 - acc: 0.8833\n",
            "Epoch 296/300\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.3572 - acc: 0.8833\n",
            "Epoch 297/300\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.3556 - acc: 0.8833\n",
            "Epoch 298/300\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.3542 - acc: 0.8833\n",
            "Epoch 299/300\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.3527 - acc: 0.8833\n",
            "Epoch 300/300\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.3514 - acc: 0.8833\n",
            "60/60 [==============================] - 1s 9ms/step\n",
            "\n",
            "acc: 93.33%\n",
            "[[18  2  1]\n",
            " [ 0 19  0]\n",
            " [ 1  0 19]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.86      0.90        21\n",
            "           1       0.90      1.00      0.95        19\n",
            "           2       0.95      0.95      0.95        20\n",
            "\n",
            "    accuracy                           0.93        60\n",
            "   macro avg       0.93      0.94      0.93        60\n",
            "weighted avg       0.93      0.93      0.93        60\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_144 (Dense)            (None, 10)                30        \n",
            "_________________________________________________________________\n",
            "dense_145 (Dense)            (None, 20)                220       \n",
            "_________________________________________________________________\n",
            "dense_146 (Dense)            (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_147 (Dense)            (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_148 (Dense)            (None, 3)                 63        \n",
            "=================================================================\n",
            "Total params: 1,153\n",
            "Trainable params: 1,153\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/400\n",
            "120/120 [==============================] - 1s 11ms/step - loss: 1.1369 - acc: 0.0583\n",
            "Epoch 2/400\n",
            "120/120 [==============================] - 0s 117us/step - loss: 1.1297 - acc: 0.0833\n",
            "Epoch 3/400\n",
            "120/120 [==============================] - 0s 93us/step - loss: 1.1237 - acc: 0.0833\n",
            "Epoch 4/400\n",
            "120/120 [==============================] - 0s 94us/step - loss: 1.1168 - acc: 0.0917\n",
            "Epoch 5/400\n",
            "120/120 [==============================] - 0s 97us/step - loss: 1.1112 - acc: 0.1000\n",
            "Epoch 6/400\n",
            "120/120 [==============================] - 0s 108us/step - loss: 1.1057 - acc: 0.1083\n",
            "Epoch 7/400\n",
            "120/120 [==============================] - 0s 82us/step - loss: 1.1003 - acc: 0.1083\n",
            "Epoch 8/400\n",
            "120/120 [==============================] - 0s 82us/step - loss: 1.0952 - acc: 0.1333\n",
            "Epoch 9/400\n",
            "120/120 [==============================] - 0s 75us/step - loss: 1.0902 - acc: 0.1583\n",
            "Epoch 10/400\n",
            "120/120 [==============================] - 0s 83us/step - loss: 1.0853 - acc: 0.2000\n",
            "Epoch 11/400\n",
            "120/120 [==============================] - 0s 81us/step - loss: 1.0801 - acc: 0.2500\n",
            "Epoch 12/400\n",
            "120/120 [==============================] - 0s 81us/step - loss: 1.0759 - acc: 0.3000\n",
            "Epoch 13/400\n",
            "120/120 [==============================] - 0s 82us/step - loss: 1.0714 - acc: 0.3167\n",
            "Epoch 14/400\n",
            "120/120 [==============================] - 0s 83us/step - loss: 1.0674 - acc: 0.3333\n",
            "Epoch 15/400\n",
            "120/120 [==============================] - 0s 118us/step - loss: 1.0639 - acc: 0.3750\n",
            "Epoch 16/400\n",
            "120/120 [==============================] - 0s 138us/step - loss: 1.0595 - acc: 0.3917\n",
            "Epoch 17/400\n",
            "120/120 [==============================] - 0s 133us/step - loss: 1.0552 - acc: 0.4417\n",
            "Epoch 18/400\n",
            "120/120 [==============================] - 0s 80us/step - loss: 1.0513 - acc: 0.4750\n",
            "Epoch 19/400\n",
            "120/120 [==============================] - 0s 80us/step - loss: 1.0477 - acc: 0.4750\n",
            "Epoch 20/400\n",
            "120/120 [==============================] - 0s 120us/step - loss: 1.0443 - acc: 0.5000\n",
            "Epoch 21/400\n",
            "120/120 [==============================] - 0s 93us/step - loss: 1.0407 - acc: 0.4750\n",
            "Epoch 22/400\n",
            "120/120 [==============================] - 0s 85us/step - loss: 1.0374 - acc: 0.5000\n",
            "Epoch 23/400\n",
            "120/120 [==============================] - 0s 109us/step - loss: 1.0339 - acc: 0.5000\n",
            "Epoch 24/400\n",
            "120/120 [==============================] - 0s 119us/step - loss: 1.0303 - acc: 0.5333\n",
            "Epoch 25/400\n",
            "120/120 [==============================] - 0s 104us/step - loss: 1.0270 - acc: 0.5333\n",
            "Epoch 26/400\n",
            "120/120 [==============================] - 0s 90us/step - loss: 1.0237 - acc: 0.5583\n",
            "Epoch 27/400\n",
            "120/120 [==============================] - 0s 130us/step - loss: 1.0201 - acc: 0.5583\n",
            "Epoch 28/400\n",
            "120/120 [==============================] - 0s 87us/step - loss: 1.0170 - acc: 0.5667\n",
            "Epoch 29/400\n",
            "120/120 [==============================] - 0s 113us/step - loss: 1.0140 - acc: 0.5750\n",
            "Epoch 30/400\n",
            "120/120 [==============================] - 0s 102us/step - loss: 1.0106 - acc: 0.5750\n",
            "Epoch 31/400\n",
            "120/120 [==============================] - 0s 108us/step - loss: 1.0075 - acc: 0.5750\n",
            "Epoch 32/400\n",
            "120/120 [==============================] - 0s 128us/step - loss: 1.0047 - acc: 0.5917\n",
            "Epoch 33/400\n",
            "120/120 [==============================] - 0s 86us/step - loss: 1.0014 - acc: 0.5917\n",
            "Epoch 34/400\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.9983 - acc: 0.5917\n",
            "Epoch 35/400\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.9951 - acc: 0.5917\n",
            "Epoch 36/400\n",
            "120/120 [==============================] - 0s 129us/step - loss: 0.9921 - acc: 0.5917\n",
            "Epoch 37/400\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.9889 - acc: 0.5917\n",
            "Epoch 38/400\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.9861 - acc: 0.5917\n",
            "Epoch 39/400\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.9831 - acc: 0.5917\n",
            "Epoch 40/400\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.9798 - acc: 0.5917\n",
            "Epoch 41/400\n",
            "120/120 [==============================] - 0s 120us/step - loss: 0.9768 - acc: 0.5917\n",
            "Epoch 42/400\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.9736 - acc: 0.5917\n",
            "Epoch 43/400\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.9706 - acc: 0.5917\n",
            "Epoch 44/400\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.9679 - acc: 0.5917\n",
            "Epoch 45/400\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.9647 - acc: 0.5917\n",
            "Epoch 46/400\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.9620 - acc: 0.5917\n",
            "Epoch 47/400\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.9590 - acc: 0.5917\n",
            "Epoch 48/400\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.9563 - acc: 0.5917\n",
            "Epoch 49/400\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.9535 - acc: 0.5917\n",
            "Epoch 50/400\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.9503 - acc: 0.5917\n",
            "Epoch 51/400\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.9474 - acc: 0.5917\n",
            "Epoch 52/400\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.9446 - acc: 0.6000\n",
            "Epoch 53/400\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.9417 - acc: 0.5917\n",
            "Epoch 54/400\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.9386 - acc: 0.6000\n",
            "Epoch 55/400\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.9354 - acc: 0.6000\n",
            "Epoch 56/400\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.9322 - acc: 0.6000\n",
            "Epoch 57/400\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.9290 - acc: 0.6000\n",
            "Epoch 58/400\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.9260 - acc: 0.6000\n",
            "Epoch 59/400\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.9229 - acc: 0.6000\n",
            "Epoch 60/400\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.9199 - acc: 0.6000\n",
            "Epoch 61/400\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.9168 - acc: 0.6000\n",
            "Epoch 62/400\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.9130 - acc: 0.6000\n",
            "Epoch 63/400\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.9097 - acc: 0.6000\n",
            "Epoch 64/400\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.9065 - acc: 0.6000\n",
            "Epoch 65/400\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.9032 - acc: 0.6000\n",
            "Epoch 66/400\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.8998 - acc: 0.6000\n",
            "Epoch 67/400\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.8965 - acc: 0.6000\n",
            "Epoch 68/400\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.8934 - acc: 0.6000\n",
            "Epoch 69/400\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.8898 - acc: 0.6000\n",
            "Epoch 70/400\n",
            "120/120 [==============================] - 0s 133us/step - loss: 0.8863 - acc: 0.6000\n",
            "Epoch 71/400\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.8829 - acc: 0.6000\n",
            "Epoch 72/400\n",
            "120/120 [==============================] - 0s 120us/step - loss: 0.8799 - acc: 0.6000\n",
            "Epoch 73/400\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.8766 - acc: 0.6083\n",
            "Epoch 74/400\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.8732 - acc: 0.6000\n",
            "Epoch 75/400\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.8696 - acc: 0.6000\n",
            "Epoch 76/400\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.8664 - acc: 0.6000\n",
            "Epoch 77/400\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.8631 - acc: 0.6083\n",
            "Epoch 78/400\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.8598 - acc: 0.6083\n",
            "Epoch 79/400\n",
            "120/120 [==============================] - 0s 123us/step - loss: 0.8563 - acc: 0.6083\n",
            "Epoch 80/400\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.8529 - acc: 0.6250\n",
            "Epoch 81/400\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.8496 - acc: 0.6583\n",
            "Epoch 82/400\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.8459 - acc: 0.6333\n",
            "Epoch 83/400\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.8421 - acc: 0.6583\n",
            "Epoch 84/400\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.8387 - acc: 0.6583\n",
            "Epoch 85/400\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.8350 - acc: 0.6833\n",
            "Epoch 86/400\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.8312 - acc: 0.6833\n",
            "Epoch 87/400\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.8274 - acc: 0.6917\n",
            "Epoch 88/400\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.8236 - acc: 0.6917\n",
            "Epoch 89/400\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.8200 - acc: 0.6917\n",
            "Epoch 90/400\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.8166 - acc: 0.7083\n",
            "Epoch 91/400\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.8128 - acc: 0.7167\n",
            "Epoch 92/400\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.8090 - acc: 0.7250\n",
            "Epoch 93/400\n",
            "120/120 [==============================] - 0s 163us/step - loss: 0.8051 - acc: 0.7250\n",
            "Epoch 94/400\n",
            "120/120 [==============================] - 0s 75us/step - loss: 0.8015 - acc: 0.7333\n",
            "Epoch 95/400\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.7977 - acc: 0.7250\n",
            "Epoch 96/400\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.7941 - acc: 0.7333\n",
            "Epoch 97/400\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.7902 - acc: 0.7333\n",
            "Epoch 98/400\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.7865 - acc: 0.7583\n",
            "Epoch 99/400\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.7825 - acc: 0.7583\n",
            "Epoch 100/400\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.7785 - acc: 0.7750\n",
            "Epoch 101/400\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.7747 - acc: 0.7750\n",
            "Epoch 102/400\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.7709 - acc: 0.7833\n",
            "Epoch 103/400\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.7672 - acc: 0.7917\n",
            "Epoch 104/400\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.7637 - acc: 0.8167\n",
            "Epoch 105/400\n",
            "120/120 [==============================] - 0s 119us/step - loss: 0.7600 - acc: 0.8500\n",
            "Epoch 106/400\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.7561 - acc: 0.8500\n",
            "Epoch 107/400\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.7521 - acc: 0.8500\n",
            "Epoch 108/400\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.7481 - acc: 0.8583\n",
            "Epoch 109/400\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.7440 - acc: 0.8667\n",
            "Epoch 110/400\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.7401 - acc: 0.8667\n",
            "Epoch 111/400\n",
            "120/120 [==============================] - 0s 137us/step - loss: 0.7361 - acc: 0.8750\n",
            "Epoch 112/400\n",
            "120/120 [==============================] - 0s 117us/step - loss: 0.7319 - acc: 0.8750\n",
            "Epoch 113/400\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.7278 - acc: 0.8833\n",
            "Epoch 114/400\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.7237 - acc: 0.8833\n",
            "Epoch 115/400\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.7197 - acc: 0.8833\n",
            "Epoch 116/400\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.7155 - acc: 0.8750\n",
            "Epoch 117/400\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.7112 - acc: 0.9083\n",
            "Epoch 118/400\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.7069 - acc: 0.9083\n",
            "Epoch 119/400\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.7025 - acc: 0.9083\n",
            "Epoch 120/400\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.6982 - acc: 0.9000\n",
            "Epoch 121/400\n",
            "120/120 [==============================] - 0s 117us/step - loss: 0.6940 - acc: 0.9083\n",
            "Epoch 122/400\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.6902 - acc: 0.9000\n",
            "Epoch 123/400\n",
            "120/120 [==============================] - 0s 115us/step - loss: 0.6863 - acc: 0.9083\n",
            "Epoch 124/400\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.6824 - acc: 0.9000\n",
            "Epoch 125/400\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.6782 - acc: 0.9083\n",
            "Epoch 126/400\n",
            "120/120 [==============================] - 0s 177us/step - loss: 0.6742 - acc: 0.9083\n",
            "Epoch 127/400\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.6700 - acc: 0.9083\n",
            "Epoch 128/400\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.6657 - acc: 0.9083\n",
            "Epoch 129/400\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.6616 - acc: 0.9167\n",
            "Epoch 130/400\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.6576 - acc: 0.9083\n",
            "Epoch 131/400\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.6534 - acc: 0.9250\n",
            "Epoch 132/400\n",
            "120/120 [==============================] - 0s 115us/step - loss: 0.6492 - acc: 0.9167\n",
            "Epoch 133/400\n",
            "120/120 [==============================] - 0s 149us/step - loss: 0.6449 - acc: 0.9250\n",
            "Epoch 134/400\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.6408 - acc: 0.9250\n",
            "Epoch 135/400\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.6366 - acc: 0.9250\n",
            "Epoch 136/400\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.6326 - acc: 0.9250\n",
            "Epoch 137/400\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.6287 - acc: 0.9250\n",
            "Epoch 138/400\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.6249 - acc: 0.9250\n",
            "Epoch 139/400\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.6209 - acc: 0.9250\n",
            "Epoch 140/400\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.6174 - acc: 0.9250\n",
            "Epoch 141/400\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.6134 - acc: 0.9250\n",
            "Epoch 142/400\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.6092 - acc: 0.9250\n",
            "Epoch 143/400\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.6052 - acc: 0.9250\n",
            "Epoch 144/400\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.6014 - acc: 0.9250\n",
            "Epoch 145/400\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.5974 - acc: 0.9250\n",
            "Epoch 146/400\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.5929 - acc: 0.9250\n",
            "Epoch 147/400\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.5883 - acc: 0.9250\n",
            "Epoch 148/400\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.5834 - acc: 0.9250\n",
            "Epoch 149/400\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.5784 - acc: 0.9250\n",
            "Epoch 150/400\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.5734 - acc: 0.9250\n",
            "Epoch 151/400\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.5687 - acc: 0.9250\n",
            "Epoch 152/400\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.5640 - acc: 0.9250\n",
            "Epoch 153/400\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.5595 - acc: 0.9333\n",
            "Epoch 154/400\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.5547 - acc: 0.9250\n",
            "Epoch 155/400\n",
            "120/120 [==============================] - 0s 161us/step - loss: 0.5503 - acc: 0.9250\n",
            "Epoch 156/400\n",
            "120/120 [==============================] - 0s 171us/step - loss: 0.5458 - acc: 0.9250\n",
            "Epoch 157/400\n",
            "120/120 [==============================] - 0s 228us/step - loss: 0.5409 - acc: 0.9250\n",
            "Epoch 158/400\n",
            "120/120 [==============================] - 0s 132us/step - loss: 0.5364 - acc: 0.9333\n",
            "Epoch 159/400\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.5315 - acc: 0.9250\n",
            "Epoch 160/400\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.5263 - acc: 0.9250\n",
            "Epoch 161/400\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.5213 - acc: 0.9250\n",
            "Epoch 162/400\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.5167 - acc: 0.9250\n",
            "Epoch 163/400\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.5123 - acc: 0.9250\n",
            "Epoch 164/400\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.5078 - acc: 0.9250\n",
            "Epoch 165/400\n",
            "120/120 [==============================] - 0s 167us/step - loss: 0.5034 - acc: 0.9333\n",
            "Epoch 166/400\n",
            "120/120 [==============================] - 0s 153us/step - loss: 0.4991 - acc: 0.9333\n",
            "Epoch 167/400\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.4951 - acc: 0.9333\n",
            "Epoch 168/400\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.4912 - acc: 0.9333\n",
            "Epoch 169/400\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.4868 - acc: 0.9333\n",
            "Epoch 170/400\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.4822 - acc: 0.9333\n",
            "Epoch 171/400\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.4778 - acc: 0.9333\n",
            "Epoch 172/400\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.4735 - acc: 0.9333\n",
            "Epoch 173/400\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.4695 - acc: 0.9333\n",
            "Epoch 174/400\n",
            "120/120 [==============================] - 0s 129us/step - loss: 0.4656 - acc: 0.9333\n",
            "Epoch 175/400\n",
            "120/120 [==============================] - 0s 125us/step - loss: 0.4614 - acc: 0.9333\n",
            "Epoch 176/400\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.4572 - acc: 0.9333\n",
            "Epoch 177/400\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.4533 - acc: 0.9333\n",
            "Epoch 178/400\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.4493 - acc: 0.9333\n",
            "Epoch 179/400\n",
            "120/120 [==============================] - 0s 130us/step - loss: 0.4454 - acc: 0.9333\n",
            "Epoch 180/400\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.4418 - acc: 0.9333\n",
            "Epoch 181/400\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.4386 - acc: 0.9333\n",
            "Epoch 182/400\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.4350 - acc: 0.9333\n",
            "Epoch 183/400\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.4304 - acc: 0.9333\n",
            "Epoch 184/400\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.4266 - acc: 0.9333\n",
            "Epoch 185/400\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.4231 - acc: 0.9333\n",
            "Epoch 186/400\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.4195 - acc: 0.9333\n",
            "Epoch 187/400\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.4163 - acc: 0.9333\n",
            "Epoch 188/400\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.4135 - acc: 0.9333\n",
            "Epoch 189/400\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.4104 - acc: 0.9333\n",
            "Epoch 190/400\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.4069 - acc: 0.9333\n",
            "Epoch 191/400\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.4036 - acc: 0.9333\n",
            "Epoch 192/400\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.4003 - acc: 0.9333\n",
            "Epoch 193/400\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.3971 - acc: 0.9333\n",
            "Epoch 194/400\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.3937 - acc: 0.9333\n",
            "Epoch 195/400\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.3906 - acc: 0.9333\n",
            "Epoch 196/400\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.3874 - acc: 0.9333\n",
            "Epoch 197/400\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.3844 - acc: 0.9333\n",
            "Epoch 198/400\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.3814 - acc: 0.9333\n",
            "Epoch 199/400\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.3785 - acc: 0.9333\n",
            "Epoch 200/400\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.3755 - acc: 0.9333\n",
            "Epoch 201/400\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.3730 - acc: 0.9333\n",
            "Epoch 202/400\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.3700 - acc: 0.9333\n",
            "Epoch 203/400\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.3671 - acc: 0.9333\n",
            "Epoch 204/400\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.3642 - acc: 0.9333\n",
            "Epoch 205/400\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.3617 - acc: 0.9333\n",
            "Epoch 206/400\n",
            "120/120 [==============================] - 0s 123us/step - loss: 0.3589 - acc: 0.9333\n",
            "Epoch 207/400\n",
            "120/120 [==============================] - 0s 127us/step - loss: 0.3561 - acc: 0.9333\n",
            "Epoch 208/400\n",
            "120/120 [==============================] - 0s 132us/step - loss: 0.3534 - acc: 0.9333\n",
            "Epoch 209/400\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.3508 - acc: 0.9333\n",
            "Epoch 210/400\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.3484 - acc: 0.9333\n",
            "Epoch 211/400\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.3458 - acc: 0.9333\n",
            "Epoch 212/400\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.3434 - acc: 0.9333\n",
            "Epoch 213/400\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.3408 - acc: 0.9333\n",
            "Epoch 214/400\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.3386 - acc: 0.9333\n",
            "Epoch 215/400\n",
            "120/120 [==============================] - 0s 135us/step - loss: 0.3366 - acc: 0.9333\n",
            "Epoch 216/400\n",
            "120/120 [==============================] - 0s 76us/step - loss: 0.3343 - acc: 0.9333\n",
            "Epoch 217/400\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.3321 - acc: 0.9333\n",
            "Epoch 218/400\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.3295 - acc: 0.9333\n",
            "Epoch 219/400\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.3271 - acc: 0.9333\n",
            "Epoch 220/400\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.3249 - acc: 0.9333\n",
            "Epoch 221/400\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.3228 - acc: 0.9333\n",
            "Epoch 222/400\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.3208 - acc: 0.9333\n",
            "Epoch 223/400\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.3187 - acc: 0.9333\n",
            "Epoch 224/400\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.3169 - acc: 0.9333\n",
            "Epoch 225/400\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.3151 - acc: 0.9333\n",
            "Epoch 226/400\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.3134 - acc: 0.9333\n",
            "Epoch 227/400\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.3118 - acc: 0.9333\n",
            "Epoch 228/400\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.3099 - acc: 0.9333\n",
            "Epoch 229/400\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.3081 - acc: 0.9333\n",
            "Epoch 230/400\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.3062 - acc: 0.9333\n",
            "Epoch 231/400\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.3041 - acc: 0.9333\n",
            "Epoch 232/400\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.3023 - acc: 0.9333\n",
            "Epoch 233/400\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.3008 - acc: 0.9333\n",
            "Epoch 234/400\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2992 - acc: 0.9333\n",
            "Epoch 235/400\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2977 - acc: 0.9333\n",
            "Epoch 236/400\n",
            "120/120 [==============================] - 0s 121us/step - loss: 0.2958 - acc: 0.9333\n",
            "Epoch 237/400\n",
            "120/120 [==============================] - 0s 127us/step - loss: 0.2944 - acc: 0.9333\n",
            "Epoch 238/400\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2928 - acc: 0.9333\n",
            "Epoch 239/400\n",
            "120/120 [==============================] - 0s 75us/step - loss: 0.2912 - acc: 0.9333\n",
            "Epoch 240/400\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2897 - acc: 0.9333\n",
            "Epoch 241/400\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.2885 - acc: 0.9333\n",
            "Epoch 242/400\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2871 - acc: 0.9333\n",
            "Epoch 243/400\n",
            "120/120 [==============================] - 0s 115us/step - loss: 0.2859 - acc: 0.9333\n",
            "Epoch 244/400\n",
            "120/120 [==============================] - 0s 131us/step - loss: 0.2844 - acc: 0.9333\n",
            "Epoch 245/400\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2835 - acc: 0.9333\n",
            "Epoch 246/400\n",
            "120/120 [==============================] - 0s 131us/step - loss: 0.2822 - acc: 0.9333\n",
            "Epoch 247/400\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.2811 - acc: 0.9333\n",
            "Epoch 248/400\n",
            "120/120 [==============================] - 0s 123us/step - loss: 0.2798 - acc: 0.9333\n",
            "Epoch 249/400\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2786 - acc: 0.9333\n",
            "Epoch 250/400\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2772 - acc: 0.9333\n",
            "Epoch 251/400\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2760 - acc: 0.9333\n",
            "Epoch 252/400\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2748 - acc: 0.9333\n",
            "Epoch 253/400\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.2738 - acc: 0.9333\n",
            "Epoch 254/400\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2730 - acc: 0.9333\n",
            "Epoch 255/400\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2721 - acc: 0.9333\n",
            "Epoch 256/400\n",
            "120/120 [==============================] - 0s 119us/step - loss: 0.2710 - acc: 0.9333\n",
            "Epoch 257/400\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2700 - acc: 0.9333\n",
            "Epoch 258/400\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2689 - acc: 0.9333\n",
            "Epoch 259/400\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2677 - acc: 0.9333\n",
            "Epoch 260/400\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2666 - acc: 0.9333\n",
            "Epoch 261/400\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2656 - acc: 0.9333\n",
            "Epoch 262/400\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2646 - acc: 0.9333\n",
            "Epoch 263/400\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2635 - acc: 0.9333\n",
            "Epoch 264/400\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2626 - acc: 0.9333\n",
            "Epoch 265/400\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2617 - acc: 0.9333\n",
            "Epoch 266/400\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2608 - acc: 0.9333\n",
            "Epoch 267/400\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2599 - acc: 0.9333\n",
            "Epoch 268/400\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.2589 - acc: 0.9333\n",
            "Epoch 269/400\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2581 - acc: 0.9333\n",
            "Epoch 270/400\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2573 - acc: 0.9333\n",
            "Epoch 271/400\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2564 - acc: 0.9333\n",
            "Epoch 272/400\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.2557 - acc: 0.9333\n",
            "Epoch 273/400\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2549 - acc: 0.9333\n",
            "Epoch 274/400\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2542 - acc: 0.9333\n",
            "Epoch 275/400\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2533 - acc: 0.9333\n",
            "Epoch 276/400\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2525 - acc: 0.9333\n",
            "Epoch 277/400\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.2517 - acc: 0.9333\n",
            "Epoch 278/400\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2511 - acc: 0.9333\n",
            "Epoch 279/400\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2503 - acc: 0.9333\n",
            "Epoch 280/400\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2496 - acc: 0.9333\n",
            "Epoch 281/400\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2489 - acc: 0.9333\n",
            "Epoch 282/400\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2483 - acc: 0.9333\n",
            "Epoch 283/400\n",
            "120/120 [==============================] - 0s 117us/step - loss: 0.2478 - acc: 0.9333\n",
            "Epoch 284/400\n",
            "120/120 [==============================] - 0s 76us/step - loss: 0.2471 - acc: 0.9333\n",
            "Epoch 285/400\n",
            "120/120 [==============================] - 0s 161us/step - loss: 0.2465 - acc: 0.9333\n",
            "Epoch 286/400\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2458 - acc: 0.9333\n",
            "Epoch 287/400\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.2452 - acc: 0.9333\n",
            "Epoch 288/400\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2444 - acc: 0.9333\n",
            "Epoch 289/400\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2437 - acc: 0.9333\n",
            "Epoch 290/400\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2434 - acc: 0.9333\n",
            "Epoch 291/400\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2428 - acc: 0.9333\n",
            "Epoch 292/400\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2420 - acc: 0.9333\n",
            "Epoch 293/400\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.2415 - acc: 0.9333\n",
            "Epoch 294/400\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.2411 - acc: 0.9333\n",
            "Epoch 295/400\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2405 - acc: 0.9333\n",
            "Epoch 296/400\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.2400 - acc: 0.9333\n",
            "Epoch 297/400\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.2399 - acc: 0.9333\n",
            "Epoch 298/400\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.2395 - acc: 0.9333\n",
            "Epoch 299/400\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2391 - acc: 0.9333\n",
            "Epoch 300/400\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2384 - acc: 0.9333\n",
            "Epoch 301/400\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2382 - acc: 0.9333\n",
            "Epoch 302/400\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2371 - acc: 0.9333\n",
            "Epoch 303/400\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2367 - acc: 0.9333\n",
            "Epoch 304/400\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.2362 - acc: 0.9333\n",
            "Epoch 305/400\n",
            "120/120 [==============================] - 0s 73us/step - loss: 0.2357 - acc: 0.9333\n",
            "Epoch 306/400\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2352 - acc: 0.9333\n",
            "Epoch 307/400\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2349 - acc: 0.9333\n",
            "Epoch 308/400\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.2343 - acc: 0.9333\n",
            "Epoch 309/400\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.2339 - acc: 0.9333\n",
            "Epoch 310/400\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2334 - acc: 0.9333\n",
            "Epoch 311/400\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2331 - acc: 0.9333\n",
            "Epoch 312/400\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2327 - acc: 0.9333\n",
            "Epoch 313/400\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.2322 - acc: 0.9333\n",
            "Epoch 314/400\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2317 - acc: 0.9333\n",
            "Epoch 315/400\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2313 - acc: 0.9333\n",
            "Epoch 316/400\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.2308 - acc: 0.9333\n",
            "Epoch 317/400\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2305 - acc: 0.9333\n",
            "Epoch 318/400\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2303 - acc: 0.9333\n",
            "Epoch 319/400\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2302 - acc: 0.9333\n",
            "Epoch 320/400\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2300 - acc: 0.9333\n",
            "Epoch 321/400\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2295 - acc: 0.9333\n",
            "Epoch 322/400\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2290 - acc: 0.9333\n",
            "Epoch 323/400\n",
            "120/120 [==============================] - 0s 142us/step - loss: 0.2288 - acc: 0.9333\n",
            "Epoch 324/400\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.2282 - acc: 0.9333\n",
            "Epoch 325/400\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2277 - acc: 0.9333\n",
            "Epoch 326/400\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2274 - acc: 0.9333\n",
            "Epoch 327/400\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2270 - acc: 0.9333\n",
            "Epoch 328/400\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2263 - acc: 0.9333\n",
            "Epoch 329/400\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2257 - acc: 0.9333\n",
            "Epoch 330/400\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2253 - acc: 0.9333\n",
            "Epoch 331/400\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2251 - acc: 0.9333\n",
            "Epoch 332/400\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2247 - acc: 0.9333\n",
            "Epoch 333/400\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.2244 - acc: 0.9333\n",
            "Epoch 334/400\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2241 - acc: 0.9333\n",
            "Epoch 335/400\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.2239 - acc: 0.9333\n",
            "Epoch 336/400\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2235 - acc: 0.9333\n",
            "Epoch 337/400\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2232 - acc: 0.9333\n",
            "Epoch 338/400\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2229 - acc: 0.9333\n",
            "Epoch 339/400\n",
            "120/120 [==============================] - 0s 76us/step - loss: 0.2226 - acc: 0.9333\n",
            "Epoch 340/400\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2223 - acc: 0.9333\n",
            "Epoch 341/400\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.2220 - acc: 0.9333\n",
            "Epoch 342/400\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2217 - acc: 0.9333\n",
            "Epoch 343/400\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2216 - acc: 0.9333\n",
            "Epoch 344/400\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2215 - acc: 0.9333\n",
            "Epoch 345/400\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2209 - acc: 0.9333\n",
            "Epoch 346/400\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.2208 - acc: 0.9333\n",
            "Epoch 347/400\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.2206 - acc: 0.9333\n",
            "Epoch 348/400\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2202 - acc: 0.9333\n",
            "Epoch 349/400\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.2198 - acc: 0.9333\n",
            "Epoch 350/400\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2194 - acc: 0.9333\n",
            "Epoch 351/400\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2191 - acc: 0.9333\n",
            "Epoch 352/400\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2190 - acc: 0.9333\n",
            "Epoch 353/400\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2186 - acc: 0.9333\n",
            "Epoch 354/400\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2183 - acc: 0.9333\n",
            "Epoch 355/400\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2181 - acc: 0.9333\n",
            "Epoch 356/400\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2179 - acc: 0.9333\n",
            "Epoch 357/400\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2176 - acc: 0.9333\n",
            "Epoch 358/400\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2174 - acc: 0.9333\n",
            "Epoch 359/400\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2171 - acc: 0.9333\n",
            "Epoch 360/400\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.2168 - acc: 0.9333\n",
            "Epoch 361/400\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2165 - acc: 0.9333\n",
            "Epoch 362/400\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2163 - acc: 0.9333\n",
            "Epoch 363/400\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2160 - acc: 0.9333\n",
            "Epoch 364/400\n",
            "120/120 [==============================] - 0s 119us/step - loss: 0.2157 - acc: 0.9333\n",
            "Epoch 365/400\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2156 - acc: 0.9333\n",
            "Epoch 366/400\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2155 - acc: 0.9333\n",
            "Epoch 367/400\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.2153 - acc: 0.9333\n",
            "Epoch 368/400\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.2148 - acc: 0.9333\n",
            "Epoch 369/400\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2145 - acc: 0.9333\n",
            "Epoch 370/400\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2144 - acc: 0.9333\n",
            "Epoch 371/400\n",
            "120/120 [==============================] - 0s 76us/step - loss: 0.2141 - acc: 0.9333\n",
            "Epoch 372/400\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2141 - acc: 0.9333\n",
            "Epoch 373/400\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2138 - acc: 0.9333\n",
            "Epoch 374/400\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2135 - acc: 0.9333\n",
            "Epoch 375/400\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2134 - acc: 0.9333\n",
            "Epoch 376/400\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2138 - acc: 0.9333\n",
            "Epoch 377/400\n",
            "120/120 [==============================] - 0s 121us/step - loss: 0.2128 - acc: 0.9333\n",
            "Epoch 378/400\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2126 - acc: 0.9333\n",
            "Epoch 379/400\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2123 - acc: 0.9333\n",
            "Epoch 380/400\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2120 - acc: 0.9333\n",
            "Epoch 381/400\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2119 - acc: 0.9333\n",
            "Epoch 382/400\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2118 - acc: 0.9333\n",
            "Epoch 383/400\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2116 - acc: 0.9333\n",
            "Epoch 384/400\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2113 - acc: 0.9333\n",
            "Epoch 385/400\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2112 - acc: 0.9333\n",
            "Epoch 386/400\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2112 - acc: 0.9333\n",
            "Epoch 387/400\n",
            "120/120 [==============================] - 0s 153us/step - loss: 0.2107 - acc: 0.9333\n",
            "Epoch 388/400\n",
            "120/120 [==============================] - 0s 115us/step - loss: 0.2105 - acc: 0.9333\n",
            "Epoch 389/400\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.2104 - acc: 0.9333\n",
            "Epoch 390/400\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2103 - acc: 0.9333\n",
            "Epoch 391/400\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2105 - acc: 0.9333\n",
            "Epoch 392/400\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2099 - acc: 0.9333\n",
            "Epoch 393/400\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.2097 - acc: 0.9333\n",
            "Epoch 394/400\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2095 - acc: 0.9333\n",
            "Epoch 395/400\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2095 - acc: 0.9333\n",
            "Epoch 396/400\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2096 - acc: 0.9333\n",
            "Epoch 397/400\n",
            "120/120 [==============================] - 0s 125us/step - loss: 0.2095 - acc: 0.9333\n",
            "Epoch 398/400\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2092 - acc: 0.9333\n",
            "Epoch 399/400\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2090 - acc: 0.9333\n",
            "Epoch 400/400\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2090 - acc: 0.9333\n",
            "60/60 [==============================] - 1s 9ms/step\n",
            "\n",
            "acc: 91.67%\n",
            "[[10  1  2]\n",
            " [ 1 20  0]\n",
            " [ 1  0 25]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.77      0.80        13\n",
            "           1       0.95      0.95      0.95        21\n",
            "           2       0.93      0.96      0.94        26\n",
            "\n",
            "    accuracy                           0.92        60\n",
            "   macro avg       0.90      0.89      0.90        60\n",
            "weighted avg       0.92      0.92      0.92        60\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_149 (Dense)            (None, 10)                30        \n",
            "_________________________________________________________________\n",
            "dense_150 (Dense)            (None, 20)                220       \n",
            "_________________________________________________________________\n",
            "dense_151 (Dense)            (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_152 (Dense)            (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_153 (Dense)            (None, 3)                 63        \n",
            "=================================================================\n",
            "Total params: 1,153\n",
            "Trainable params: 1,153\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.0873 - acc: 0.1083\n",
            "Epoch 2/500\n",
            "120/120 [==============================] - 0s 122us/step - loss: 1.0853 - acc: 0.1500\n",
            "Epoch 3/500\n",
            "120/120 [==============================] - 0s 79us/step - loss: 1.0832 - acc: 0.1417\n",
            "Epoch 4/500\n",
            "120/120 [==============================] - 0s 85us/step - loss: 1.0811 - acc: 0.1583\n",
            "Epoch 5/500\n",
            "120/120 [==============================] - 0s 97us/step - loss: 1.0792 - acc: 0.1917\n",
            "Epoch 6/500\n",
            "120/120 [==============================] - 0s 95us/step - loss: 1.0773 - acc: 0.2250\n",
            "Epoch 7/500\n",
            "120/120 [==============================] - 0s 96us/step - loss: 1.0754 - acc: 0.2667\n",
            "Epoch 8/500\n",
            "120/120 [==============================] - 0s 95us/step - loss: 1.0736 - acc: 0.3000\n",
            "Epoch 9/500\n",
            "120/120 [==============================] - 0s 91us/step - loss: 1.0718 - acc: 0.3167\n",
            "Epoch 10/500\n",
            "120/120 [==============================] - 0s 91us/step - loss: 1.0701 - acc: 0.3417\n",
            "Epoch 11/500\n",
            "120/120 [==============================] - 0s 90us/step - loss: 1.0681 - acc: 0.3333\n",
            "Epoch 12/500\n",
            "120/120 [==============================] - 0s 84us/step - loss: 1.0661 - acc: 0.3583\n",
            "Epoch 13/500\n",
            "120/120 [==============================] - 0s 89us/step - loss: 1.0642 - acc: 0.3667\n",
            "Epoch 14/500\n",
            "120/120 [==============================] - 0s 109us/step - loss: 1.0624 - acc: 0.3833\n",
            "Epoch 15/500\n",
            "120/120 [==============================] - 0s 73us/step - loss: 1.0606 - acc: 0.3833\n",
            "Epoch 16/500\n",
            "120/120 [==============================] - 0s 91us/step - loss: 1.0587 - acc: 0.4083\n",
            "Epoch 17/500\n",
            "120/120 [==============================] - 0s 83us/step - loss: 1.0569 - acc: 0.4417\n",
            "Epoch 18/500\n",
            "120/120 [==============================] - 0s 77us/step - loss: 1.0552 - acc: 0.4500\n",
            "Epoch 19/500\n",
            "120/120 [==============================] - 0s 95us/step - loss: 1.0535 - acc: 0.4417\n",
            "Epoch 20/500\n",
            "120/120 [==============================] - 0s 80us/step - loss: 1.0517 - acc: 0.4417\n",
            "Epoch 21/500\n",
            "120/120 [==============================] - 0s 74us/step - loss: 1.0499 - acc: 0.4583\n",
            "Epoch 22/500\n",
            "120/120 [==============================] - 0s 82us/step - loss: 1.0482 - acc: 0.4667\n",
            "Epoch 23/500\n",
            "120/120 [==============================] - 0s 81us/step - loss: 1.0464 - acc: 0.4750\n",
            "Epoch 24/500\n",
            "120/120 [==============================] - 0s 96us/step - loss: 1.0447 - acc: 0.4917\n",
            "Epoch 25/500\n",
            "120/120 [==============================] - 0s 82us/step - loss: 1.0431 - acc: 0.5250\n",
            "Epoch 26/500\n",
            "120/120 [==============================] - 0s 87us/step - loss: 1.0414 - acc: 0.5833\n",
            "Epoch 27/500\n",
            "120/120 [==============================] - 0s 77us/step - loss: 1.0395 - acc: 0.5667\n",
            "Epoch 28/500\n",
            "120/120 [==============================] - 0s 94us/step - loss: 1.0376 - acc: 0.5417\n",
            "Epoch 29/500\n",
            "120/120 [==============================] - 0s 105us/step - loss: 1.0358 - acc: 0.5833\n",
            "Epoch 30/500\n",
            "120/120 [==============================] - 0s 86us/step - loss: 1.0337 - acc: 0.5500\n",
            "Epoch 31/500\n",
            "120/120 [==============================] - 0s 77us/step - loss: 1.0318 - acc: 0.5583\n",
            "Epoch 32/500\n",
            "120/120 [==============================] - 0s 97us/step - loss: 1.0301 - acc: 0.6167\n",
            "Epoch 33/500\n",
            "120/120 [==============================] - 0s 105us/step - loss: 1.0282 - acc: 0.6167\n",
            "Epoch 34/500\n",
            "120/120 [==============================] - 0s 79us/step - loss: 1.0264 - acc: 0.6083\n",
            "Epoch 35/500\n",
            "120/120 [==============================] - 0s 81us/step - loss: 1.0243 - acc: 0.6500\n",
            "Epoch 36/500\n",
            "120/120 [==============================] - 0s 85us/step - loss: 1.0225 - acc: 0.6500\n",
            "Epoch 37/500\n",
            "120/120 [==============================] - 0s 82us/step - loss: 1.0206 - acc: 0.6667\n",
            "Epoch 38/500\n",
            "120/120 [==============================] - 0s 87us/step - loss: 1.0187 - acc: 0.6833\n",
            "Epoch 39/500\n",
            "120/120 [==============================] - 0s 91us/step - loss: 1.0170 - acc: 0.6917\n",
            "Epoch 40/500\n",
            "120/120 [==============================] - 0s 83us/step - loss: 1.0149 - acc: 0.6917\n",
            "Epoch 41/500\n",
            "120/120 [==============================] - 0s 98us/step - loss: 1.0127 - acc: 0.6917\n",
            "Epoch 42/500\n",
            "120/120 [==============================] - 0s 86us/step - loss: 1.0109 - acc: 0.6917\n",
            "Epoch 43/500\n",
            "120/120 [==============================] - 0s 86us/step - loss: 1.0090 - acc: 0.7167\n",
            "Epoch 44/500\n",
            "120/120 [==============================] - 0s 88us/step - loss: 1.0068 - acc: 0.7000\n",
            "Epoch 45/500\n",
            "120/120 [==============================] - 0s 83us/step - loss: 1.0050 - acc: 0.7000\n",
            "Epoch 46/500\n",
            "120/120 [==============================] - 0s 86us/step - loss: 1.0031 - acc: 0.7167\n",
            "Epoch 47/500\n",
            "120/120 [==============================] - 0s 104us/step - loss: 1.0012 - acc: 0.7167\n",
            "Epoch 48/500\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.9993 - acc: 0.7167\n",
            "Epoch 49/500\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.9974 - acc: 0.7083\n",
            "Epoch 50/500\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.9955 - acc: 0.7167\n",
            "Epoch 51/500\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.9932 - acc: 0.7167\n",
            "Epoch 52/500\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.9910 - acc: 0.7167\n",
            "Epoch 53/500\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.9890 - acc: 0.7167\n",
            "Epoch 54/500\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.9872 - acc: 0.7167\n",
            "Epoch 55/500\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.9854 - acc: 0.7167\n",
            "Epoch 56/500\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.9832 - acc: 0.7167\n",
            "Epoch 57/500\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.9812 - acc: 0.7167\n",
            "Epoch 58/500\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.9787 - acc: 0.7250\n",
            "Epoch 59/500\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.9765 - acc: 0.7333\n",
            "Epoch 60/500\n",
            "120/120 [==============================] - 0s 75us/step - loss: 0.9744 - acc: 0.7333\n",
            "Epoch 61/500\n",
            "120/120 [==============================] - 0s 73us/step - loss: 0.9721 - acc: 0.7333\n",
            "Epoch 62/500\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.9700 - acc: 0.7333\n",
            "Epoch 63/500\n",
            "120/120 [==============================] - 0s 154us/step - loss: 0.9680 - acc: 0.7333\n",
            "Epoch 64/500\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.9659 - acc: 0.7333\n",
            "Epoch 65/500\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.9639 - acc: 0.7333\n",
            "Epoch 66/500\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.9618 - acc: 0.7417\n",
            "Epoch 67/500\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.9598 - acc: 0.7417\n",
            "Epoch 68/500\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.9576 - acc: 0.7417\n",
            "Epoch 69/500\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.9552 - acc: 0.7417\n",
            "Epoch 70/500\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.9531 - acc: 0.7417\n",
            "Epoch 71/500\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.9509 - acc: 0.7417\n",
            "Epoch 72/500\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.9487 - acc: 0.7417\n",
            "Epoch 73/500\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.9465 - acc: 0.7417\n",
            "Epoch 74/500\n",
            "120/120 [==============================] - 0s 126us/step - loss: 0.9440 - acc: 0.7417\n",
            "Epoch 75/500\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.9415 - acc: 0.7500\n",
            "Epoch 76/500\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.9393 - acc: 0.7500\n",
            "Epoch 77/500\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.9366 - acc: 0.7500\n",
            "Epoch 78/500\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.9345 - acc: 0.7500\n",
            "Epoch 79/500\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.9323 - acc: 0.7500\n",
            "Epoch 80/500\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.9297 - acc: 0.7500\n",
            "Epoch 81/500\n",
            "120/120 [==============================] - 0s 76us/step - loss: 0.9274 - acc: 0.7500\n",
            "Epoch 82/500\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.9249 - acc: 0.7500\n",
            "Epoch 83/500\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.9227 - acc: 0.7500\n",
            "Epoch 84/500\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.9205 - acc: 0.7500\n",
            "Epoch 85/500\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.9181 - acc: 0.7500\n",
            "Epoch 86/500\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.9157 - acc: 0.7500\n",
            "Epoch 87/500\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.9136 - acc: 0.7583\n",
            "Epoch 88/500\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.9113 - acc: 0.7583\n",
            "Epoch 89/500\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.9087 - acc: 0.7667\n",
            "Epoch 90/500\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.9064 - acc: 0.7667\n",
            "Epoch 91/500\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.9041 - acc: 0.7667\n",
            "Epoch 92/500\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.9017 - acc: 0.7667\n",
            "Epoch 93/500\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.8994 - acc: 0.7667\n",
            "Epoch 94/500\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.8968 - acc: 0.7667\n",
            "Epoch 95/500\n",
            "120/120 [==============================] - 0s 121us/step - loss: 0.8941 - acc: 0.7750\n",
            "Epoch 96/500\n",
            "120/120 [==============================] - 0s 126us/step - loss: 0.8916 - acc: 0.7833\n",
            "Epoch 97/500\n",
            "120/120 [==============================] - 0s 134us/step - loss: 0.8889 - acc: 0.7833\n",
            "Epoch 98/500\n",
            "120/120 [==============================] - 0s 147us/step - loss: 0.8863 - acc: 0.7833\n",
            "Epoch 99/500\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.8840 - acc: 0.7833\n",
            "Epoch 100/500\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.8812 - acc: 0.7833\n",
            "Epoch 101/500\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.8787 - acc: 0.7833\n",
            "Epoch 102/500\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.8761 - acc: 0.7833\n",
            "Epoch 103/500\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.8736 - acc: 0.7833\n",
            "Epoch 104/500\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.8711 - acc: 0.7833\n",
            "Epoch 105/500\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.8688 - acc: 0.7833\n",
            "Epoch 106/500\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.8664 - acc: 0.7917\n",
            "Epoch 107/500\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.8635 - acc: 0.7917\n",
            "Epoch 108/500\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.8607 - acc: 0.7833\n",
            "Epoch 109/500\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.8582 - acc: 0.8000\n",
            "Epoch 110/500\n",
            "120/120 [==============================] - 0s 75us/step - loss: 0.8557 - acc: 0.7917\n",
            "Epoch 111/500\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.8532 - acc: 0.7917\n",
            "Epoch 112/500\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.8507 - acc: 0.7917\n",
            "Epoch 113/500\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.8480 - acc: 0.7917\n",
            "Epoch 114/500\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.8455 - acc: 0.7917\n",
            "Epoch 115/500\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.8429 - acc: 0.8000\n",
            "Epoch 116/500\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.8400 - acc: 0.7917\n",
            "Epoch 117/500\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.8374 - acc: 0.7917\n",
            "Epoch 118/500\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.8347 - acc: 0.7833\n",
            "Epoch 119/500\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.8319 - acc: 0.7917\n",
            "Epoch 120/500\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.8293 - acc: 0.7833\n",
            "Epoch 121/500\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.8265 - acc: 0.7917\n",
            "Epoch 122/500\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.8238 - acc: 0.7917\n",
            "Epoch 123/500\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.8210 - acc: 0.8083\n",
            "Epoch 124/500\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.8184 - acc: 0.8083\n",
            "Epoch 125/500\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.8159 - acc: 0.8083\n",
            "Epoch 126/500\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.8134 - acc: 0.8083\n",
            "Epoch 127/500\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.8104 - acc: 0.8083\n",
            "Epoch 128/500\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.8077 - acc: 0.8083\n",
            "Epoch 129/500\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.8048 - acc: 0.8000\n",
            "Epoch 130/500\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.8022 - acc: 0.8083\n",
            "Epoch 131/500\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.7995 - acc: 0.8000\n",
            "Epoch 132/500\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.7967 - acc: 0.8083\n",
            "Epoch 133/500\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.7941 - acc: 0.8167\n",
            "Epoch 134/500\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.7915 - acc: 0.8167\n",
            "Epoch 135/500\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.7887 - acc: 0.8167\n",
            "Epoch 136/500\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.7860 - acc: 0.8167\n",
            "Epoch 137/500\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.7832 - acc: 0.8167\n",
            "Epoch 138/500\n",
            "120/120 [==============================] - 0s 125us/step - loss: 0.7803 - acc: 0.8167\n",
            "Epoch 139/500\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.7774 - acc: 0.8167\n",
            "Epoch 140/500\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.7747 - acc: 0.8167\n",
            "Epoch 141/500\n",
            "120/120 [==============================] - 0s 134us/step - loss: 0.7719 - acc: 0.8167\n",
            "Epoch 142/500\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.7693 - acc: 0.8167\n",
            "Epoch 143/500\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.7666 - acc: 0.8167\n",
            "Epoch 144/500\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.7639 - acc: 0.8167\n",
            "Epoch 145/500\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.7611 - acc: 0.8167\n",
            "Epoch 146/500\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.7586 - acc: 0.8167\n",
            "Epoch 147/500\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.7558 - acc: 0.8167\n",
            "Epoch 148/500\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.7530 - acc: 0.8167\n",
            "Epoch 149/500\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.7503 - acc: 0.8167\n",
            "Epoch 150/500\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.7474 - acc: 0.8167\n",
            "Epoch 151/500\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.7449 - acc: 0.8167\n",
            "Epoch 152/500\n",
            "120/120 [==============================] - 0s 76us/step - loss: 0.7425 - acc: 0.8167\n",
            "Epoch 153/500\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.7398 - acc: 0.8167\n",
            "Epoch 154/500\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.7370 - acc: 0.8167\n",
            "Epoch 155/500\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.7342 - acc: 0.8083\n",
            "Epoch 156/500\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.7315 - acc: 0.8083\n",
            "Epoch 157/500\n",
            "120/120 [==============================] - 0s 76us/step - loss: 0.7289 - acc: 0.8167\n",
            "Epoch 158/500\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.7260 - acc: 0.8167\n",
            "Epoch 159/500\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.7233 - acc: 0.8167\n",
            "Epoch 160/500\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.7207 - acc: 0.8083\n",
            "Epoch 161/500\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.7182 - acc: 0.8167\n",
            "Epoch 162/500\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.7155 - acc: 0.8167\n",
            "Epoch 163/500\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.7130 - acc: 0.8167\n",
            "Epoch 164/500\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.7102 - acc: 0.8167\n",
            "Epoch 165/500\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.7076 - acc: 0.8083\n",
            "Epoch 166/500\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.7048 - acc: 0.8083\n",
            "Epoch 167/500\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.7020 - acc: 0.8167\n",
            "Epoch 168/500\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.6992 - acc: 0.8083\n",
            "Epoch 169/500\n",
            "120/120 [==============================] - 0s 74us/step - loss: 0.6965 - acc: 0.8083\n",
            "Epoch 170/500\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.6939 - acc: 0.8083\n",
            "Epoch 171/500\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.6914 - acc: 0.8167\n",
            "Epoch 172/500\n",
            "120/120 [==============================] - 0s 77us/step - loss: 0.6888 - acc: 0.8167\n",
            "Epoch 173/500\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.6862 - acc: 0.8167\n",
            "Epoch 174/500\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.6836 - acc: 0.8083\n",
            "Epoch 175/500\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.6810 - acc: 0.8167\n",
            "Epoch 176/500\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.6785 - acc: 0.8167\n",
            "Epoch 177/500\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.6759 - acc: 0.8167\n",
            "Epoch 178/500\n",
            "120/120 [==============================] - 0s 193us/step - loss: 0.6733 - acc: 0.8167\n",
            "Epoch 179/500\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.6707 - acc: 0.8167\n",
            "Epoch 180/500\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.6681 - acc: 0.8167\n",
            "Epoch 181/500\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.6655 - acc: 0.8083\n",
            "Epoch 182/500\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.6628 - acc: 0.8167\n",
            "Epoch 183/500\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.6600 - acc: 0.8250\n",
            "Epoch 184/500\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.6572 - acc: 0.8167\n",
            "Epoch 185/500\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.6545 - acc: 0.8250\n",
            "Epoch 186/500\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.6520 - acc: 0.8167\n",
            "Epoch 187/500\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.6494 - acc: 0.8250\n",
            "Epoch 188/500\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.6468 - acc: 0.8167\n",
            "Epoch 189/500\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.6441 - acc: 0.8167\n",
            "Epoch 190/500\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.6418 - acc: 0.8167\n",
            "Epoch 191/500\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.6394 - acc: 0.8167\n",
            "Epoch 192/500\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.6369 - acc: 0.8250\n",
            "Epoch 193/500\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.6345 - acc: 0.8250\n",
            "Epoch 194/500\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.6317 - acc: 0.8333\n",
            "Epoch 195/500\n",
            "120/120 [==============================] - 0s 73us/step - loss: 0.6291 - acc: 0.8333\n",
            "Epoch 196/500\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.6267 - acc: 0.8333\n",
            "Epoch 197/500\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.6242 - acc: 0.8333\n",
            "Epoch 198/500\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.6218 - acc: 0.8333\n",
            "Epoch 199/500\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.6194 - acc: 0.8333\n",
            "Epoch 200/500\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.6170 - acc: 0.8333\n",
            "Epoch 201/500\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.6145 - acc: 0.8333\n",
            "Epoch 202/500\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.6120 - acc: 0.8333\n",
            "Epoch 203/500\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.6099 - acc: 0.8333\n",
            "Epoch 204/500\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.6074 - acc: 0.8333\n",
            "Epoch 205/500\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.6050 - acc: 0.8333\n",
            "Epoch 206/500\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.6025 - acc: 0.8333\n",
            "Epoch 207/500\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.6002 - acc: 0.8333\n",
            "Epoch 208/500\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.5978 - acc: 0.8333\n",
            "Epoch 209/500\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.5954 - acc: 0.8333\n",
            "Epoch 210/500\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.5932 - acc: 0.8333\n",
            "Epoch 211/500\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.5908 - acc: 0.8333\n",
            "Epoch 212/500\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.5885 - acc: 0.8333\n",
            "Epoch 213/500\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.5862 - acc: 0.8333\n",
            "Epoch 214/500\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.5837 - acc: 0.8333\n",
            "Epoch 215/500\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.5812 - acc: 0.8333\n",
            "Epoch 216/500\n",
            "120/120 [==============================] - 0s 77us/step - loss: 0.5790 - acc: 0.8333\n",
            "Epoch 217/500\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.5768 - acc: 0.8333\n",
            "Epoch 218/500\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.5746 - acc: 0.8333\n",
            "Epoch 219/500\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.5723 - acc: 0.8333\n",
            "Epoch 220/500\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.5702 - acc: 0.8333\n",
            "Epoch 221/500\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.5682 - acc: 0.8333\n",
            "Epoch 222/500\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.5657 - acc: 0.8333\n",
            "Epoch 223/500\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.5634 - acc: 0.8333\n",
            "Epoch 224/500\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.5612 - acc: 0.8333\n",
            "Epoch 225/500\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.5589 - acc: 0.8333\n",
            "Epoch 226/500\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.5566 - acc: 0.8333\n",
            "Epoch 227/500\n",
            "120/120 [==============================] - 0s 129us/step - loss: 0.5545 - acc: 0.8333\n",
            "Epoch 228/500\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.5524 - acc: 0.8333\n",
            "Epoch 229/500\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.5503 - acc: 0.8333\n",
            "Epoch 230/500\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.5480 - acc: 0.8333\n",
            "Epoch 231/500\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.5460 - acc: 0.8333\n",
            "Epoch 232/500\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.5439 - acc: 0.8333\n",
            "Epoch 233/500\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.5418 - acc: 0.8333\n",
            "Epoch 234/500\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.5397 - acc: 0.8333\n",
            "Epoch 235/500\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.5380 - acc: 0.8333\n",
            "Epoch 236/500\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.5359 - acc: 0.8333\n",
            "Epoch 237/500\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.5338 - acc: 0.8333\n",
            "Epoch 238/500\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.5321 - acc: 0.8333\n",
            "Epoch 239/500\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.5303 - acc: 0.8417\n",
            "Epoch 240/500\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.5282 - acc: 0.8333\n",
            "Epoch 241/500\n",
            "120/120 [==============================] - 0s 117us/step - loss: 0.5262 - acc: 0.8333\n",
            "Epoch 242/500\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.5243 - acc: 0.8333\n",
            "Epoch 243/500\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.5221 - acc: 0.8333\n",
            "Epoch 244/500\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.5202 - acc: 0.8417\n",
            "Epoch 245/500\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.5185 - acc: 0.8417\n",
            "Epoch 246/500\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.5166 - acc: 0.8417\n",
            "Epoch 247/500\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.5146 - acc: 0.8333\n",
            "Epoch 248/500\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.5125 - acc: 0.8417\n",
            "Epoch 249/500\n",
            "120/120 [==============================] - 0s 71us/step - loss: 0.5107 - acc: 0.8333\n",
            "Epoch 250/500\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.5087 - acc: 0.8417\n",
            "Epoch 251/500\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.5070 - acc: 0.8417\n",
            "Epoch 252/500\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.5050 - acc: 0.8417\n",
            "Epoch 253/500\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.5033 - acc: 0.8417\n",
            "Epoch 254/500\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.5015 - acc: 0.8333\n",
            "Epoch 255/500\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.4997 - acc: 0.8333\n",
            "Epoch 256/500\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.4980 - acc: 0.8333\n",
            "Epoch 257/500\n",
            "120/120 [==============================] - 0s 119us/step - loss: 0.4964 - acc: 0.8417\n",
            "Epoch 258/500\n",
            "120/120 [==============================] - 0s 135us/step - loss: 0.4946 - acc: 0.8417\n",
            "Epoch 259/500\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.4929 - acc: 0.8417\n",
            "Epoch 260/500\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.4909 - acc: 0.8417\n",
            "Epoch 261/500\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.4892 - acc: 0.8417\n",
            "Epoch 262/500\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.4875 - acc: 0.8333\n",
            "Epoch 263/500\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.4859 - acc: 0.8333\n",
            "Epoch 264/500\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.4843 - acc: 0.8333\n",
            "Epoch 265/500\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.4828 - acc: 0.8333\n",
            "Epoch 266/500\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.4814 - acc: 0.8250\n",
            "Epoch 267/500\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.4797 - acc: 0.8333\n",
            "Epoch 268/500\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.4781 - acc: 0.8333\n",
            "Epoch 269/500\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.4764 - acc: 0.8333\n",
            "Epoch 270/500\n",
            "120/120 [==============================] - 0s 133us/step - loss: 0.4747 - acc: 0.8333\n",
            "Epoch 271/500\n",
            "120/120 [==============================] - 0s 135us/step - loss: 0.4730 - acc: 0.8333\n",
            "Epoch 272/500\n",
            "120/120 [==============================] - 0s 76us/step - loss: 0.4717 - acc: 0.8333\n",
            "Epoch 273/500\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.4701 - acc: 0.8333\n",
            "Epoch 274/500\n",
            "120/120 [==============================] - 0s 132us/step - loss: 0.4684 - acc: 0.8333\n",
            "Epoch 275/500\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.4665 - acc: 0.8333\n",
            "Epoch 276/500\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.4651 - acc: 0.8333\n",
            "Epoch 277/500\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.4638 - acc: 0.8333\n",
            "Epoch 278/500\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.4619 - acc: 0.8417\n",
            "Epoch 279/500\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.4605 - acc: 0.8333\n",
            "Epoch 280/500\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.4588 - acc: 0.8250\n",
            "Epoch 281/500\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.4573 - acc: 0.8333\n",
            "Epoch 282/500\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.4560 - acc: 0.8333\n",
            "Epoch 283/500\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.4544 - acc: 0.8250\n",
            "Epoch 284/500\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.4530 - acc: 0.8333\n",
            "Epoch 285/500\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.4519 - acc: 0.8417\n",
            "Epoch 286/500\n",
            "120/120 [==============================] - 0s 135us/step - loss: 0.4503 - acc: 0.8333\n",
            "Epoch 287/500\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.4489 - acc: 0.8333\n",
            "Epoch 288/500\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.4477 - acc: 0.8333\n",
            "Epoch 289/500\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.4468 - acc: 0.8333\n",
            "Epoch 290/500\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.4454 - acc: 0.8333\n",
            "Epoch 291/500\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.4439 - acc: 0.8333\n",
            "Epoch 292/500\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.4424 - acc: 0.8333\n",
            "Epoch 293/500\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.4411 - acc: 0.8333\n",
            "Epoch 294/500\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.4395 - acc: 0.8333\n",
            "Epoch 295/500\n",
            "120/120 [==============================] - 0s 74us/step - loss: 0.4382 - acc: 0.8333\n",
            "Epoch 296/500\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.4368 - acc: 0.8333\n",
            "Epoch 297/500\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.4356 - acc: 0.8333\n",
            "Epoch 298/500\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.4343 - acc: 0.8417\n",
            "Epoch 299/500\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.4331 - acc: 0.8417\n",
            "Epoch 300/500\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.4317 - acc: 0.8333\n",
            "Epoch 301/500\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.4305 - acc: 0.8333\n",
            "Epoch 302/500\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.4291 - acc: 0.8333\n",
            "Epoch 303/500\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.4282 - acc: 0.8333\n",
            "Epoch 304/500\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.4270 - acc: 0.8333\n",
            "Epoch 305/500\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.4257 - acc: 0.8333\n",
            "Epoch 306/500\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.4244 - acc: 0.8333\n",
            "Epoch 307/500\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.4233 - acc: 0.8333\n",
            "Epoch 308/500\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.4222 - acc: 0.8333\n",
            "Epoch 309/500\n",
            "120/120 [==============================] - 0s 146us/step - loss: 0.4210 - acc: 0.8333\n",
            "Epoch 310/500\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.4200 - acc: 0.8333\n",
            "Epoch 311/500\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.4190 - acc: 0.8333\n",
            "Epoch 312/500\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.4181 - acc: 0.8333\n",
            "Epoch 313/500\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.4173 - acc: 0.8417\n",
            "Epoch 314/500\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.4161 - acc: 0.8417\n",
            "Epoch 315/500\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.4149 - acc: 0.8333\n",
            "Epoch 316/500\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.4136 - acc: 0.8333\n",
            "Epoch 317/500\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.4125 - acc: 0.8333\n",
            "Epoch 318/500\n",
            "120/120 [==============================] - 0s 73us/step - loss: 0.4115 - acc: 0.8333\n",
            "Epoch 319/500\n",
            "120/120 [==============================] - 0s 73us/step - loss: 0.4101 - acc: 0.8333\n",
            "Epoch 320/500\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.4088 - acc: 0.8333\n",
            "Epoch 321/500\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.4076 - acc: 0.8333\n",
            "Epoch 322/500\n",
            "120/120 [==============================] - 0s 75us/step - loss: 0.4065 - acc: 0.8333\n",
            "Epoch 323/500\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.4055 - acc: 0.8333\n",
            "Epoch 324/500\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.4046 - acc: 0.8333\n",
            "Epoch 325/500\n",
            "120/120 [==============================] - 0s 76us/step - loss: 0.4033 - acc: 0.8333\n",
            "Epoch 326/500\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.4020 - acc: 0.8333\n",
            "Epoch 327/500\n",
            "120/120 [==============================] - 0s 75us/step - loss: 0.4010 - acc: 0.8333\n",
            "Epoch 328/500\n",
            "100/120 [========================>.....] - ETA: 0s - loss: 0.4071 - acc: 0.8100"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.341561). Check your callbacks.\n",
            "  % delta_t_median)\n",
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.170807). Check your callbacks.\n",
            "  % delta_t_median)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "120/120 [==============================] - 0s 77us/step - loss: 0.4000 - acc: 0.8333\n",
            "Epoch 329/500\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.3991 - acc: 0.8333\n",
            "Epoch 330/500\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.3979 - acc: 0.8417\n",
            "Epoch 331/500\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.3968 - acc: 0.8333\n",
            "Epoch 332/500\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.3957 - acc: 0.8417\n",
            "Epoch 333/500\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.3946 - acc: 0.8417\n",
            "Epoch 334/500\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.3936 - acc: 0.8417\n",
            "Epoch 335/500\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.3929 - acc: 0.8333\n",
            "Epoch 336/500\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.3918 - acc: 0.8417\n",
            "Epoch 337/500\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.3907 - acc: 0.8417\n",
            "Epoch 338/500\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.3897 - acc: 0.8417\n",
            "Epoch 339/500\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.3886 - acc: 0.8333\n",
            "Epoch 340/500\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.3877 - acc: 0.8333\n",
            "Epoch 341/500\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.3867 - acc: 0.8417\n",
            "Epoch 342/500\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.3857 - acc: 0.8417\n",
            "Epoch 343/500\n",
            "120/120 [==============================] - 0s 77us/step - loss: 0.3846 - acc: 0.8417\n",
            "Epoch 344/500\n",
            "120/120 [==============================] - 0s 76us/step - loss: 0.3837 - acc: 0.8333\n",
            "Epoch 345/500\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.3830 - acc: 0.8417\n",
            "Epoch 346/500\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.3820 - acc: 0.8333\n",
            "Epoch 347/500\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.3811 - acc: 0.8333\n",
            "Epoch 348/500\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.3803 - acc: 0.8333\n",
            "Epoch 349/500\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.3794 - acc: 0.8333\n",
            "Epoch 350/500\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.3787 - acc: 0.8333\n",
            "Epoch 351/500\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.3779 - acc: 0.8333\n",
            "Epoch 352/500\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.3767 - acc: 0.8333\n",
            "Epoch 353/500\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.3757 - acc: 0.8333\n",
            "Epoch 354/500\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.3750 - acc: 0.8333\n",
            "Epoch 355/500\n",
            "120/120 [==============================] - 0s 145us/step - loss: 0.3744 - acc: 0.8333\n",
            "Epoch 356/500\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.3735 - acc: 0.8333\n",
            "Epoch 357/500\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.3727 - acc: 0.8333\n",
            "Epoch 358/500\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.3719 - acc: 0.8417\n",
            "Epoch 359/500\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.3712 - acc: 0.8417\n",
            "Epoch 360/500\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.3703 - acc: 0.8333\n",
            "Epoch 361/500\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.3696 - acc: 0.8333\n",
            "Epoch 362/500\n",
            "120/120 [==============================] - 0s 74us/step - loss: 0.3685 - acc: 0.8333\n",
            "Epoch 363/500\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.3679 - acc: 0.8417\n",
            "Epoch 364/500\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.3672 - acc: 0.8417\n",
            "Epoch 365/500\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.3664 - acc: 0.8333\n",
            "Epoch 366/500\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.3656 - acc: 0.8333\n",
            "Epoch 367/500\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.3649 - acc: 0.8333\n",
            "Epoch 368/500\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.3642 - acc: 0.8417\n",
            "Epoch 369/500\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.3638 - acc: 0.8500\n",
            "Epoch 370/500\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.3633 - acc: 0.8500\n",
            "Epoch 371/500\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.3623 - acc: 0.8417\n",
            "Epoch 372/500\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.3615 - acc: 0.8333\n",
            "Epoch 373/500\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.3610 - acc: 0.8333\n",
            "Epoch 374/500\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.3602 - acc: 0.8333\n",
            "Epoch 375/500\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.3596 - acc: 0.8333\n",
            "Epoch 376/500\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.3592 - acc: 0.8333\n",
            "Epoch 377/500\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.3588 - acc: 0.8333\n",
            "Epoch 378/500\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.3582 - acc: 0.8333\n",
            "Epoch 379/500\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.3572 - acc: 0.8333\n",
            "Epoch 380/500\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.3567 - acc: 0.8333\n",
            "Epoch 381/500\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.3562 - acc: 0.8333\n",
            "Epoch 382/500\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.3555 - acc: 0.8333\n",
            "Epoch 383/500\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.3548 - acc: 0.8333\n",
            "Epoch 384/500\n",
            "120/120 [==============================] - 0s 121us/step - loss: 0.3542 - acc: 0.8333\n",
            "Epoch 385/500\n",
            "120/120 [==============================] - 0s 145us/step - loss: 0.3537 - acc: 0.8333\n",
            "Epoch 386/500\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.3531 - acc: 0.8333\n",
            "Epoch 387/500\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.3526 - acc: 0.8333\n",
            "Epoch 388/500\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.3520 - acc: 0.8333\n",
            "Epoch 389/500\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.3515 - acc: 0.8333\n",
            "Epoch 390/500\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.3508 - acc: 0.8333\n",
            "Epoch 391/500\n",
            "120/120 [==============================] - 0s 155us/step - loss: 0.3503 - acc: 0.8333\n",
            "Epoch 392/500\n",
            "120/120 [==============================] - 0s 128us/step - loss: 0.3495 - acc: 0.8333\n",
            "Epoch 393/500\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.3490 - acc: 0.8333\n",
            "Epoch 394/500\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.3484 - acc: 0.8333\n",
            "Epoch 395/500\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.3479 - acc: 0.8333\n",
            "Epoch 396/500\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.3475 - acc: 0.8333\n",
            "Epoch 397/500\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.3469 - acc: 0.8333\n",
            "Epoch 398/500\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.3467 - acc: 0.8333\n",
            "Epoch 399/500\n",
            "120/120 [==============================] - 0s 130us/step - loss: 0.3462 - acc: 0.8417\n",
            "Epoch 400/500\n",
            "120/120 [==============================] - 0s 115us/step - loss: 0.3455 - acc: 0.8417\n",
            "Epoch 401/500\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.3452 - acc: 0.8333\n",
            "Epoch 402/500\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.3447 - acc: 0.8333\n",
            "Epoch 403/500\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.3443 - acc: 0.8333\n",
            "Epoch 404/500\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.3438 - acc: 0.8333\n",
            "Epoch 405/500\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.3433 - acc: 0.8333\n",
            "Epoch 406/500\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.3431 - acc: 0.8333\n",
            "Epoch 407/500\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.3425 - acc: 0.8333\n",
            "Epoch 408/500\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.3420 - acc: 0.8333\n",
            "Epoch 409/500\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.3415 - acc: 0.8333\n",
            "Epoch 410/500\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.3412 - acc: 0.8333\n",
            "Epoch 411/500\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.3409 - acc: 0.8333\n",
            "Epoch 412/500\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.3404 - acc: 0.8333\n",
            "Epoch 413/500\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.3400 - acc: 0.8333\n",
            "Epoch 414/500\n",
            "120/120 [==============================] - 0s 119us/step - loss: 0.3395 - acc: 0.8333\n",
            "Epoch 415/500\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.3388 - acc: 0.8333\n",
            "Epoch 416/500\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.3383 - acc: 0.8333\n",
            "Epoch 417/500\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.3378 - acc: 0.8333\n",
            "Epoch 418/500\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.3375 - acc: 0.8333\n",
            "Epoch 419/500\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.3373 - acc: 0.8333\n",
            "Epoch 420/500\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.3369 - acc: 0.8333\n",
            "Epoch 421/500\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.3364 - acc: 0.8333\n",
            "Epoch 422/500\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.3357 - acc: 0.8333\n",
            "Epoch 423/500\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.3354 - acc: 0.8333\n",
            "Epoch 424/500\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.3351 - acc: 0.8417\n",
            "Epoch 425/500\n",
            "120/120 [==============================] - 0s 123us/step - loss: 0.3349 - acc: 0.8417\n",
            "Epoch 426/500\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.3345 - acc: 0.8417\n",
            "Epoch 427/500\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.3340 - acc: 0.8333\n",
            "Epoch 428/500\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.3335 - acc: 0.8417\n",
            "Epoch 429/500\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.3330 - acc: 0.8333\n",
            "Epoch 430/500\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.3328 - acc: 0.8333\n",
            "Epoch 431/500\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.3326 - acc: 0.8333\n",
            "Epoch 432/500\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.3323 - acc: 0.8333\n",
            "Epoch 433/500\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.3316 - acc: 0.8333\n",
            "Epoch 434/500\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.3314 - acc: 0.8333\n",
            "Epoch 435/500\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.3310 - acc: 0.8333\n",
            "Epoch 436/500\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.3307 - acc: 0.8333\n",
            "Epoch 437/500\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.3300 - acc: 0.8333\n",
            "Epoch 438/500\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.3297 - acc: 0.8333\n",
            "Epoch 439/500\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.3294 - acc: 0.8333\n",
            "Epoch 440/500\n",
            "120/120 [==============================] - 0s 136us/step - loss: 0.3291 - acc: 0.8333\n",
            "Epoch 441/500\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.3287 - acc: 0.8333\n",
            "Epoch 442/500\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.3289 - acc: 0.8333\n",
            "Epoch 443/500\n",
            "120/120 [==============================] - 0s 76us/step - loss: 0.3286 - acc: 0.8333\n",
            "Epoch 444/500\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.3281 - acc: 0.8333\n",
            "Epoch 445/500\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.3278 - acc: 0.8333\n",
            "Epoch 446/500\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.3273 - acc: 0.8333\n",
            "Epoch 447/500\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.3269 - acc: 0.8333\n",
            "Epoch 448/500\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.3266 - acc: 0.8333\n",
            "Epoch 449/500\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.3262 - acc: 0.8333\n",
            "Epoch 450/500\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.3259 - acc: 0.8333\n",
            "Epoch 451/500\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.3256 - acc: 0.8333\n",
            "Epoch 452/500\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.3260 - acc: 0.8333\n",
            "Epoch 453/500\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.3255 - acc: 0.8417\n",
            "Epoch 454/500\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.3256 - acc: 0.8417\n",
            "Epoch 455/500\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.3247 - acc: 0.8417\n",
            "Epoch 456/500\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.3243 - acc: 0.8333\n",
            "Epoch 457/500\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.3239 - acc: 0.8417\n",
            "Epoch 458/500\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.3237 - acc: 0.8417\n",
            "Epoch 459/500\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.3233 - acc: 0.8333\n",
            "Epoch 460/500\n",
            "120/120 [==============================] - 0s 122us/step - loss: 0.3230 - acc: 0.8333\n",
            "Epoch 461/500\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.3230 - acc: 0.8333\n",
            "Epoch 462/500\n",
            "120/120 [==============================] - 0s 77us/step - loss: 0.3229 - acc: 0.8417\n",
            "Epoch 463/500\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.3227 - acc: 0.8417\n",
            "Epoch 464/500\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.3223 - acc: 0.8417\n",
            "Epoch 465/500\n",
            "120/120 [==============================] - 0s 122us/step - loss: 0.3218 - acc: 0.8417\n",
            "Epoch 466/500\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.3214 - acc: 0.8417\n",
            "Epoch 467/500\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.3210 - acc: 0.8417\n",
            "Epoch 468/500\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.3207 - acc: 0.8417\n",
            "Epoch 469/500\n",
            "120/120 [==============================] - 0s 123us/step - loss: 0.3205 - acc: 0.8417\n",
            "Epoch 470/500\n",
            "120/120 [==============================] - 0s 136us/step - loss: 0.3207 - acc: 0.8417\n",
            "Epoch 471/500\n",
            "120/120 [==============================] - 0s 124us/step - loss: 0.3206 - acc: 0.8417\n",
            "Epoch 472/500\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.3200 - acc: 0.8417\n",
            "Epoch 473/500\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.3195 - acc: 0.8417\n",
            "Epoch 474/500\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.3189 - acc: 0.8417\n",
            "Epoch 475/500\n",
            "120/120 [==============================] - 0s 187us/step - loss: 0.3184 - acc: 0.8417\n",
            "Epoch 476/500\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.3182 - acc: 0.8417\n",
            "Epoch 477/500\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.3178 - acc: 0.8417\n",
            "Epoch 478/500\n",
            "120/120 [==============================] - 0s 117us/step - loss: 0.3173 - acc: 0.8417\n",
            "Epoch 479/500\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.3169 - acc: 0.8417\n",
            "Epoch 480/500\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.3168 - acc: 0.8417\n",
            "Epoch 481/500\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.3164 - acc: 0.8333\n",
            "Epoch 482/500\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.3162 - acc: 0.8417\n",
            "Epoch 483/500\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.3166 - acc: 0.8417\n",
            "Epoch 484/500\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.3166 - acc: 0.8417\n",
            "Epoch 485/500\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.3162 - acc: 0.8500\n",
            "Epoch 486/500\n",
            "120/120 [==============================] - 0s 77us/step - loss: 0.3159 - acc: 0.8417\n",
            "Epoch 487/500\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.3148 - acc: 0.8417\n",
            "Epoch 488/500\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.3144 - acc: 0.8417\n",
            "Epoch 489/500\n",
            "120/120 [==============================] - 0s 115us/step - loss: 0.3144 - acc: 0.8417\n",
            "Epoch 490/500\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.3142 - acc: 0.8417\n",
            "Epoch 491/500\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.3139 - acc: 0.8417\n",
            "Epoch 492/500\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.3132 - acc: 0.8417\n",
            "Epoch 493/500\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.3132 - acc: 0.8417\n",
            "Epoch 494/500\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.3129 - acc: 0.8417\n",
            "Epoch 495/500\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.3124 - acc: 0.8417\n",
            "Epoch 496/500\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.3122 - acc: 0.8417\n",
            "Epoch 497/500\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.3120 - acc: 0.8417\n",
            "Epoch 498/500\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.3116 - acc: 0.8417\n",
            "Epoch 499/500\n",
            "120/120 [==============================] - 0s 122us/step - loss: 0.3114 - acc: 0.8417\n",
            "Epoch 500/500\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.3112 - acc: 0.8417\n",
            "60/60 [==============================] - 1s 9ms/step\n",
            "\n",
            "acc: 95.00%\n",
            "[[24  1  1]\n",
            " [ 1 15  0]\n",
            " [ 0  0 18]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.92      0.94        26\n",
            "           1       0.94      0.94      0.94        16\n",
            "           2       0.95      1.00      0.97        18\n",
            "\n",
            "    accuracy                           0.95        60\n",
            "   macro avg       0.95      0.95      0.95        60\n",
            "weighted avg       0.95      0.95      0.95        60\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_154 (Dense)            (None, 10)                30        \n",
            "_________________________________________________________________\n",
            "dense_155 (Dense)            (None, 20)                220       \n",
            "_________________________________________________________________\n",
            "dense_156 (Dense)            (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_157 (Dense)            (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_158 (Dense)            (None, 3)                 63        \n",
            "=================================================================\n",
            "Total params: 1,153\n",
            "Trainable params: 1,153\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/600\n",
            "120/120 [==============================] - 1s 12ms/step - loss: 1.1087 - acc: 0.3500\n",
            "Epoch 2/600\n",
            "120/120 [==============================] - 0s 106us/step - loss: 1.0992 - acc: 0.3500\n",
            "Epoch 3/600\n",
            "120/120 [==============================] - 0s 81us/step - loss: 1.0899 - acc: 0.3500\n",
            "Epoch 4/600\n",
            "120/120 [==============================] - 0s 86us/step - loss: 1.0817 - acc: 0.3500\n",
            "Epoch 5/600\n",
            "120/120 [==============================] - 0s 76us/step - loss: 1.0731 - acc: 0.3500\n",
            "Epoch 6/600\n",
            "120/120 [==============================] - 0s 87us/step - loss: 1.0646 - acc: 0.3667\n",
            "Epoch 7/600\n",
            "120/120 [==============================] - 0s 78us/step - loss: 1.0562 - acc: 0.3583\n",
            "Epoch 8/600\n",
            "120/120 [==============================] - 0s 79us/step - loss: 1.0493 - acc: 0.3583\n",
            "Epoch 9/600\n",
            "120/120 [==============================] - 0s 84us/step - loss: 1.0423 - acc: 0.3583\n",
            "Epoch 10/600\n",
            "120/120 [==============================] - 0s 77us/step - loss: 1.0356 - acc: 0.3667\n",
            "Epoch 11/600\n",
            "120/120 [==============================] - 0s 77us/step - loss: 1.0293 - acc: 0.3750\n",
            "Epoch 12/600\n",
            "120/120 [==============================] - 0s 74us/step - loss: 1.0232 - acc: 0.4000\n",
            "Epoch 13/600\n",
            "120/120 [==============================] - 0s 75us/step - loss: 1.0174 - acc: 0.4083\n",
            "Epoch 14/600\n",
            "120/120 [==============================] - 0s 93us/step - loss: 1.0119 - acc: 0.4167\n",
            "Epoch 15/600\n",
            "120/120 [==============================] - 0s 80us/step - loss: 1.0068 - acc: 0.4167\n",
            "Epoch 16/600\n",
            "120/120 [==============================] - 0s 86us/step - loss: 1.0019 - acc: 0.4333\n",
            "Epoch 17/600\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.9971 - acc: 0.4500\n",
            "Epoch 18/600\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.9925 - acc: 0.4750\n",
            "Epoch 19/600\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.9879 - acc: 0.4917\n",
            "Epoch 20/600\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.9834 - acc: 0.5667\n",
            "Epoch 21/600\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.9796 - acc: 0.5917\n",
            "Epoch 22/600\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.9754 - acc: 0.6333\n",
            "Epoch 23/600\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.9713 - acc: 0.6250\n",
            "Epoch 24/600\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.9673 - acc: 0.6333\n",
            "Epoch 25/600\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.9633 - acc: 0.6333\n",
            "Epoch 26/600\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.9596 - acc: 0.6500\n",
            "Epoch 27/600\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.9560 - acc: 0.6750\n",
            "Epoch 28/600\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.9520 - acc: 0.6833\n",
            "Epoch 29/600\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.9482 - acc: 0.6750\n",
            "Epoch 30/600\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.9440 - acc: 0.6833\n",
            "Epoch 31/600\n",
            "120/120 [==============================] - 0s 73us/step - loss: 0.9400 - acc: 0.6833\n",
            "Epoch 32/600\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.9361 - acc: 0.6917\n",
            "Epoch 33/600\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.9325 - acc: 0.6833\n",
            "Epoch 34/600\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.9285 - acc: 0.6833\n",
            "Epoch 35/600\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.9248 - acc: 0.6917\n",
            "Epoch 36/600\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.9211 - acc: 0.6917\n",
            "Epoch 37/600\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.9172 - acc: 0.6917\n",
            "Epoch 38/600\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.9132 - acc: 0.6833\n",
            "Epoch 39/600\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.9095 - acc: 0.6833\n",
            "Epoch 40/600\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.9057 - acc: 0.6750\n",
            "Epoch 41/600\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.9016 - acc: 0.6750\n",
            "Epoch 42/600\n",
            "120/120 [==============================] - 0s 125us/step - loss: 0.8980 - acc: 0.6750\n",
            "Epoch 43/600\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.8945 - acc: 0.6750\n",
            "Epoch 44/600\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.8903 - acc: 0.6750\n",
            "Epoch 45/600\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.8863 - acc: 0.6750\n",
            "Epoch 46/600\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.8827 - acc: 0.6750\n",
            "Epoch 47/600\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.8790 - acc: 0.6750\n",
            "Epoch 48/600\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.8751 - acc: 0.6750\n",
            "Epoch 49/600\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.8713 - acc: 0.6750\n",
            "Epoch 50/600\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.8677 - acc: 0.6750\n",
            "Epoch 51/600\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.8641 - acc: 0.6750\n",
            "Epoch 52/600\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.8602 - acc: 0.6750\n",
            "Epoch 53/600\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.8565 - acc: 0.6750\n",
            "Epoch 54/600\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.8524 - acc: 0.6750\n",
            "Epoch 55/600\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.8488 - acc: 0.7000\n",
            "Epoch 56/600\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.8451 - acc: 0.7000\n",
            "Epoch 57/600\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.8410 - acc: 0.7000\n",
            "Epoch 58/600\n",
            "120/120 [==============================] - 0s 131us/step - loss: 0.8372 - acc: 0.7000\n",
            "Epoch 59/600\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.8334 - acc: 0.7000\n",
            "Epoch 60/600\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.8294 - acc: 0.7000\n",
            "Epoch 61/600\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.8256 - acc: 0.7000\n",
            "Epoch 62/600\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.8220 - acc: 0.7000\n",
            "Epoch 63/600\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.8184 - acc: 0.7000\n",
            "Epoch 64/600\n",
            "120/120 [==============================] - 0s 154us/step - loss: 0.8149 - acc: 0.7000\n",
            "Epoch 65/600\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.8112 - acc: 0.7000\n",
            "Epoch 66/600\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.8074 - acc: 0.7000\n",
            "Epoch 67/600\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.8039 - acc: 0.6917\n",
            "Epoch 68/600\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.8004 - acc: 0.6917\n",
            "Epoch 69/600\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.7968 - acc: 0.6917\n",
            "Epoch 70/600\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.7935 - acc: 0.6833\n",
            "Epoch 71/600\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.7898 - acc: 0.6833\n",
            "Epoch 72/600\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.7863 - acc: 0.6833\n",
            "Epoch 73/600\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.7830 - acc: 0.6917\n",
            "Epoch 74/600\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.7795 - acc: 0.6833\n",
            "Epoch 75/600\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.7761 - acc: 0.6833\n",
            "Epoch 76/600\n",
            "120/120 [==============================] - 0s 126us/step - loss: 0.7728 - acc: 0.6917\n",
            "Epoch 77/600\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.7692 - acc: 0.6917\n",
            "Epoch 78/600\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.7656 - acc: 0.6917\n",
            "Epoch 79/600\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.7622 - acc: 0.6917\n",
            "Epoch 80/600\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.7589 - acc: 0.6917\n",
            "Epoch 81/600\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.7555 - acc: 0.6917\n",
            "Epoch 82/600\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.7522 - acc: 0.6917\n",
            "Epoch 83/600\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.7490 - acc: 0.6917\n",
            "Epoch 84/600\n",
            "120/120 [==============================] - 0s 127us/step - loss: 0.7458 - acc: 0.6917\n",
            "Epoch 85/600\n",
            "120/120 [==============================] - 0s 125us/step - loss: 0.7425 - acc: 0.6917\n",
            "Epoch 86/600\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.7392 - acc: 0.6917\n",
            "Epoch 87/600\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.7358 - acc: 0.6917\n",
            "Epoch 88/600\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.7326 - acc: 0.6917\n",
            "Epoch 89/600\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.7295 - acc: 0.6917\n",
            "Epoch 90/600\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.7264 - acc: 0.6917\n",
            "Epoch 91/600\n",
            "120/120 [==============================] - 0s 76us/step - loss: 0.7231 - acc: 0.6917\n",
            "Epoch 92/600\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.7198 - acc: 0.7000\n",
            "Epoch 93/600\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.7165 - acc: 0.7000\n",
            "Epoch 94/600\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.7132 - acc: 0.7000\n",
            "Epoch 95/600\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.7102 - acc: 0.7000\n",
            "Epoch 96/600\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.7070 - acc: 0.7000\n",
            "Epoch 97/600\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.7038 - acc: 0.7167\n",
            "Epoch 98/600\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.7006 - acc: 0.7333\n",
            "Epoch 99/600\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.6976 - acc: 0.7417\n",
            "Epoch 100/600\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.6945 - acc: 0.7417\n",
            "Epoch 101/600\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.6916 - acc: 0.7417\n",
            "Epoch 102/600\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.6886 - acc: 0.7583\n",
            "Epoch 103/600\n",
            "120/120 [==============================] - 0s 125us/step - loss: 0.6855 - acc: 0.7750\n",
            "Epoch 104/600\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.6827 - acc: 0.7750\n",
            "Epoch 105/600\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.6797 - acc: 0.7833\n",
            "Epoch 106/600\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.6768 - acc: 0.7833\n",
            "Epoch 107/600\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.6739 - acc: 0.7833\n",
            "Epoch 108/600\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.6708 - acc: 0.7833\n",
            "Epoch 109/600\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.6676 - acc: 0.7833\n",
            "Epoch 110/600\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.6647 - acc: 0.7833\n",
            "Epoch 111/600\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.6619 - acc: 0.7917\n",
            "Epoch 112/600\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.6591 - acc: 0.7917\n",
            "Epoch 113/600\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.6559 - acc: 0.7917\n",
            "Epoch 114/600\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.6528 - acc: 0.7917\n",
            "Epoch 115/600\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.6498 - acc: 0.7917\n",
            "Epoch 116/600\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.6467 - acc: 0.7917\n",
            "Epoch 117/600\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.6437 - acc: 0.7917\n",
            "Epoch 118/600\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.6405 - acc: 0.8000\n",
            "Epoch 119/600\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.6374 - acc: 0.8000\n",
            "Epoch 120/600\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.6345 - acc: 0.8167\n",
            "Epoch 121/600\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.6315 - acc: 0.8167\n",
            "Epoch 122/600\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.6286 - acc: 0.8083\n",
            "Epoch 123/600\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.6257 - acc: 0.8167\n",
            "Epoch 124/600\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.6231 - acc: 0.8250\n",
            "Epoch 125/600\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.6203 - acc: 0.8250\n",
            "Epoch 126/600\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.6172 - acc: 0.8250\n",
            "Epoch 127/600\n",
            "120/120 [==============================] - 0s 119us/step - loss: 0.6141 - acc: 0.8250\n",
            "Epoch 128/600\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.6112 - acc: 0.8333\n",
            "Epoch 129/600\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.6083 - acc: 0.8333\n",
            "Epoch 130/600\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.6053 - acc: 0.8333\n",
            "Epoch 131/600\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.6020 - acc: 0.8250\n",
            "Epoch 132/600\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.5991 - acc: 0.8333\n",
            "Epoch 133/600\n",
            "120/120 [==============================] - 0s 119us/step - loss: 0.5961 - acc: 0.8333\n",
            "Epoch 134/600\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.5932 - acc: 0.8333\n",
            "Epoch 135/600\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.5901 - acc: 0.8333\n",
            "Epoch 136/600\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.5873 - acc: 0.8333\n",
            "Epoch 137/600\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.5844 - acc: 0.8333\n",
            "Epoch 138/600\n",
            "120/120 [==============================] - 0s 75us/step - loss: 0.5816 - acc: 0.8333\n",
            "Epoch 139/600\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.5787 - acc: 0.8333\n",
            "Epoch 140/600\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.5756 - acc: 0.8333\n",
            "Epoch 141/600\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.5725 - acc: 0.8333\n",
            "Epoch 142/600\n",
            "120/120 [==============================] - 0s 138us/step - loss: 0.5697 - acc: 0.8333\n",
            "Epoch 143/600\n",
            "120/120 [==============================] - 0s 129us/step - loss: 0.5670 - acc: 0.8333\n",
            "Epoch 144/600\n",
            "120/120 [==============================] - 0s 117us/step - loss: 0.5641 - acc: 0.8500\n",
            "Epoch 145/600\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.5610 - acc: 0.8500\n",
            "Epoch 146/600\n",
            "120/120 [==============================] - 0s 133us/step - loss: 0.5583 - acc: 0.8500\n",
            "Epoch 147/600\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.5556 - acc: 0.8500\n",
            "Epoch 148/600\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.5530 - acc: 0.8583\n",
            "Epoch 149/600\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.5505 - acc: 0.8500\n",
            "Epoch 150/600\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.5476 - acc: 0.8500\n",
            "Epoch 151/600\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.5448 - acc: 0.8500\n",
            "Epoch 152/600\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.5420 - acc: 0.8500\n",
            "Epoch 153/600\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.5394 - acc: 0.8500\n",
            "Epoch 154/600\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.5367 - acc: 0.8667\n",
            "Epoch 155/600\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.5339 - acc: 0.8667\n",
            "Epoch 156/600\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.5313 - acc: 0.8667\n",
            "Epoch 157/600\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.5286 - acc: 0.8667\n",
            "Epoch 158/600\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.5259 - acc: 0.8667\n",
            "Epoch 159/600\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.5233 - acc: 0.8667\n",
            "Epoch 160/600\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.5205 - acc: 0.8667\n",
            "Epoch 161/600\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.5178 - acc: 0.8667\n",
            "Epoch 162/600\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.5153 - acc: 0.8667\n",
            "Epoch 163/600\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.5127 - acc: 0.8667\n",
            "Epoch 164/600\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.5105 - acc: 0.8667\n",
            "Epoch 165/600\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.5080 - acc: 0.8750\n",
            "Epoch 166/600\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.5054 - acc: 0.8667\n",
            "Epoch 167/600\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.5028 - acc: 0.8750\n",
            "Epoch 168/600\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.5003 - acc: 0.8750\n",
            "Epoch 169/600\n",
            "120/120 [==============================] - 0s 77us/step - loss: 0.4981 - acc: 0.8750\n",
            "Epoch 170/600\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.4958 - acc: 0.8750\n",
            "Epoch 171/600\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.4932 - acc: 0.8750\n",
            "Epoch 172/600\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.4908 - acc: 0.8750\n",
            "Epoch 173/600\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.4882 - acc: 0.8750\n",
            "Epoch 174/600\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.4859 - acc: 0.8833\n",
            "Epoch 175/600\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.4837 - acc: 0.8833\n",
            "Epoch 176/600\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.4813 - acc: 0.8833\n",
            "Epoch 177/600\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.4789 - acc: 0.8833\n",
            "Epoch 178/600\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.4765 - acc: 0.8833\n",
            "Epoch 179/600\n",
            "120/120 [==============================] - 0s 132us/step - loss: 0.4743 - acc: 0.8833\n",
            "Epoch 180/600\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.4721 - acc: 0.8833\n",
            "Epoch 181/600\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.4698 - acc: 0.8833\n",
            "Epoch 182/600\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.4675 - acc: 0.8833\n",
            "Epoch 183/600\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.4655 - acc: 0.8833\n",
            "Epoch 184/600\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.4636 - acc: 0.8833\n",
            "Epoch 185/600\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.4613 - acc: 0.8833\n",
            "Epoch 186/600\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.4591 - acc: 0.8833\n",
            "Epoch 187/600\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.4569 - acc: 0.8833\n",
            "Epoch 188/600\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.4546 - acc: 0.8833\n",
            "Epoch 189/600\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.4524 - acc: 0.8833\n",
            "Epoch 190/600\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.4502 - acc: 0.8833\n",
            "Epoch 191/600\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.4481 - acc: 0.8833\n",
            "Epoch 192/600\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.4461 - acc: 0.8833\n",
            "Epoch 193/600\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.4443 - acc: 0.8833\n",
            "Epoch 194/600\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.4423 - acc: 0.8833\n",
            "Epoch 195/600\n",
            "120/120 [==============================] - 0s 76us/step - loss: 0.4404 - acc: 0.8833\n",
            "Epoch 196/600\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.4387 - acc: 0.8917\n",
            "Epoch 197/600\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.4367 - acc: 0.8917\n",
            "Epoch 198/600\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.4348 - acc: 0.8917\n",
            "Epoch 199/600\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.4329 - acc: 0.8917\n",
            "Epoch 200/600\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.4310 - acc: 0.8917\n",
            "Epoch 201/600\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.4292 - acc: 0.8917\n",
            "Epoch 202/600\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.4275 - acc: 0.8917\n",
            "Epoch 203/600\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.4257 - acc: 0.9000\n",
            "Epoch 204/600\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.4237 - acc: 0.9083\n",
            "Epoch 205/600\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.4219 - acc: 0.9083\n",
            "Epoch 206/600\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.4199 - acc: 0.9083\n",
            "Epoch 207/600\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.4183 - acc: 0.9083\n",
            "Epoch 208/600\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.4167 - acc: 0.9083\n",
            "Epoch 209/600\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.4150 - acc: 0.9083\n",
            "Epoch 210/600\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.4133 - acc: 0.9083\n",
            "Epoch 211/600\n",
            "120/120 [==============================] - 0s 146us/step - loss: 0.4115 - acc: 0.9083\n",
            "Epoch 212/600\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.4097 - acc: 0.9083\n",
            "Epoch 213/600\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.4078 - acc: 0.9083\n",
            "Epoch 214/600\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.4061 - acc: 0.9083\n",
            "Epoch 215/600\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.4045 - acc: 0.9000\n",
            "Epoch 216/600\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.4029 - acc: 0.9000\n",
            "Epoch 217/600\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.4013 - acc: 0.9000\n",
            "Epoch 218/600\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.3996 - acc: 0.9000\n",
            "Epoch 219/600\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.3981 - acc: 0.9000\n",
            "Epoch 220/600\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.3963 - acc: 0.9000\n",
            "Epoch 221/600\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.3946 - acc: 0.9000\n",
            "Epoch 222/600\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.3930 - acc: 0.9000\n",
            "Epoch 223/600\n",
            "120/120 [==============================] - 0s 137us/step - loss: 0.3915 - acc: 0.9000\n",
            "Epoch 224/600\n",
            "120/120 [==============================] - 0s 129us/step - loss: 0.3898 - acc: 0.9000\n",
            "Epoch 225/600\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.3883 - acc: 0.9000\n",
            "Epoch 226/600\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.3866 - acc: 0.9000\n",
            "Epoch 227/600\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.3851 - acc: 0.9000\n",
            "Epoch 228/600\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.3836 - acc: 0.9000\n",
            "Epoch 229/600\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.3821 - acc: 0.9000\n",
            "Epoch 230/600\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.3807 - acc: 0.9000\n",
            "Epoch 231/600\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.3794 - acc: 0.9000\n",
            "Epoch 232/600\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.3781 - acc: 0.9000\n",
            "Epoch 233/600\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.3768 - acc: 0.9000\n",
            "Epoch 234/600\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.3751 - acc: 0.9000\n",
            "Epoch 235/600\n",
            "120/120 [==============================] - 0s 132us/step - loss: 0.3735 - acc: 0.9000\n",
            "Epoch 236/600\n",
            "120/120 [==============================] - 0s 127us/step - loss: 0.3720 - acc: 0.9000\n",
            "Epoch 237/600\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.3707 - acc: 0.9000\n",
            "Epoch 238/600\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.3692 - acc: 0.9000\n",
            "Epoch 239/600\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.3679 - acc: 0.9000\n",
            "Epoch 240/600\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.3665 - acc: 0.9000\n",
            "Epoch 241/600\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.3651 - acc: 0.9000\n",
            "Epoch 242/600\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.3637 - acc: 0.9000\n",
            "Epoch 243/600\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.3623 - acc: 0.9000\n",
            "Epoch 244/600\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.3608 - acc: 0.9000\n",
            "Epoch 245/600\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.3594 - acc: 0.9000\n",
            "Epoch 246/600\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.3581 - acc: 0.9000\n",
            "Epoch 247/600\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.3568 - acc: 0.9000\n",
            "Epoch 248/600\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.3555 - acc: 0.9000\n",
            "Epoch 249/600\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.3543 - acc: 0.9000\n",
            "Epoch 250/600\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.3530 - acc: 0.9000\n",
            "Epoch 251/600\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.3517 - acc: 0.9000\n",
            "Epoch 252/600\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.3505 - acc: 0.9000\n",
            "Epoch 253/600\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.3493 - acc: 0.9000\n",
            "Epoch 254/600\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.3482 - acc: 0.9000\n",
            "Epoch 255/600\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.3469 - acc: 0.9000\n",
            "Epoch 256/600\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.3457 - acc: 0.9000\n",
            "Epoch 257/600\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.3445 - acc: 0.9000\n",
            "Epoch 258/600\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.3434 - acc: 0.9000\n",
            "Epoch 259/600\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.3425 - acc: 0.9000\n",
            "Epoch 260/600\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.3415 - acc: 0.9000\n",
            "Epoch 261/600\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.3403 - acc: 0.9000\n",
            "Epoch 262/600\n",
            "120/120 [==============================] - 0s 74us/step - loss: 0.3392 - acc: 0.8917\n",
            "Epoch 263/600\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.3380 - acc: 0.9000\n",
            "Epoch 264/600\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.3368 - acc: 0.9000\n",
            "Epoch 265/600\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.3358 - acc: 0.9000\n",
            "Epoch 266/600\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.3349 - acc: 0.9000\n",
            "Epoch 267/600\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.3340 - acc: 0.8917\n",
            "Epoch 268/600\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.3327 - acc: 0.8917\n",
            "Epoch 269/600\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.3316 - acc: 0.9000\n",
            "Epoch 270/600\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.3306 - acc: 0.9083\n",
            "Epoch 271/600\n",
            "120/120 [==============================] - 0s 115us/step - loss: 0.3297 - acc: 0.9083\n",
            "Epoch 272/600\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.3286 - acc: 0.9000\n",
            "Epoch 273/600\n",
            "120/120 [==============================] - 0s 122us/step - loss: 0.3274 - acc: 0.9000\n",
            "Epoch 274/600\n",
            "120/120 [==============================] - 0s 176us/step - loss: 0.3262 - acc: 0.9000\n",
            "Epoch 275/600\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.3251 - acc: 0.9000\n",
            "Epoch 276/600\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.3239 - acc: 0.9083\n",
            "Epoch 277/600\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.3231 - acc: 0.9000\n",
            "Epoch 278/600\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.3220 - acc: 0.9000\n",
            "Epoch 279/600\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.3211 - acc: 0.9000\n",
            "Epoch 280/600\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.3201 - acc: 0.9000\n",
            "Epoch 281/600\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.3192 - acc: 0.9000\n",
            "Epoch 282/600\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.3183 - acc: 0.9000\n",
            "Epoch 283/600\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.3173 - acc: 0.9000\n",
            "Epoch 284/600\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.3164 - acc: 0.9000\n",
            "Epoch 285/600\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.3154 - acc: 0.9000\n",
            "Epoch 286/600\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.3144 - acc: 0.8917\n",
            "Epoch 287/600\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.3136 - acc: 0.8917\n",
            "Epoch 288/600\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.3129 - acc: 0.8917\n",
            "Epoch 289/600\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.3119 - acc: 0.8917\n",
            "Epoch 290/600\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.3110 - acc: 0.8833\n",
            "Epoch 291/600\n",
            "120/120 [==============================] - 0s 129us/step - loss: 0.3102 - acc: 0.8917\n",
            "Epoch 292/600\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.3094 - acc: 0.9000\n",
            "Epoch 293/600\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.3085 - acc: 0.9000\n",
            "Epoch 294/600\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.3075 - acc: 0.9000\n",
            "Epoch 295/600\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.3067 - acc: 0.9000\n",
            "Epoch 296/600\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.3059 - acc: 0.9000\n",
            "Epoch 297/600\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.3050 - acc: 0.9000\n",
            "Epoch 298/600\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.3041 - acc: 0.9000\n",
            "Epoch 299/600\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.3035 - acc: 0.9000\n",
            "Epoch 300/600\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.3026 - acc: 0.9000\n",
            "Epoch 301/600\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.3016 - acc: 0.9000\n",
            "Epoch 302/600\n",
            "120/120 [==============================] - 0s 134us/step - loss: 0.3007 - acc: 0.9000\n",
            "Epoch 303/600\n",
            "120/120 [==============================] - 0s 131us/step - loss: 0.3001 - acc: 0.9000\n",
            "Epoch 304/600\n",
            "120/120 [==============================] - 0s 115us/step - loss: 0.2994 - acc: 0.9000\n",
            "Epoch 305/600\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2986 - acc: 0.9000\n",
            "Epoch 306/600\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2978 - acc: 0.9000\n",
            "Epoch 307/600\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2970 - acc: 0.9000\n",
            "Epoch 308/600\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2962 - acc: 0.9000\n",
            "Epoch 309/600\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2955 - acc: 0.8917\n",
            "Epoch 310/600\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2949 - acc: 0.9000\n",
            "Epoch 311/600\n",
            "120/120 [==============================] - 0s 77us/step - loss: 0.2941 - acc: 0.9083\n",
            "Epoch 312/600\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2934 - acc: 0.9083\n",
            "Epoch 313/600\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2926 - acc: 0.9000\n",
            "Epoch 314/600\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2920 - acc: 0.9000\n",
            "Epoch 315/600\n",
            "120/120 [==============================] - 0s 121us/step - loss: 0.2913 - acc: 0.9000\n",
            "Epoch 316/600\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.2906 - acc: 0.9000\n",
            "Epoch 317/600\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2899 - acc: 0.9000\n",
            "Epoch 318/600\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.2891 - acc: 0.9000\n",
            "Epoch 319/600\n",
            "120/120 [==============================] - 0s 115us/step - loss: 0.2883 - acc: 0.9000\n",
            "Epoch 320/600\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2877 - acc: 0.8917\n",
            "Epoch 321/600\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2870 - acc: 0.9000\n",
            "Epoch 322/600\n",
            "120/120 [==============================] - 0s 123us/step - loss: 0.2863 - acc: 0.8917\n",
            "Epoch 323/600\n",
            "120/120 [==============================] - 0s 117us/step - loss: 0.2857 - acc: 0.8917\n",
            "Epoch 324/600\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.2850 - acc: 0.9083\n",
            "Epoch 325/600\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.2842 - acc: 0.9083\n",
            "Epoch 326/600\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2836 - acc: 0.9083\n",
            "Epoch 327/600\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2828 - acc: 0.9000\n",
            "Epoch 328/600\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2821 - acc: 0.9000\n",
            "Epoch 329/600\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2814 - acc: 0.9000\n",
            "Epoch 330/600\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2808 - acc: 0.9000\n",
            "Epoch 331/600\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.2802 - acc: 0.8917\n",
            "Epoch 332/600\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2795 - acc: 0.8917\n",
            "Epoch 333/600\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2789 - acc: 0.8917\n",
            "Epoch 334/600\n",
            "120/120 [==============================] - 0s 115us/step - loss: 0.2784 - acc: 0.8917\n",
            "Epoch 335/600\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2777 - acc: 0.8917\n",
            "Epoch 336/600\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.2772 - acc: 0.8917\n",
            "Epoch 337/600\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2767 - acc: 0.8917\n",
            "Epoch 338/600\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2761 - acc: 0.8917\n",
            "Epoch 339/600\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2755 - acc: 0.8917\n",
            "Epoch 340/600\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2746 - acc: 0.8917\n",
            "Epoch 341/600\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2739 - acc: 0.9000\n",
            "Epoch 342/600\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2732 - acc: 0.9000\n",
            "Epoch 343/600\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2726 - acc: 0.9000\n",
            "Epoch 344/600\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2719 - acc: 0.9000\n",
            "Epoch 345/600\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2713 - acc: 0.9000\n",
            "Epoch 346/600\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.2708 - acc: 0.9000\n",
            "Epoch 347/600\n",
            "120/120 [==============================] - 0s 134us/step - loss: 0.2702 - acc: 0.9083\n",
            "Epoch 348/600\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2696 - acc: 0.9083\n",
            "Epoch 349/600\n",
            "120/120 [==============================] - 0s 121us/step - loss: 0.2691 - acc: 0.9000\n",
            "Epoch 350/600\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2684 - acc: 0.9083\n",
            "Epoch 351/600\n",
            "120/120 [==============================] - 0s 76us/step - loss: 0.2681 - acc: 0.9000\n",
            "Epoch 352/600\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.2675 - acc: 0.9083\n",
            "Epoch 353/600\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2671 - acc: 0.9083\n",
            "Epoch 354/600\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2664 - acc: 0.9083\n",
            "Epoch 355/600\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2659 - acc: 0.9083\n",
            "Epoch 356/600\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.2654 - acc: 0.9000\n",
            "Epoch 357/600\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2650 - acc: 0.9083\n",
            "Epoch 358/600\n",
            "120/120 [==============================] - 0s 74us/step - loss: 0.2645 - acc: 0.9000\n",
            "Epoch 359/600\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.2641 - acc: 0.9000\n",
            "Epoch 360/600\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2638 - acc: 0.9083\n",
            "Epoch 361/600\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2634 - acc: 0.9000\n",
            "Epoch 362/600\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2629 - acc: 0.9083\n",
            "Epoch 363/600\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2625 - acc: 0.9083\n",
            "Epoch 364/600\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.2619 - acc: 0.9083\n",
            "Epoch 365/600\n",
            "120/120 [==============================] - 0s 74us/step - loss: 0.2614 - acc: 0.9083\n",
            "Epoch 366/600\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2609 - acc: 0.9083\n",
            "Epoch 367/600\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2605 - acc: 0.9083\n",
            "Epoch 368/600\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2600 - acc: 0.9083\n",
            "Epoch 369/600\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2595 - acc: 0.9083\n",
            "Epoch 370/600\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2590 - acc: 0.9083\n",
            "Epoch 371/600\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2586 - acc: 0.9083\n",
            "Epoch 372/600\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2582 - acc: 0.9083\n",
            "Epoch 373/600\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2578 - acc: 0.9083\n",
            "Epoch 374/600\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.2573 - acc: 0.9083\n",
            "Epoch 375/600\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2567 - acc: 0.9083\n",
            "Epoch 376/600\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2563 - acc: 0.9083\n",
            "Epoch 377/600\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2559 - acc: 0.9083\n",
            "Epoch 378/600\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2554 - acc: 0.9083\n",
            "Epoch 379/600\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2550 - acc: 0.9083\n",
            "Epoch 380/600\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2546 - acc: 0.9083\n",
            "Epoch 381/600\n",
            "120/120 [==============================] - 0s 134us/step - loss: 0.2542 - acc: 0.9083\n",
            "Epoch 382/600\n",
            "120/120 [==============================] - 0s 160us/step - loss: 0.2538 - acc: 0.9083\n",
            "Epoch 383/600\n",
            "120/120 [==============================] - 0s 119us/step - loss: 0.2535 - acc: 0.9083\n",
            "Epoch 384/600\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2530 - acc: 0.9083\n",
            "Epoch 385/600\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2525 - acc: 0.9000\n",
            "Epoch 386/600\n",
            "120/120 [==============================] - 0s 77us/step - loss: 0.2520 - acc: 0.9083\n",
            "Epoch 387/600\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2517 - acc: 0.9083\n",
            "Epoch 388/600\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.2513 - acc: 0.9000\n",
            "Epoch 389/600\n",
            "120/120 [==============================] - 0s 123us/step - loss: 0.2512 - acc: 0.9000\n",
            "Epoch 390/600\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2508 - acc: 0.9000\n",
            "Epoch 391/600\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2505 - acc: 0.9000\n",
            "Epoch 392/600\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2500 - acc: 0.9000\n",
            "Epoch 393/600\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2495 - acc: 0.9000\n",
            "Epoch 394/600\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2491 - acc: 0.9000\n",
            "Epoch 395/600\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.2486 - acc: 0.9083\n",
            "Epoch 396/600\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2484 - acc: 0.9083\n",
            "Epoch 397/600\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2480 - acc: 0.9083\n",
            "Epoch 398/600\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2477 - acc: 0.9083\n",
            "Epoch 399/600\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2475 - acc: 0.9083\n",
            "Epoch 400/600\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.2473 - acc: 0.9083\n",
            "Epoch 401/600\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2469 - acc: 0.9083\n",
            "Epoch 402/600\n",
            "120/120 [==============================] - 0s 121us/step - loss: 0.2467 - acc: 0.9083\n",
            "Epoch 403/600\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2463 - acc: 0.9083\n",
            "Epoch 404/600\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2461 - acc: 0.9083\n",
            "Epoch 405/600\n",
            "120/120 [==============================] - 0s 117us/step - loss: 0.2458 - acc: 0.9000\n",
            "Epoch 406/600\n",
            "120/120 [==============================] - 0s 73us/step - loss: 0.2454 - acc: 0.9083\n",
            "Epoch 407/600\n",
            "120/120 [==============================] - 0s 125us/step - loss: 0.2452 - acc: 0.9083\n",
            "Epoch 408/600\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2447 - acc: 0.9083\n",
            "Epoch 409/600\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2443 - acc: 0.9083\n",
            "Epoch 410/600\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2440 - acc: 0.9083\n",
            "Epoch 411/600\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2437 - acc: 0.9083\n",
            "Epoch 412/600\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2433 - acc: 0.9083\n",
            "Epoch 413/600\n",
            "120/120 [==============================] - 0s 135us/step - loss: 0.2431 - acc: 0.9083\n",
            "Epoch 414/600\n",
            "120/120 [==============================] - 0s 122us/step - loss: 0.2427 - acc: 0.9083\n",
            "Epoch 415/600\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.2424 - acc: 0.9000\n",
            "Epoch 416/600\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2420 - acc: 0.9083\n",
            "Epoch 417/600\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.2417 - acc: 0.9083\n",
            "Epoch 418/600\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2413 - acc: 0.9083\n",
            "Epoch 419/600\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2409 - acc: 0.9083\n",
            "Epoch 420/600\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.2405 - acc: 0.9083\n",
            "Epoch 421/600\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2403 - acc: 0.9083\n",
            "Epoch 422/600\n",
            "120/120 [==============================] - 0s 121us/step - loss: 0.2400 - acc: 0.9083\n",
            "Epoch 423/600\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2396 - acc: 0.9083\n",
            "Epoch 424/600\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2394 - acc: 0.9083\n",
            "Epoch 425/600\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2391 - acc: 0.9083\n",
            "Epoch 426/600\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2387 - acc: 0.9083\n",
            "Epoch 427/600\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2384 - acc: 0.9083\n",
            "Epoch 428/600\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2382 - acc: 0.9083\n",
            "Epoch 429/600\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2380 - acc: 0.9000\n",
            "Epoch 430/600\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2375 - acc: 0.9083\n",
            "Epoch 431/600\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2372 - acc: 0.9083\n",
            "Epoch 432/600\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2371 - acc: 0.9083\n",
            "Epoch 433/600\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2368 - acc: 0.9083\n",
            "Epoch 434/600\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2364 - acc: 0.9167\n",
            "Epoch 435/600\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.2361 - acc: 0.9167\n",
            "Epoch 436/600\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.2359 - acc: 0.9167\n",
            "Epoch 437/600\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2356 - acc: 0.9167\n",
            "Epoch 438/600\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2353 - acc: 0.9083\n",
            "Epoch 439/600\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2350 - acc: 0.9083\n",
            "Epoch 440/600\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2347 - acc: 0.9083\n",
            "Epoch 441/600\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2346 - acc: 0.9083\n",
            "Epoch 442/600\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2343 - acc: 0.9083\n",
            "Epoch 443/600\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2340 - acc: 0.9167\n",
            "Epoch 444/600\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2337 - acc: 0.9083\n",
            "Epoch 445/600\n",
            "120/120 [==============================] - 0s 129us/step - loss: 0.2334 - acc: 0.9083\n",
            "Epoch 446/600\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.2332 - acc: 0.9167\n",
            "Epoch 447/600\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2330 - acc: 0.9167\n",
            "Epoch 448/600\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.2327 - acc: 0.9083\n",
            "Epoch 449/600\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2324 - acc: 0.9083\n",
            "Epoch 450/600\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2323 - acc: 0.9083\n",
            "Epoch 451/600\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2320 - acc: 0.9083\n",
            "Epoch 452/600\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2318 - acc: 0.9083\n",
            "Epoch 453/600\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.2314 - acc: 0.9167\n",
            "Epoch 454/600\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2312 - acc: 0.9167\n",
            "Epoch 455/600\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2309 - acc: 0.9083\n",
            "Epoch 456/600\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2307 - acc: 0.9083\n",
            "Epoch 457/600\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.2306 - acc: 0.9083\n",
            "Epoch 458/600\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2305 - acc: 0.9083\n",
            "Epoch 459/600\n",
            "120/120 [==============================] - 0s 137us/step - loss: 0.2304 - acc: 0.9000\n",
            "Epoch 460/600\n",
            "120/120 [==============================] - 0s 134us/step - loss: 0.2299 - acc: 0.9083\n",
            "Epoch 461/600\n",
            "120/120 [==============================] - 0s 119us/step - loss: 0.2299 - acc: 0.9083\n",
            "Epoch 462/600\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.2298 - acc: 0.9000\n",
            "Epoch 463/600\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.2296 - acc: 0.9000\n",
            "Epoch 464/600\n",
            "120/120 [==============================] - 0s 117us/step - loss: 0.2294 - acc: 0.9000\n",
            "Epoch 465/600\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2292 - acc: 0.9000\n",
            "Epoch 466/600\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2287 - acc: 0.9083\n",
            "Epoch 467/600\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2284 - acc: 0.9083\n",
            "Epoch 468/600\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2281 - acc: 0.9083\n",
            "Epoch 469/600\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2279 - acc: 0.9083\n",
            "Epoch 470/600\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2278 - acc: 0.9083\n",
            "Epoch 471/600\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2276 - acc: 0.9083\n",
            "Epoch 472/600\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2273 - acc: 0.9083\n",
            "Epoch 473/600\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2270 - acc: 0.9083\n",
            "Epoch 474/600\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2268 - acc: 0.9083\n",
            "Epoch 475/600\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2268 - acc: 0.9083\n",
            "Epoch 476/600\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2266 - acc: 0.9083\n",
            "Epoch 477/600\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2262 - acc: 0.9083\n",
            "Epoch 478/600\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2260 - acc: 0.9083\n",
            "Epoch 479/600\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2259 - acc: 0.9083\n",
            "Epoch 480/600\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.2259 - acc: 0.9083\n",
            "Epoch 481/600\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2255 - acc: 0.9083\n",
            "Epoch 482/600\n",
            "120/120 [==============================] - 0s 119us/step - loss: 0.2255 - acc: 0.9083\n",
            "Epoch 483/600\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2253 - acc: 0.9083\n",
            "Epoch 484/600\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2252 - acc: 0.9083\n",
            "Epoch 485/600\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2250 - acc: 0.9083\n",
            "Epoch 486/600\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2250 - acc: 0.9083\n",
            "Epoch 487/600\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2249 - acc: 0.9000\n",
            "Epoch 488/600\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2247 - acc: 0.9083\n",
            "Epoch 489/600\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2243 - acc: 0.9083\n",
            "Epoch 490/600\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2242 - acc: 0.9083\n",
            "Epoch 491/600\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.2240 - acc: 0.9083\n",
            "Epoch 492/600\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2238 - acc: 0.9083\n",
            "Epoch 493/600\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2235 - acc: 0.9083\n",
            "Epoch 494/600\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2233 - acc: 0.9083\n",
            "Epoch 495/600\n",
            "120/120 [==============================] - 0s 135us/step - loss: 0.2232 - acc: 0.9083\n",
            "Epoch 496/600\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2230 - acc: 0.9083\n",
            "Epoch 497/600\n",
            "120/120 [==============================] - 0s 124us/step - loss: 0.2228 - acc: 0.9083\n",
            "Epoch 498/600\n",
            "120/120 [==============================] - 0s 115us/step - loss: 0.2227 - acc: 0.9083\n",
            "Epoch 499/600\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2225 - acc: 0.9083\n",
            "Epoch 500/600\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.2223 - acc: 0.9083\n",
            "Epoch 501/600\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.2223 - acc: 0.9083\n",
            "Epoch 502/600\n",
            "120/120 [==============================] - 0s 129us/step - loss: 0.2218 - acc: 0.9083\n",
            "Epoch 503/600\n",
            "120/120 [==============================] - 0s 140us/step - loss: 0.2216 - acc: 0.9167\n",
            "Epoch 504/600\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2214 - acc: 0.9167\n",
            "Epoch 505/600\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.2213 - acc: 0.9167\n",
            "Epoch 506/600\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2211 - acc: 0.9083\n",
            "Epoch 507/600\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.2209 - acc: 0.9083\n",
            "Epoch 508/600\n",
            "120/120 [==============================] - 0s 134us/step - loss: 0.2209 - acc: 0.9083\n",
            "Epoch 509/600\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2208 - acc: 0.9083\n",
            "Epoch 510/600\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2205 - acc: 0.9083\n",
            "Epoch 511/600\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2203 - acc: 0.9083\n",
            "Epoch 512/600\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.2202 - acc: 0.9083\n",
            "Epoch 513/600\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2200 - acc: 0.9083\n",
            "Epoch 514/600\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2199 - acc: 0.9083\n",
            "Epoch 515/600\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.2197 - acc: 0.9083\n",
            "Epoch 516/600\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2195 - acc: 0.9167\n",
            "Epoch 517/600\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2193 - acc: 0.9083\n",
            "Epoch 518/600\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2191 - acc: 0.9167\n",
            "Epoch 519/600\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2191 - acc: 0.9083\n",
            "Epoch 520/600\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2189 - acc: 0.9083\n",
            "Epoch 521/600\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2188 - acc: 0.9083\n",
            "Epoch 522/600\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2186 - acc: 0.9083\n",
            "Epoch 523/600\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2185 - acc: 0.9083\n",
            "Epoch 524/600\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2182 - acc: 0.9083\n",
            "Epoch 525/600\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.2182 - acc: 0.9083\n",
            "Epoch 526/600\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2182 - acc: 0.9083\n",
            "Epoch 527/600\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2180 - acc: 0.9000\n",
            "Epoch 528/600\n",
            "120/120 [==============================] - 0s 117us/step - loss: 0.2177 - acc: 0.9083\n",
            "Epoch 529/600\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.2176 - acc: 0.9083\n",
            "Epoch 530/600\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2174 - acc: 0.9083\n",
            "Epoch 531/600\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2173 - acc: 0.9083\n",
            "Epoch 532/600\n",
            "120/120 [==============================] - 0s 123us/step - loss: 0.2172 - acc: 0.9083\n",
            "Epoch 533/600\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2172 - acc: 0.9083\n",
            "Epoch 534/600\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.2170 - acc: 0.9083\n",
            "Epoch 535/600\n",
            "120/120 [==============================] - 0s 168us/step - loss: 0.2169 - acc: 0.9083\n",
            "Epoch 536/600\n",
            "120/120 [==============================] - 0s 122us/step - loss: 0.2166 - acc: 0.9083\n",
            "Epoch 537/600\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.2165 - acc: 0.9083\n",
            "Epoch 538/600\n",
            "120/120 [==============================] - 0s 129us/step - loss: 0.2163 - acc: 0.9083\n",
            "Epoch 539/600\n",
            "120/120 [==============================] - 0s 119us/step - loss: 0.2161 - acc: 0.9083\n",
            "Epoch 540/600\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.2160 - acc: 0.9083\n",
            "Epoch 541/600\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.2158 - acc: 0.9083\n",
            "Epoch 542/600\n",
            "120/120 [==============================] - 0s 126us/step - loss: 0.2157 - acc: 0.9083\n",
            "Epoch 543/600\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2156 - acc: 0.9083\n",
            "Epoch 544/600\n",
            "120/120 [==============================] - 0s 181us/step - loss: 0.2155 - acc: 0.9083\n",
            "Epoch 545/600\n",
            "120/120 [==============================] - 0s 120us/step - loss: 0.2154 - acc: 0.9083\n",
            "Epoch 546/600\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2151 - acc: 0.9083\n",
            "Epoch 547/600\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2151 - acc: 0.9083\n",
            "Epoch 548/600\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2150 - acc: 0.9167\n",
            "Epoch 549/600\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2149 - acc: 0.9167\n",
            "Epoch 550/600\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2149 - acc: 0.9167\n",
            "Epoch 551/600\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2148 - acc: 0.9167\n",
            "Epoch 552/600\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2148 - acc: 0.9250\n",
            "Epoch 553/600\n",
            "120/120 [==============================] - 0s 125us/step - loss: 0.2146 - acc: 0.9167\n",
            "Epoch 554/600\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2145 - acc: 0.9250\n",
            "Epoch 555/600\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2144 - acc: 0.9167\n",
            "Epoch 556/600\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2142 - acc: 0.9167\n",
            "Epoch 557/600\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2144 - acc: 0.9167\n",
            "Epoch 558/600\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2143 - acc: 0.9333\n",
            "Epoch 559/600\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.2140 - acc: 0.9333\n",
            "Epoch 560/600\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2139 - acc: 0.9167\n",
            "Epoch 561/600\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2139 - acc: 0.9333\n",
            "Epoch 562/600\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2138 - acc: 0.9333\n",
            "Epoch 563/600\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2135 - acc: 0.9250\n",
            "Epoch 564/600\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2133 - acc: 0.9333\n",
            "Epoch 565/600\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2134 - acc: 0.9250\n",
            "Epoch 566/600\n",
            "120/120 [==============================] - 0s 77us/step - loss: 0.2133 - acc: 0.9250\n",
            "Epoch 567/600\n",
            "120/120 [==============================] - 0s 77us/step - loss: 0.2129 - acc: 0.9167\n",
            "Epoch 568/600\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2127 - acc: 0.9250\n",
            "Epoch 569/600\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2125 - acc: 0.9167\n",
            "Epoch 570/600\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2125 - acc: 0.9167\n",
            "Epoch 571/600\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2123 - acc: 0.9167\n",
            "Epoch 572/600\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2122 - acc: 0.9167\n",
            "Epoch 573/600\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2121 - acc: 0.9167\n",
            "Epoch 574/600\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2124 - acc: 0.9167\n",
            "Epoch 575/600\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.2120 - acc: 0.9083\n",
            "Epoch 576/600\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2118 - acc: 0.9083\n",
            "Epoch 577/600\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.2117 - acc: 0.9167\n",
            "Epoch 578/600\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.2116 - acc: 0.9167\n",
            "Epoch 579/600\n",
            "120/120 [==============================] - 0s 123us/step - loss: 0.2115 - acc: 0.9167\n",
            "Epoch 580/600\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2114 - acc: 0.9167\n",
            "Epoch 581/600\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2113 - acc: 0.9167\n",
            "Epoch 582/600\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2112 - acc: 0.9167\n",
            "Epoch 583/600\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2111 - acc: 0.9167\n",
            "Epoch 584/600\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.2111 - acc: 0.9083\n",
            "Epoch 585/600\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2111 - acc: 0.9083\n",
            "Epoch 586/600\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2110 - acc: 0.9083\n",
            "Epoch 587/600\n",
            "120/120 [==============================] - 0s 121us/step - loss: 0.2110 - acc: 0.9083\n",
            "Epoch 588/600\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.2109 - acc: 0.9083\n",
            "Epoch 589/600\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.2106 - acc: 0.9083\n",
            "Epoch 590/600\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2105 - acc: 0.9167\n",
            "Epoch 591/600\n",
            "120/120 [==============================] - 0s 76us/step - loss: 0.2105 - acc: 0.9167\n",
            "Epoch 592/600\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2102 - acc: 0.9167\n",
            "Epoch 593/600\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2101 - acc: 0.9167\n",
            "Epoch 594/600\n",
            "120/120 [==============================] - 0s 130us/step - loss: 0.2102 - acc: 0.9167\n",
            "Epoch 595/600\n",
            "120/120 [==============================] - 0s 122us/step - loss: 0.2099 - acc: 0.9167\n",
            "Epoch 596/600\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2099 - acc: 0.9167\n",
            "Epoch 597/600\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2098 - acc: 0.9083\n",
            "Epoch 598/600\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2098 - acc: 0.9083\n",
            "Epoch 599/600\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2097 - acc: 0.9083\n",
            "Epoch 600/600\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2095 - acc: 0.9083\n",
            "60/60 [==============================] - 1s 9ms/step\n",
            "\n",
            "acc: 90.00%\n",
            "[[26  3  2]\n",
            " [ 1 19  0]\n",
            " [ 0  0  9]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.84      0.90        31\n",
            "           1       0.86      0.95      0.90        20\n",
            "           2       0.82      1.00      0.90         9\n",
            "\n",
            "    accuracy                           0.90        60\n",
            "   macro avg       0.88      0.93      0.90        60\n",
            "weighted avg       0.91      0.90      0.90        60\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_159 (Dense)            (None, 10)                30        \n",
            "_________________________________________________________________\n",
            "dense_160 (Dense)            (None, 20)                220       \n",
            "_________________________________________________________________\n",
            "dense_161 (Dense)            (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_162 (Dense)            (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_163 (Dense)            (None, 3)                 63        \n",
            "=================================================================\n",
            "Total params: 1,153\n",
            "Trainable params: 1,153\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/700\n",
            "120/120 [==============================] - 2s 13ms/step - loss: 1.1359 - acc: 0.3250\n",
            "Epoch 2/700\n",
            "120/120 [==============================] - 0s 112us/step - loss: 1.1330 - acc: 0.3250\n",
            "Epoch 3/700\n",
            "120/120 [==============================] - 0s 97us/step - loss: 1.1304 - acc: 0.3417\n",
            "Epoch 4/700\n",
            "120/120 [==============================] - 0s 85us/step - loss: 1.1277 - acc: 0.3667\n",
            "Epoch 5/700\n",
            "120/120 [==============================] - 0s 86us/step - loss: 1.1250 - acc: 0.3667\n",
            "Epoch 6/700\n",
            "120/120 [==============================] - 0s 85us/step - loss: 1.1224 - acc: 0.4000\n",
            "Epoch 7/700\n",
            "120/120 [==============================] - 0s 96us/step - loss: 1.1197 - acc: 0.5083\n",
            "Epoch 8/700\n",
            "120/120 [==============================] - 0s 90us/step - loss: 1.1166 - acc: 0.5333\n",
            "Epoch 9/700\n",
            "120/120 [==============================] - 0s 114us/step - loss: 1.1133 - acc: 0.5333\n",
            "Epoch 10/700\n",
            "120/120 [==============================] - 0s 111us/step - loss: 1.1105 - acc: 0.5333\n",
            "Epoch 11/700\n",
            "120/120 [==============================] - 0s 93us/step - loss: 1.1078 - acc: 0.5667\n",
            "Epoch 12/700\n",
            "120/120 [==============================] - 0s 88us/step - loss: 1.1050 - acc: 0.5750\n",
            "Epoch 13/700\n",
            "120/120 [==============================] - 0s 91us/step - loss: 1.1021 - acc: 0.6083\n",
            "Epoch 14/700\n",
            "120/120 [==============================] - 0s 92us/step - loss: 1.0995 - acc: 0.6167\n",
            "Epoch 15/700\n",
            "120/120 [==============================] - 0s 105us/step - loss: 1.0969 - acc: 0.6250\n",
            "Epoch 16/700\n",
            "120/120 [==============================] - 0s 103us/step - loss: 1.0939 - acc: 0.6250\n",
            "Epoch 17/700\n",
            "120/120 [==============================] - 0s 96us/step - loss: 1.0914 - acc: 0.6250\n",
            "Epoch 18/700\n",
            "120/120 [==============================] - 0s 100us/step - loss: 1.0889 - acc: 0.6250\n",
            "Epoch 19/700\n",
            "120/120 [==============================] - 0s 102us/step - loss: 1.0867 - acc: 0.6500\n",
            "Epoch 20/700\n",
            "120/120 [==============================] - 0s 100us/step - loss: 1.0842 - acc: 0.6417\n",
            "Epoch 21/700\n",
            "120/120 [==============================] - 0s 95us/step - loss: 1.0819 - acc: 0.6500\n",
            "Epoch 22/700\n",
            "120/120 [==============================] - 0s 118us/step - loss: 1.0795 - acc: 0.6500\n",
            "Epoch 23/700\n",
            "120/120 [==============================] - 0s 110us/step - loss: 1.0773 - acc: 0.6500\n",
            "Epoch 24/700\n",
            "120/120 [==============================] - 0s 107us/step - loss: 1.0748 - acc: 0.6583\n",
            "Epoch 25/700\n",
            "120/120 [==============================] - 0s 128us/step - loss: 1.0727 - acc: 0.6583\n",
            "Epoch 26/700\n",
            "120/120 [==============================] - 0s 117us/step - loss: 1.0705 - acc: 0.6667\n",
            "Epoch 27/700\n",
            "120/120 [==============================] - 0s 100us/step - loss: 1.0683 - acc: 0.6667\n",
            "Epoch 28/700\n",
            "120/120 [==============================] - 0s 84us/step - loss: 1.0656 - acc: 0.6667\n",
            "Epoch 29/700\n",
            "120/120 [==============================] - 0s 73us/step - loss: 1.0628 - acc: 0.6583\n",
            "Epoch 30/700\n",
            "120/120 [==============================] - 0s 71us/step - loss: 1.0605 - acc: 0.6667\n",
            "Epoch 31/700\n",
            "120/120 [==============================] - 0s 107us/step - loss: 1.0581 - acc: 0.6583\n",
            "Epoch 32/700\n",
            "120/120 [==============================] - 0s 93us/step - loss: 1.0558 - acc: 0.6583\n",
            "Epoch 33/700\n",
            "120/120 [==============================] - 0s 116us/step - loss: 1.0535 - acc: 0.6583\n",
            "Epoch 34/700\n",
            "120/120 [==============================] - 0s 87us/step - loss: 1.0515 - acc: 0.6583\n",
            "Epoch 35/700\n",
            "120/120 [==============================] - 0s 97us/step - loss: 1.0490 - acc: 0.6250\n",
            "Epoch 36/700\n",
            "120/120 [==============================] - 0s 97us/step - loss: 1.0467 - acc: 0.6417\n",
            "Epoch 37/700\n",
            "120/120 [==============================] - 0s 109us/step - loss: 1.0445 - acc: 0.6583\n",
            "Epoch 38/700\n",
            "120/120 [==============================] - 0s 101us/step - loss: 1.0422 - acc: 0.6333\n",
            "Epoch 39/700\n",
            "120/120 [==============================] - 0s 98us/step - loss: 1.0402 - acc: 0.6583\n",
            "Epoch 40/700\n",
            "120/120 [==============================] - 0s 76us/step - loss: 1.0380 - acc: 0.6333\n",
            "Epoch 41/700\n",
            "120/120 [==============================] - 0s 97us/step - loss: 1.0361 - acc: 0.6583\n",
            "Epoch 42/700\n",
            "120/120 [==============================] - 0s 98us/step - loss: 1.0342 - acc: 0.6500\n",
            "Epoch 43/700\n",
            "120/120 [==============================] - 0s 97us/step - loss: 1.0325 - acc: 0.6583\n",
            "Epoch 44/700\n",
            "120/120 [==============================] - 0s 86us/step - loss: 1.0306 - acc: 0.6583\n",
            "Epoch 45/700\n",
            "120/120 [==============================] - 0s 91us/step - loss: 1.0284 - acc: 0.6583\n",
            "Epoch 46/700\n",
            "120/120 [==============================] - 0s 99us/step - loss: 1.0262 - acc: 0.6583\n",
            "Epoch 47/700\n",
            "120/120 [==============================] - 0s 101us/step - loss: 1.0242 - acc: 0.6583\n",
            "Epoch 48/700\n",
            "120/120 [==============================] - 0s 93us/step - loss: 1.0220 - acc: 0.6583\n",
            "Epoch 49/700\n",
            "120/120 [==============================] - 0s 95us/step - loss: 1.0198 - acc: 0.6583\n",
            "Epoch 50/700\n",
            "120/120 [==============================] - 0s 82us/step - loss: 1.0175 - acc: 0.6583\n",
            "Epoch 51/700\n",
            "120/120 [==============================] - 0s 84us/step - loss: 1.0153 - acc: 0.6583\n",
            "Epoch 52/700\n",
            "120/120 [==============================] - 0s 84us/step - loss: 1.0132 - acc: 0.6417\n",
            "Epoch 53/700\n",
            "120/120 [==============================] - 0s 92us/step - loss: 1.0109 - acc: 0.6583\n",
            "Epoch 54/700\n",
            "120/120 [==============================] - 0s 85us/step - loss: 1.0086 - acc: 0.6417\n",
            "Epoch 55/700\n",
            "120/120 [==============================] - 0s 121us/step - loss: 1.0064 - acc: 0.6417\n",
            "Epoch 56/700\n",
            "120/120 [==============================] - 0s 95us/step - loss: 1.0044 - acc: 0.6250\n",
            "Epoch 57/700\n",
            "120/120 [==============================] - 0s 105us/step - loss: 1.0023 - acc: 0.6333\n",
            "Epoch 58/700\n",
            "120/120 [==============================] - 0s 99us/step - loss: 1.0003 - acc: 0.6333\n",
            "Epoch 59/700\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.9983 - acc: 0.6583\n",
            "Epoch 60/700\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.9963 - acc: 0.6417\n",
            "Epoch 61/700\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.9942 - acc: 0.6583\n",
            "Epoch 62/700\n",
            "120/120 [==============================] - 0s 157us/step - loss: 0.9919 - acc: 0.6500\n",
            "Epoch 63/700\n",
            "120/120 [==============================] - 0s 121us/step - loss: 0.9896 - acc: 0.6583\n",
            "Epoch 64/700\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.9874 - acc: 0.6500\n",
            "Epoch 65/700\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.9852 - acc: 0.6250\n",
            "Epoch 66/700\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.9831 - acc: 0.6583\n",
            "Epoch 67/700\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.9809 - acc: 0.6417\n",
            "Epoch 68/700\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.9791 - acc: 0.6583\n",
            "Epoch 69/700\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.9766 - acc: 0.6583\n",
            "Epoch 70/700\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.9746 - acc: 0.6583\n",
            "Epoch 71/700\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.9722 - acc: 0.6417\n",
            "Epoch 72/700\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.9699 - acc: 0.6417\n",
            "Epoch 73/700\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.9676 - acc: 0.6417\n",
            "Epoch 74/700\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.9651 - acc: 0.6333\n",
            "Epoch 75/700\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.9629 - acc: 0.6417\n",
            "Epoch 76/700\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.9608 - acc: 0.6500\n",
            "Epoch 77/700\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.9587 - acc: 0.6500\n",
            "Epoch 78/700\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.9561 - acc: 0.6500\n",
            "Epoch 79/700\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.9538 - acc: 0.6500\n",
            "Epoch 80/700\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.9513 - acc: 0.6417\n",
            "Epoch 81/700\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.9489 - acc: 0.6500\n",
            "Epoch 82/700\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.9466 - acc: 0.6417\n",
            "Epoch 83/700\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.9441 - acc: 0.6417\n",
            "Epoch 84/700\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.9417 - acc: 0.6583\n",
            "Epoch 85/700\n",
            "120/120 [==============================] - 0s 152us/step - loss: 0.9393 - acc: 0.6583\n",
            "Epoch 86/700\n",
            "120/120 [==============================] - 0s 192us/step - loss: 0.9368 - acc: 0.6583\n",
            "Epoch 87/700\n",
            "120/120 [==============================] - 0s 130us/step - loss: 0.9341 - acc: 0.6500\n",
            "Epoch 88/700\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.9320 - acc: 0.6583\n",
            "Epoch 89/700\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.9294 - acc: 0.6583\n",
            "Epoch 90/700\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.9267 - acc: 0.6583\n",
            "Epoch 91/700\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.9242 - acc: 0.6583\n",
            "Epoch 92/700\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.9216 - acc: 0.6583\n",
            "Epoch 93/700\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.9192 - acc: 0.6583\n",
            "Epoch 94/700\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.9167 - acc: 0.6583\n",
            "Epoch 95/700\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.9142 - acc: 0.6583\n",
            "Epoch 96/700\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.9117 - acc: 0.6583\n",
            "Epoch 97/700\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.9092 - acc: 0.6667\n",
            "Epoch 98/700\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.9065 - acc: 0.6667\n",
            "Epoch 99/700\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.9041 - acc: 0.6667\n",
            "Epoch 100/700\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.9015 - acc: 0.6667\n",
            "Epoch 101/700\n",
            "120/120 [==============================] - 0s 75us/step - loss: 0.8991 - acc: 0.6667\n",
            "Epoch 102/700\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.8962 - acc: 0.6667\n",
            "Epoch 103/700\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.8937 - acc: 0.6667\n",
            "Epoch 104/700\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.8910 - acc: 0.6667\n",
            "Epoch 105/700\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.8881 - acc: 0.6667\n",
            "Epoch 106/700\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.8854 - acc: 0.6667\n",
            "Epoch 107/700\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.8826 - acc: 0.6667\n",
            "Epoch 108/700\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.8796 - acc: 0.6667\n",
            "Epoch 109/700\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.8768 - acc: 0.6667\n",
            "Epoch 110/700\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.8741 - acc: 0.6750\n",
            "Epoch 111/700\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.8711 - acc: 0.6750\n",
            "Epoch 112/700\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.8681 - acc: 0.6750\n",
            "Epoch 113/700\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.8653 - acc: 0.6750\n",
            "Epoch 114/700\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.8623 - acc: 0.6833\n",
            "Epoch 115/700\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.8595 - acc: 0.6833\n",
            "Epoch 116/700\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.8567 - acc: 0.6833\n",
            "Epoch 117/700\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.8536 - acc: 0.6833\n",
            "Epoch 118/700\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.8507 - acc: 0.6917\n",
            "Epoch 119/700\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.8476 - acc: 0.6833\n",
            "Epoch 120/700\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.8448 - acc: 0.7000\n",
            "Epoch 121/700\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.8418 - acc: 0.7000\n",
            "Epoch 122/700\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.8387 - acc: 0.7083\n",
            "Epoch 123/700\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.8358 - acc: 0.7083\n",
            "Epoch 124/700\n",
            "120/120 [==============================] - 0s 138us/step - loss: 0.8326 - acc: 0.7083\n",
            "Epoch 125/700\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.8297 - acc: 0.7083\n",
            "Epoch 126/700\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.8265 - acc: 0.7083\n",
            "Epoch 127/700\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.8233 - acc: 0.7083\n",
            "Epoch 128/700\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.8203 - acc: 0.7083\n",
            "Epoch 129/700\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.8171 - acc: 0.7083\n",
            "Epoch 130/700\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.8141 - acc: 0.7083\n",
            "Epoch 131/700\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.8109 - acc: 0.7083\n",
            "Epoch 132/700\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.8078 - acc: 0.7083\n",
            "Epoch 133/700\n",
            "120/120 [==============================] - 0s 119us/step - loss: 0.8045 - acc: 0.7167\n",
            "Epoch 134/700\n",
            "120/120 [==============================] - 0s 119us/step - loss: 0.8013 - acc: 0.7250\n",
            "Epoch 135/700\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.7983 - acc: 0.7250\n",
            "Epoch 136/700\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.7950 - acc: 0.7417\n",
            "Epoch 137/700\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.7919 - acc: 0.7417\n",
            "Epoch 138/700\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.7888 - acc: 0.7417\n",
            "Epoch 139/700\n",
            "120/120 [==============================] - 0s 77us/step - loss: 0.7857 - acc: 0.7417\n",
            "Epoch 140/700\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.7827 - acc: 0.7417\n",
            "Epoch 141/700\n",
            "120/120 [==============================] - 0s 117us/step - loss: 0.7797 - acc: 0.7417\n",
            "Epoch 142/700\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.7765 - acc: 0.7417\n",
            "Epoch 143/700\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.7735 - acc: 0.7417\n",
            "Epoch 144/700\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.7703 - acc: 0.7417\n",
            "Epoch 145/700\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.7673 - acc: 0.7417\n",
            "Epoch 146/700\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.7642 - acc: 0.7583\n",
            "Epoch 147/700\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.7610 - acc: 0.7583\n",
            "Epoch 148/700\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.7579 - acc: 0.7583\n",
            "Epoch 149/700\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.7549 - acc: 0.7583\n",
            "Epoch 150/700\n",
            "120/120 [==============================] - 0s 129us/step - loss: 0.7518 - acc: 0.7583\n",
            "Epoch 151/700\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.7485 - acc: 0.7667\n",
            "Epoch 152/700\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.7454 - acc: 0.7750\n",
            "Epoch 153/700\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.7423 - acc: 0.7750\n",
            "Epoch 154/700\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.7395 - acc: 0.7750\n",
            "Epoch 155/700\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.7365 - acc: 0.7750\n",
            "Epoch 156/700\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.7332 - acc: 0.7750\n",
            "Epoch 157/700\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.7300 - acc: 0.7750\n",
            "Epoch 158/700\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.7271 - acc: 0.7750\n",
            "Epoch 159/700\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.7239 - acc: 0.7833\n",
            "Epoch 160/700\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.7207 - acc: 0.7833\n",
            "Epoch 161/700\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.7175 - acc: 0.7833\n",
            "Epoch 162/700\n",
            "120/120 [==============================] - 0s 76us/step - loss: 0.7145 - acc: 0.7917\n",
            "Epoch 163/700\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.7115 - acc: 0.7917\n",
            "Epoch 164/700\n",
            "120/120 [==============================] - 0s 138us/step - loss: 0.7086 - acc: 0.7917\n",
            "Epoch 165/700\n",
            "120/120 [==============================] - 0s 132us/step - loss: 0.7058 - acc: 0.7917\n",
            "Epoch 166/700\n",
            "120/120 [==============================] - 0s 146us/step - loss: 0.7026 - acc: 0.7917\n",
            "Epoch 167/700\n",
            "120/120 [==============================] - 0s 119us/step - loss: 0.6996 - acc: 0.7917\n",
            "Epoch 168/700\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.6966 - acc: 0.7917\n",
            "Epoch 169/700\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.6932 - acc: 0.7917\n",
            "Epoch 170/700\n",
            "120/120 [==============================] - 0s 127us/step - loss: 0.6904 - acc: 0.7917\n",
            "Epoch 171/700\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.6875 - acc: 0.8083\n",
            "Epoch 172/700\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.6845 - acc: 0.8083\n",
            "Epoch 173/700\n",
            "120/120 [==============================] - 0s 123us/step - loss: 0.6814 - acc: 0.8083\n",
            "Epoch 174/700\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.6785 - acc: 0.8167\n",
            "Epoch 175/700\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.6756 - acc: 0.8250\n",
            "Epoch 176/700\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.6726 - acc: 0.8250\n",
            "Epoch 177/700\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.6697 - acc: 0.8250\n",
            "Epoch 178/700\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.6666 - acc: 0.8250\n",
            "Epoch 179/700\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.6634 - acc: 0.8250\n",
            "Epoch 180/700\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.6605 - acc: 0.8250\n",
            "Epoch 181/700\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.6575 - acc: 0.8250\n",
            "Epoch 182/700\n",
            "120/120 [==============================] - 0s 122us/step - loss: 0.6546 - acc: 0.8250\n",
            "Epoch 183/700\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.6515 - acc: 0.8250\n",
            "Epoch 184/700\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.6484 - acc: 0.8250\n",
            "Epoch 185/700\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.6455 - acc: 0.8250\n",
            "Epoch 186/700\n",
            "120/120 [==============================] - 0s 132us/step - loss: 0.6424 - acc: 0.8250\n",
            "Epoch 187/700\n",
            "120/120 [==============================] - 0s 154us/step - loss: 0.6393 - acc: 0.8250\n",
            "Epoch 188/700\n",
            "120/120 [==============================] - 0s 137us/step - loss: 0.6363 - acc: 0.8250\n",
            "Epoch 189/700\n",
            "120/120 [==============================] - 0s 115us/step - loss: 0.6332 - acc: 0.8250\n",
            "Epoch 190/700\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.6302 - acc: 0.8250\n",
            "Epoch 191/700\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.6271 - acc: 0.8250\n",
            "Epoch 192/700\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.6240 - acc: 0.8250\n",
            "Epoch 193/700\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.6210 - acc: 0.8250\n",
            "Epoch 194/700\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.6180 - acc: 0.8250\n",
            "Epoch 195/700\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.6151 - acc: 0.8250\n",
            "Epoch 196/700\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.6121 - acc: 0.8250\n",
            "Epoch 197/700\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.6091 - acc: 0.8250\n",
            "Epoch 198/700\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.6063 - acc: 0.8333\n",
            "Epoch 199/700\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.6034 - acc: 0.8333\n",
            "Epoch 200/700\n",
            "120/120 [==============================] - 0s 138us/step - loss: 0.6002 - acc: 0.8333\n",
            "Epoch 201/700\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.5974 - acc: 0.8333\n",
            "Epoch 202/700\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.5945 - acc: 0.8500\n",
            "Epoch 203/700\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.5915 - acc: 0.8500\n",
            "Epoch 204/700\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.5884 - acc: 0.8500\n",
            "Epoch 205/700\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.5856 - acc: 0.8500\n",
            "Epoch 206/700\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.5827 - acc: 0.8500\n",
            "Epoch 207/700\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.5799 - acc: 0.8500\n",
            "Epoch 208/700\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.5768 - acc: 0.8500\n",
            "Epoch 209/700\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.5738 - acc: 0.8500\n",
            "Epoch 210/700\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.5709 - acc: 0.8500\n",
            "Epoch 211/700\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.5680 - acc: 0.8500\n",
            "Epoch 212/700\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.5651 - acc: 0.8500\n",
            "Epoch 213/700\n",
            "120/120 [==============================] - 0s 123us/step - loss: 0.5622 - acc: 0.8500\n",
            "Epoch 214/700\n",
            "120/120 [==============================] - 0s 117us/step - loss: 0.5595 - acc: 0.8583\n",
            "Epoch 215/700\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.5567 - acc: 0.8500\n",
            "Epoch 216/700\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.5538 - acc: 0.8583\n",
            "Epoch 217/700\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.5511 - acc: 0.8583\n",
            "Epoch 218/700\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.5483 - acc: 0.8500\n",
            "Epoch 219/700\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.5454 - acc: 0.8583\n",
            "Epoch 220/700\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.5425 - acc: 0.8583\n",
            "Epoch 221/700\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.5398 - acc: 0.8583\n",
            "Epoch 222/700\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.5370 - acc: 0.8667\n",
            "Epoch 223/700\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.5342 - acc: 0.8583\n",
            "Epoch 224/700\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.5316 - acc: 0.8583\n",
            "Epoch 225/700\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.5289 - acc: 0.8583\n",
            "Epoch 226/700\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.5262 - acc: 0.8667\n",
            "Epoch 227/700\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.5233 - acc: 0.8750\n",
            "Epoch 228/700\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.5205 - acc: 0.8750\n",
            "Epoch 229/700\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.5178 - acc: 0.8750\n",
            "Epoch 230/700\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.5151 - acc: 0.8750\n",
            "Epoch 231/700\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.5126 - acc: 0.8750\n",
            "Epoch 232/700\n",
            "120/120 [==============================] - 0s 134us/step - loss: 0.5100 - acc: 0.8833\n",
            "Epoch 233/700\n",
            "120/120 [==============================] - 0s 115us/step - loss: 0.5073 - acc: 0.8833\n",
            "Epoch 234/700\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.5046 - acc: 0.8833\n",
            "Epoch 235/700\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.5019 - acc: 0.8833\n",
            "Epoch 236/700\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.4993 - acc: 0.8833\n",
            "Epoch 237/700\n",
            "120/120 [==============================] - 0s 143us/step - loss: 0.4966 - acc: 0.8917\n",
            "Epoch 238/700\n",
            "120/120 [==============================] - 0s 162us/step - loss: 0.4941 - acc: 0.8833\n",
            "Epoch 239/700\n",
            "120/120 [==============================] - 0s 139us/step - loss: 0.4916 - acc: 0.8833\n",
            "Epoch 240/700\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.4888 - acc: 0.8917\n",
            "Epoch 241/700\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.4867 - acc: 0.8917\n",
            "Epoch 242/700\n",
            "120/120 [==============================] - 0s 77us/step - loss: 0.4835 - acc: 0.8917\n",
            "Epoch 243/700\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.4809 - acc: 0.8917\n",
            "Epoch 244/700\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.4783 - acc: 0.8917\n",
            "Epoch 245/700\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.4760 - acc: 0.8917\n",
            "Epoch 246/700\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.4735 - acc: 0.8917\n",
            "Epoch 247/700\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.4709 - acc: 0.8917\n",
            "Epoch 248/700\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.4684 - acc: 0.8917\n",
            "Epoch 249/700\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.4660 - acc: 0.8917\n",
            "Epoch 250/700\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.4636 - acc: 0.8917\n",
            "Epoch 251/700\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.4613 - acc: 0.8917\n",
            "Epoch 252/700\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.4591 - acc: 0.8917\n",
            "Epoch 253/700\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.4570 - acc: 0.8917\n",
            "Epoch 254/700\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.4545 - acc: 0.8917\n",
            "Epoch 255/700\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.4519 - acc: 0.8917\n",
            "Epoch 256/700\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.4496 - acc: 0.8917\n",
            "Epoch 257/700\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.4474 - acc: 0.8917\n",
            "Epoch 258/700\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.4454 - acc: 0.8917\n",
            "Epoch 259/700\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.4431 - acc: 0.8917\n",
            "Epoch 260/700\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.4409 - acc: 0.8917\n",
            "Epoch 261/700\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.4386 - acc: 0.8917\n",
            "Epoch 262/700\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.4363 - acc: 0.8917\n",
            "Epoch 263/700\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.4340 - acc: 0.8917\n",
            "Epoch 264/700\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.4317 - acc: 0.8917\n",
            "Epoch 265/700\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.4296 - acc: 0.8917\n",
            "Epoch 266/700\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.4275 - acc: 0.9083\n",
            "Epoch 267/700\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.4253 - acc: 0.9083\n",
            "Epoch 268/700\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.4232 - acc: 0.9083\n",
            "Epoch 269/700\n",
            "120/120 [==============================] - 0s 125us/step - loss: 0.4210 - acc: 0.9167\n",
            "Epoch 270/700\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.4187 - acc: 0.9167\n",
            "Epoch 271/700\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.4166 - acc: 0.9167\n",
            "Epoch 272/700\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.4145 - acc: 0.9167\n",
            "Epoch 273/700\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.4123 - acc: 0.9167\n",
            "Epoch 274/700\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.4101 - acc: 0.9167\n",
            "Epoch 275/700\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.4080 - acc: 0.9167\n",
            "Epoch 276/700\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.4061 - acc: 0.9167\n",
            "Epoch 277/700\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.4042 - acc: 0.9167\n",
            "Epoch 278/700\n",
            "120/120 [==============================] - 0s 139us/step - loss: 0.4023 - acc: 0.9167\n",
            "Epoch 279/700\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.4004 - acc: 0.9167\n",
            "Epoch 280/700\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.3986 - acc: 0.9167\n",
            "Epoch 281/700\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.3967 - acc: 0.9250\n",
            "Epoch 282/700\n",
            "120/120 [==============================] - 0s 120us/step - loss: 0.3950 - acc: 0.9167\n",
            "Epoch 283/700\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.3931 - acc: 0.9167\n",
            "Epoch 284/700\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.3913 - acc: 0.9167\n",
            "Epoch 285/700\n",
            "120/120 [==============================] - 0s 120us/step - loss: 0.3895 - acc: 0.9167\n",
            "Epoch 286/700\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.3875 - acc: 0.9167\n",
            "Epoch 287/700\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.3859 - acc: 0.9250\n",
            "Epoch 288/700\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.3842 - acc: 0.9250\n",
            "Epoch 289/700\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.3825 - acc: 0.9167\n",
            "Epoch 290/700\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.3806 - acc: 0.9167\n",
            "Epoch 291/700\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.3789 - acc: 0.9167\n",
            "Epoch 292/700\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.3772 - acc: 0.9167\n",
            "Epoch 293/700\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.3755 - acc: 0.9167\n",
            "Epoch 294/700\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.3739 - acc: 0.9167\n",
            "Epoch 295/700\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.3722 - acc: 0.9167\n",
            "Epoch 296/700\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.3704 - acc: 0.9167\n",
            "Epoch 297/700\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.3689 - acc: 0.9167\n",
            "Epoch 298/700\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.3671 - acc: 0.9167\n",
            "Epoch 299/700\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.3657 - acc: 0.9167\n",
            "Epoch 300/700\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.3645 - acc: 0.9167\n",
            "Epoch 301/700\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.3633 - acc: 0.9167\n",
            "Epoch 302/700\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.3619 - acc: 0.9167\n",
            "Epoch 303/700\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.3602 - acc: 0.9167\n",
            "Epoch 304/700\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.3583 - acc: 0.9167\n",
            "Epoch 305/700\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.3563 - acc: 0.9167\n",
            "Epoch 306/700\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.3547 - acc: 0.9167\n",
            "Epoch 307/700\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.3531 - acc: 0.9250\n",
            "Epoch 308/700\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.3514 - acc: 0.9250\n",
            "Epoch 309/700\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.3499 - acc: 0.9250\n",
            "Epoch 310/700\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.3485 - acc: 0.9250\n",
            "Epoch 311/700\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.3467 - acc: 0.9167\n",
            "Epoch 312/700\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.3459 - acc: 0.9250\n",
            "Epoch 313/700\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.3446 - acc: 0.9167\n",
            "Epoch 314/700\n",
            "120/120 [==============================] - 0s 191us/step - loss: 0.3430 - acc: 0.9250\n",
            "Epoch 315/700\n",
            "120/120 [==============================] - 0s 120us/step - loss: 0.3419 - acc: 0.9167\n",
            "Epoch 316/700\n",
            "120/120 [==============================] - 0s 123us/step - loss: 0.3406 - acc: 0.9167\n",
            "Epoch 317/700\n",
            "120/120 [==============================] - 0s 130us/step - loss: 0.3394 - acc: 0.9167\n",
            "Epoch 318/700\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.3377 - acc: 0.9167\n",
            "Epoch 319/700\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.3362 - acc: 0.9250\n",
            "Epoch 320/700\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.3348 - acc: 0.9167\n",
            "Epoch 321/700\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.3335 - acc: 0.9167\n",
            "Epoch 322/700\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.3320 - acc: 0.9167\n",
            "Epoch 323/700\n",
            "120/120 [==============================] - 0s 115us/step - loss: 0.3308 - acc: 0.9250\n",
            "Epoch 324/700\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.3297 - acc: 0.9167\n",
            "Epoch 325/700\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.3283 - acc: 0.9167\n",
            "Epoch 326/700\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.3270 - acc: 0.9167\n",
            "Epoch 327/700\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.3256 - acc: 0.9250\n",
            "Epoch 328/700\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.3245 - acc: 0.9167\n",
            "Epoch 329/700\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.3232 - acc: 0.9083\n",
            "Epoch 330/700\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.3219 - acc: 0.9167\n",
            "Epoch 331/700\n",
            "120/120 [==============================] - 0s 117us/step - loss: 0.3208 - acc: 0.9167\n",
            "Epoch 332/700\n",
            "120/120 [==============================] - 0s 115us/step - loss: 0.3196 - acc: 0.9083\n",
            "Epoch 333/700\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.3187 - acc: 0.9083\n",
            "Epoch 334/700\n",
            "120/120 [==============================] - 0s 121us/step - loss: 0.3176 - acc: 0.9083\n",
            "Epoch 335/700\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.3163 - acc: 0.9083\n",
            "Epoch 336/700\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.3153 - acc: 0.9083\n",
            "Epoch 337/700\n",
            "120/120 [==============================] - 0s 125us/step - loss: 0.3142 - acc: 0.9083\n",
            "Epoch 338/700\n",
            "120/120 [==============================] - 0s 122us/step - loss: 0.3130 - acc: 0.9083\n",
            "Epoch 339/700\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.3120 - acc: 0.9083\n",
            "Epoch 340/700\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.3110 - acc: 0.9083\n",
            "Epoch 341/700\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.3100 - acc: 0.9167\n",
            "Epoch 342/700\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.3092 - acc: 0.9083\n",
            "Epoch 343/700\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.3077 - acc: 0.9083\n",
            "Epoch 344/700\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.3070 - acc: 0.9083\n",
            "Epoch 345/700\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.3060 - acc: 0.9083\n",
            "Epoch 346/700\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.3050 - acc: 0.9083\n",
            "Epoch 347/700\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.3038 - acc: 0.9083\n",
            "Epoch 348/700\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.3028 - acc: 0.9167\n",
            "Epoch 349/700\n",
            "120/120 [==============================] - 0s 149us/step - loss: 0.3018 - acc: 0.9083\n",
            "Epoch 350/700\n",
            "120/120 [==============================] - 0s 121us/step - loss: 0.3008 - acc: 0.9083\n",
            "Epoch 351/700\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.2998 - acc: 0.9083\n",
            "Epoch 352/700\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2988 - acc: 0.9083\n",
            "Epoch 353/700\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.2979 - acc: 0.9083\n",
            "Epoch 354/700\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2967 - acc: 0.9167\n",
            "Epoch 355/700\n",
            "120/120 [==============================] - 0s 135us/step - loss: 0.2961 - acc: 0.9167\n",
            "Epoch 356/700\n",
            "120/120 [==============================] - 0s 128us/step - loss: 0.2950 - acc: 0.9083\n",
            "Epoch 357/700\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.2942 - acc: 0.9083\n",
            "Epoch 358/700\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2933 - acc: 0.9083\n",
            "Epoch 359/700\n",
            "120/120 [==============================] - 0s 76us/step - loss: 0.2921 - acc: 0.9167\n",
            "Epoch 360/700\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2912 - acc: 0.9167\n",
            "Epoch 361/700\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.2903 - acc: 0.9167\n",
            "Epoch 362/700\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2895 - acc: 0.9167\n",
            "Epoch 363/700\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2887 - acc: 0.9167\n",
            "Epoch 364/700\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.2878 - acc: 0.9167\n",
            "Epoch 365/700\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2869 - acc: 0.9083\n",
            "Epoch 366/700\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.2861 - acc: 0.9167\n",
            "Epoch 367/700\n",
            "120/120 [==============================] - 0s 77us/step - loss: 0.2853 - acc: 0.9167\n",
            "Epoch 368/700\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2846 - acc: 0.9250\n",
            "Epoch 369/700\n",
            "120/120 [==============================] - 0s 72us/step - loss: 0.2839 - acc: 0.9167\n",
            "Epoch 370/700\n",
            "120/120 [==============================] - 0s 74us/step - loss: 0.2831 - acc: 0.9167\n",
            "Epoch 371/700\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2824 - acc: 0.9250\n",
            "Epoch 372/700\n",
            "120/120 [==============================] - 0s 152us/step - loss: 0.2814 - acc: 0.9167\n",
            "Epoch 373/700\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2807 - acc: 0.9167\n",
            "Epoch 374/700\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2801 - acc: 0.9167\n",
            "Epoch 375/700\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2794 - acc: 0.9167\n",
            "Epoch 376/700\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.2787 - acc: 0.9167\n",
            "Epoch 377/700\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2776 - acc: 0.9167\n",
            "Epoch 378/700\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2769 - acc: 0.9167\n",
            "Epoch 379/700\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2761 - acc: 0.9167\n",
            "Epoch 380/700\n",
            "120/120 [==============================] - 0s 119us/step - loss: 0.2757 - acc: 0.9167\n",
            "Epoch 381/700\n",
            "120/120 [==============================] - 0s 125us/step - loss: 0.2748 - acc: 0.9167\n",
            "Epoch 382/700\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2740 - acc: 0.9167\n",
            "Epoch 383/700\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2735 - acc: 0.9167\n",
            "Epoch 384/700\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.2729 - acc: 0.9167\n",
            "Epoch 385/700\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2719 - acc: 0.9083\n",
            "Epoch 386/700\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2710 - acc: 0.9083\n",
            "Epoch 387/700\n",
            "120/120 [==============================] - 0s 125us/step - loss: 0.2705 - acc: 0.9083\n",
            "Epoch 388/700\n",
            "120/120 [==============================] - 0s 134us/step - loss: 0.2695 - acc: 0.9083\n",
            "Epoch 389/700\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2688 - acc: 0.9083\n",
            "Epoch 390/700\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.2681 - acc: 0.9083\n",
            "Epoch 391/700\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2673 - acc: 0.9083\n",
            "Epoch 392/700\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.2673 - acc: 0.9083\n",
            "Epoch 393/700\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2666 - acc: 0.9083\n",
            "Epoch 394/700\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2665 - acc: 0.9083\n",
            "Epoch 395/700\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.2649 - acc: 0.9083\n",
            "Epoch 396/700\n",
            "120/120 [==============================] - 0s 121us/step - loss: 0.2644 - acc: 0.9083\n",
            "Epoch 397/700\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2639 - acc: 0.9083\n",
            "Epoch 398/700\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2633 - acc: 0.9083\n",
            "Epoch 399/700\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2627 - acc: 0.9083\n",
            "Epoch 400/700\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2620 - acc: 0.9083\n",
            "Epoch 401/700\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2621 - acc: 0.9083\n",
            "Epoch 402/700\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.2611 - acc: 0.9083\n",
            "Epoch 403/700\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.2606 - acc: 0.9083\n",
            "Epoch 404/700\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2608 - acc: 0.9083\n",
            "Epoch 405/700\n",
            "120/120 [==============================] - 0s 117us/step - loss: 0.2606 - acc: 0.9083\n",
            "Epoch 406/700\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2595 - acc: 0.9083\n",
            "Epoch 407/700\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2584 - acc: 0.9083\n",
            "Epoch 408/700\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2577 - acc: 0.9083\n",
            "Epoch 409/700\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2573 - acc: 0.9083\n",
            "Epoch 410/700\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2566 - acc: 0.9083\n",
            "Epoch 411/700\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2560 - acc: 0.9083\n",
            "Epoch 412/700\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2556 - acc: 0.9083\n",
            "Epoch 413/700\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2555 - acc: 0.9083\n",
            "Epoch 414/700\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2554 - acc: 0.9083\n",
            "Epoch 415/700\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2552 - acc: 0.9083\n",
            "Epoch 416/700\n",
            "120/120 [==============================] - 0s 117us/step - loss: 0.2536 - acc: 0.9083\n",
            "Epoch 417/700\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2538 - acc: 0.9083\n",
            "Epoch 418/700\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.2538 - acc: 0.9083\n",
            "Epoch 419/700\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2533 - acc: 0.9083\n",
            "Epoch 420/700\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.2523 - acc: 0.9167\n",
            "Epoch 421/700\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2512 - acc: 0.9083\n",
            "Epoch 422/700\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2507 - acc: 0.9083\n",
            "Epoch 423/700\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2503 - acc: 0.9083\n",
            "Epoch 424/700\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2502 - acc: 0.9083\n",
            "Epoch 425/700\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2499 - acc: 0.9083\n",
            "Epoch 426/700\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2492 - acc: 0.9083\n",
            "Epoch 427/700\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2485 - acc: 0.9083\n",
            "Epoch 428/700\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.2481 - acc: 0.9083\n",
            "Epoch 429/700\n",
            "120/120 [==============================] - 0s 120us/step - loss: 0.2477 - acc: 0.9083\n",
            "Epoch 430/700\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2474 - acc: 0.9167\n",
            "Epoch 431/700\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2469 - acc: 0.9083\n",
            "Epoch 432/700\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2463 - acc: 0.9083\n",
            "Epoch 433/700\n",
            "120/120 [==============================] - 0s 120us/step - loss: 0.2460 - acc: 0.9083\n",
            "Epoch 434/700\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2461 - acc: 0.9083\n",
            "Epoch 435/700\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2451 - acc: 0.9083\n",
            "Epoch 436/700\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2449 - acc: 0.9083\n",
            "Epoch 437/700\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.2444 - acc: 0.9083\n",
            "Epoch 438/700\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2442 - acc: 0.9083\n",
            "Epoch 439/700\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2439 - acc: 0.9083\n",
            "Epoch 440/700\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.2434 - acc: 0.9083\n",
            "Epoch 441/700\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.2429 - acc: 0.9083\n",
            "Epoch 442/700\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2421 - acc: 0.9083\n",
            "Epoch 443/700\n",
            "120/120 [==============================] - 0s 136us/step - loss: 0.2417 - acc: 0.9083\n",
            "Epoch 444/700\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2414 - acc: 0.9083\n",
            "Epoch 445/700\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2410 - acc: 0.9083\n",
            "Epoch 446/700\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2408 - acc: 0.9083\n",
            "Epoch 447/700\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2404 - acc: 0.9083\n",
            "Epoch 448/700\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2400 - acc: 0.9083\n",
            "Epoch 449/700\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2397 - acc: 0.9083\n",
            "Epoch 450/700\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.2394 - acc: 0.9083\n",
            "Epoch 451/700\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2391 - acc: 0.9083\n",
            "Epoch 452/700\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.2389 - acc: 0.9083\n",
            "Epoch 453/700\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2383 - acc: 0.9083\n",
            "Epoch 454/700\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2378 - acc: 0.9083\n",
            "Epoch 455/700\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2375 - acc: 0.9083\n",
            "Epoch 456/700\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2372 - acc: 0.9083\n",
            "Epoch 457/700\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2369 - acc: 0.9083\n",
            "Epoch 458/700\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2365 - acc: 0.9083\n",
            "Epoch 459/700\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.2364 - acc: 0.9083\n",
            "Epoch 460/700\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.2361 - acc: 0.9167\n",
            "Epoch 461/700\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2360 - acc: 0.9167\n",
            "Epoch 462/700\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2359 - acc: 0.9083\n",
            "Epoch 463/700\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2352 - acc: 0.9167\n",
            "Epoch 464/700\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2347 - acc: 0.9167\n",
            "Epoch 465/700\n",
            "120/120 [==============================] - 0s 145us/step - loss: 0.2342 - acc: 0.9083\n",
            "Epoch 466/700\n",
            "120/120 [==============================] - 0s 152us/step - loss: 0.2338 - acc: 0.9083\n",
            "Epoch 467/700\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2338 - acc: 0.9083\n",
            "Epoch 468/700\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.2335 - acc: 0.9167\n",
            "Epoch 469/700\n",
            "120/120 [==============================] - 0s 119us/step - loss: 0.2344 - acc: 0.9083\n",
            "Epoch 470/700\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2337 - acc: 0.9083\n",
            "Epoch 471/700\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2333 - acc: 0.9083\n",
            "Epoch 472/700\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2333 - acc: 0.9250\n",
            "Epoch 473/700\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2334 - acc: 0.9250\n",
            "Epoch 474/700\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2325 - acc: 0.9250\n",
            "Epoch 475/700\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2319 - acc: 0.9250\n",
            "Epoch 476/700\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.2315 - acc: 0.9083\n",
            "Epoch 477/700\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2313 - acc: 0.9083\n",
            "Epoch 478/700\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2307 - acc: 0.9083\n",
            "Epoch 479/700\n",
            "120/120 [==============================] - 0s 73us/step - loss: 0.2304 - acc: 0.9083\n",
            "Epoch 480/700\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2300 - acc: 0.9083\n",
            "Epoch 481/700\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2298 - acc: 0.9083\n",
            "Epoch 482/700\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2295 - acc: 0.9083\n",
            "Epoch 483/700\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2292 - acc: 0.9083\n",
            "Epoch 484/700\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2291 - acc: 0.9083\n",
            "Epoch 485/700\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2288 - acc: 0.9083\n",
            "Epoch 486/700\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.2288 - acc: 0.9167\n",
            "Epoch 487/700\n",
            "120/120 [==============================] - 0s 117us/step - loss: 0.2282 - acc: 0.9083\n",
            "Epoch 488/700\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2281 - acc: 0.9167\n",
            "Epoch 489/700\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2283 - acc: 0.9250\n",
            "Epoch 490/700\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2283 - acc: 0.9250\n",
            "Epoch 491/700\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2277 - acc: 0.9167\n",
            "Epoch 492/700\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2273 - acc: 0.9167\n",
            "Epoch 493/700\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2271 - acc: 0.9167\n",
            "Epoch 494/700\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2266 - acc: 0.9083\n",
            "Epoch 495/700\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2263 - acc: 0.9083\n",
            "Epoch 496/700\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.2261 - acc: 0.9083\n",
            "Epoch 497/700\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.2259 - acc: 0.9083\n",
            "Epoch 498/700\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2256 - acc: 0.9083\n",
            "Epoch 499/700\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.2253 - acc: 0.9167\n",
            "Epoch 500/700\n",
            "120/120 [==============================] - 0s 73us/step - loss: 0.2252 - acc: 0.9083\n",
            "Epoch 501/700\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2250 - acc: 0.9250\n",
            "Epoch 502/700\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2249 - acc: 0.9250\n",
            "Epoch 503/700\n",
            "120/120 [==============================] - 0s 119us/step - loss: 0.2249 - acc: 0.9250\n",
            "Epoch 504/700\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2245 - acc: 0.9333\n",
            "Epoch 505/700\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.2239 - acc: 0.9250\n",
            "Epoch 506/700\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2236 - acc: 0.9083\n",
            "Epoch 507/700\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2235 - acc: 0.9083\n",
            "Epoch 508/700\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2232 - acc: 0.9083\n",
            "Epoch 509/700\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2231 - acc: 0.9167\n",
            "Epoch 510/700\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2230 - acc: 0.9167\n",
            "Epoch 511/700\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.2226 - acc: 0.9083\n",
            "Epoch 512/700\n",
            "120/120 [==============================] - 0s 77us/step - loss: 0.2224 - acc: 0.9083\n",
            "Epoch 513/700\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2222 - acc: 0.9083\n",
            "Epoch 514/700\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.2221 - acc: 0.9083\n",
            "Epoch 515/700\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2218 - acc: 0.9083\n",
            "Epoch 516/700\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.2216 - acc: 0.9083\n",
            "Epoch 517/700\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.2216 - acc: 0.9083\n",
            "Epoch 518/700\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2217 - acc: 0.9083\n",
            "Epoch 519/700\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2216 - acc: 0.9083\n",
            "Epoch 520/700\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2214 - acc: 0.9083\n",
            "Epoch 521/700\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2214 - acc: 0.9083\n",
            "Epoch 522/700\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2207 - acc: 0.9083\n",
            "Epoch 523/700\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2210 - acc: 0.9083\n",
            "Epoch 524/700\n",
            "120/120 [==============================] - 0s 145us/step - loss: 0.2204 - acc: 0.9167\n",
            "Epoch 525/700\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2203 - acc: 0.9083\n",
            "Epoch 526/700\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2206 - acc: 0.9167\n",
            "Epoch 527/700\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2198 - acc: 0.9083\n",
            "Epoch 528/700\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2197 - acc: 0.9083\n",
            "Epoch 529/700\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2196 - acc: 0.9083\n",
            "Epoch 530/700\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2194 - acc: 0.9083\n",
            "Epoch 531/700\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2190 - acc: 0.9083\n",
            "Epoch 532/700\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2192 - acc: 0.9083\n",
            "Epoch 533/700\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2195 - acc: 0.9167\n",
            "Epoch 534/700\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2198 - acc: 0.9083\n",
            "Epoch 535/700\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2183 - acc: 0.9167\n",
            "Epoch 536/700\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2181 - acc: 0.9083\n",
            "Epoch 537/700\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2180 - acc: 0.9083\n",
            "Epoch 538/700\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2178 - acc: 0.9167\n",
            "Epoch 539/700\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2176 - acc: 0.9083\n",
            "Epoch 540/700\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2179 - acc: 0.9083\n",
            "Epoch 541/700\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2181 - acc: 0.9167\n",
            "Epoch 542/700\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.2175 - acc: 0.9167\n",
            "Epoch 543/700\n",
            "120/120 [==============================] - 0s 152us/step - loss: 0.2169 - acc: 0.9083\n",
            "Epoch 544/700\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.2170 - acc: 0.9083\n",
            "Epoch 545/700\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2170 - acc: 0.9167\n",
            "Epoch 546/700\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.2168 - acc: 0.9167\n",
            "Epoch 547/700\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.2164 - acc: 0.9250\n",
            "Epoch 548/700\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2162 - acc: 0.9167\n",
            "Epoch 549/700\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2161 - acc: 0.9167\n",
            "Epoch 550/700\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2158 - acc: 0.9167\n",
            "Epoch 551/700\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2157 - acc: 0.9250\n",
            "Epoch 552/700\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2157 - acc: 0.9250\n",
            "Epoch 553/700\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2153 - acc: 0.9167\n",
            "Epoch 554/700\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2151 - acc: 0.9167\n",
            "Epoch 555/700\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2151 - acc: 0.9167\n",
            "Epoch 556/700\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2152 - acc: 0.9167\n",
            "Epoch 557/700\n",
            "120/120 [==============================] - 0s 115us/step - loss: 0.2151 - acc: 0.9167\n",
            "Epoch 558/700\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.2149 - acc: 0.9167\n",
            "Epoch 559/700\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.2148 - acc: 0.9167\n",
            "Epoch 560/700\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2144 - acc: 0.9250\n",
            "Epoch 561/700\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2144 - acc: 0.9250\n",
            "Epoch 562/700\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2145 - acc: 0.9167\n",
            "Epoch 563/700\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2147 - acc: 0.9167\n",
            "Epoch 564/700\n",
            "120/120 [==============================] - 0s 76us/step - loss: 0.2141 - acc: 0.9083\n",
            "Epoch 565/700\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.2143 - acc: 0.9083\n",
            "Epoch 566/700\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2138 - acc: 0.9083\n",
            "Epoch 567/700\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2138 - acc: 0.9083\n",
            "Epoch 568/700\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2134 - acc: 0.9083\n",
            "Epoch 569/700\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2133 - acc: 0.9083\n",
            "Epoch 570/700\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2131 - acc: 0.9250\n",
            "Epoch 571/700\n",
            "120/120 [==============================] - 0s 140us/step - loss: 0.2145 - acc: 0.9167\n",
            "Epoch 572/700\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.2152 - acc: 0.9083\n",
            "Epoch 573/700\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2132 - acc: 0.9167\n",
            "Epoch 574/700\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.2132 - acc: 0.9167\n",
            "Epoch 575/700\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.2136 - acc: 0.9083\n",
            "Epoch 576/700\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2129 - acc: 0.9167\n",
            "Epoch 577/700\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2128 - acc: 0.9250\n",
            "Epoch 578/700\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2125 - acc: 0.9167\n",
            "Epoch 579/700\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2121 - acc: 0.9083\n",
            "Epoch 580/700\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2121 - acc: 0.9167\n",
            "Epoch 581/700\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.2120 - acc: 0.9167\n",
            "Epoch 582/700\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2112 - acc: 0.9167\n",
            "Epoch 583/700\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2114 - acc: 0.9250\n",
            "Epoch 584/700\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2115 - acc: 0.9167\n",
            "Epoch 585/700\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2117 - acc: 0.9167\n",
            "Epoch 586/700\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2114 - acc: 0.9167\n",
            "Epoch 587/700\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2110 - acc: 0.9167\n",
            "Epoch 588/700\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2112 - acc: 0.9167\n",
            "Epoch 589/700\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2105 - acc: 0.9167\n",
            "Epoch 590/700\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2104 - acc: 0.9167\n",
            "Epoch 591/700\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2103 - acc: 0.9167\n",
            "Epoch 592/700\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2101 - acc: 0.9167\n",
            "Epoch 593/700\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2101 - acc: 0.9250\n",
            "Epoch 594/700\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2102 - acc: 0.9250\n",
            "Epoch 595/700\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2102 - acc: 0.9250\n",
            "Epoch 596/700\n",
            "120/120 [==============================] - 0s 137us/step - loss: 0.2098 - acc: 0.9250\n",
            "Epoch 597/700\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.2097 - acc: 0.9333\n",
            "Epoch 598/700\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.2098 - acc: 0.9333\n",
            "Epoch 599/700\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2095 - acc: 0.9333\n",
            "Epoch 600/700\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2097 - acc: 0.9333\n",
            "Epoch 601/700\n",
            "120/120 [==============================] - 0s 75us/step - loss: 0.2092 - acc: 0.9250\n",
            "Epoch 602/700\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2092 - acc: 0.9167\n",
            "Epoch 603/700\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2090 - acc: 0.9250\n",
            "Epoch 604/700\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2086 - acc: 0.9333\n",
            "Epoch 605/700\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2084 - acc: 0.9333\n",
            "Epoch 606/700\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2083 - acc: 0.9333\n",
            "Epoch 607/700\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2084 - acc: 0.9250\n",
            "Epoch 608/700\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2084 - acc: 0.9333\n",
            "Epoch 609/700\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2082 - acc: 0.9250\n",
            "Epoch 610/700\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2079 - acc: 0.9250\n",
            "Epoch 611/700\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2077 - acc: 0.9250\n",
            "Epoch 612/700\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2076 - acc: 0.9250\n",
            "Epoch 613/700\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2074 - acc: 0.9250\n",
            "Epoch 614/700\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2073 - acc: 0.9250\n",
            "Epoch 615/700\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2077 - acc: 0.9250\n",
            "Epoch 616/700\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.2077 - acc: 0.9167\n",
            "Epoch 617/700\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.2074 - acc: 0.9167\n",
            "Epoch 618/700\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2071 - acc: 0.9167\n",
            "Epoch 619/700\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2073 - acc: 0.9167\n",
            "Epoch 620/700\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2068 - acc: 0.9167\n",
            "Epoch 621/700\n",
            "120/120 [==============================] - 0s 146us/step - loss: 0.2068 - acc: 0.9167\n",
            "Epoch 622/700\n",
            "120/120 [==============================] - 0s 123us/step - loss: 0.2064 - acc: 0.9250\n",
            "Epoch 623/700\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2065 - acc: 0.9250\n",
            "Epoch 624/700\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2070 - acc: 0.9250\n",
            "Epoch 625/700\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2068 - acc: 0.9167\n",
            "Epoch 626/700\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2065 - acc: 0.9167\n",
            "Epoch 627/700\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.2064 - acc: 0.9167\n",
            "Epoch 628/700\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2063 - acc: 0.9250\n",
            "Epoch 629/700\n",
            "120/120 [==============================] - 0s 157us/step - loss: 0.2063 - acc: 0.9167\n",
            "Epoch 630/700\n",
            "120/120 [==============================] - 0s 134us/step - loss: 0.2059 - acc: 0.9250\n",
            "Epoch 631/700\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2058 - acc: 0.9250\n",
            "Epoch 632/700\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2058 - acc: 0.9250\n",
            "Epoch 633/700\n",
            "120/120 [==============================] - 0s 75us/step - loss: 0.2057 - acc: 0.9250\n",
            "Epoch 634/700\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2059 - acc: 0.9167\n",
            "Epoch 635/700\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.2056 - acc: 0.9167\n",
            "Epoch 636/700\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.2054 - acc: 0.9250\n",
            "Epoch 637/700\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2051 - acc: 0.9250\n",
            "Epoch 638/700\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2052 - acc: 0.9250\n",
            "Epoch 639/700\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2053 - acc: 0.9250\n",
            "Epoch 640/700\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2053 - acc: 0.9250\n",
            "Epoch 641/700\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2052 - acc: 0.9250\n",
            "Epoch 642/700\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2056 - acc: 0.9250\n",
            "Epoch 643/700\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.2057 - acc: 0.9333\n",
            "Epoch 644/700\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2055 - acc: 0.9333\n",
            "Epoch 645/700\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.2044 - acc: 0.9333\n",
            "Epoch 646/700\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2046 - acc: 0.9333\n",
            "Epoch 647/700\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2048 - acc: 0.9333\n",
            "Epoch 648/700\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2045 - acc: 0.9333\n",
            "Epoch 649/700\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2041 - acc: 0.9250\n",
            "Epoch 650/700\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.2046 - acc: 0.9250\n",
            "Epoch 651/700\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2041 - acc: 0.9250\n",
            "Epoch 652/700\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2044 - acc: 0.9250\n",
            "Epoch 653/700\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2042 - acc: 0.9250\n",
            "Epoch 654/700\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2035 - acc: 0.9250\n",
            "Epoch 655/700\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2037 - acc: 0.9250\n",
            "Epoch 656/700\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2037 - acc: 0.9167\n",
            "Epoch 657/700\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2036 - acc: 0.9167\n",
            "Epoch 658/700\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2033 - acc: 0.9250\n",
            "Epoch 659/700\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.2033 - acc: 0.9250\n",
            "Epoch 660/700\n",
            "120/120 [==============================] - 0s 117us/step - loss: 0.2031 - acc: 0.9250\n",
            "Epoch 661/700\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2034 - acc: 0.9167\n",
            "Epoch 662/700\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.2030 - acc: 0.9250\n",
            "Epoch 663/700\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2032 - acc: 0.9250\n",
            "Epoch 664/700\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2027 - acc: 0.9167\n",
            "Epoch 665/700\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2036 - acc: 0.9250\n",
            "Epoch 666/700\n",
            "120/120 [==============================] - 0s 120us/step - loss: 0.2041 - acc: 0.9083\n",
            "Epoch 667/700\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2030 - acc: 0.9167\n",
            "Epoch 668/700\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2030 - acc: 0.9250\n",
            "Epoch 669/700\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2032 - acc: 0.9167\n",
            "Epoch 670/700\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.2023 - acc: 0.9250\n",
            "Epoch 671/700\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.2024 - acc: 0.9250\n",
            "Epoch 672/700\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2035 - acc: 0.9250\n",
            "Epoch 673/700\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.2041 - acc: 0.9167\n",
            "Epoch 674/700\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2024 - acc: 0.9250\n",
            "Epoch 675/700\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2019 - acc: 0.9333\n",
            "Epoch 676/700\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2019 - acc: 0.9167\n",
            "Epoch 677/700\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2016 - acc: 0.9250\n",
            "Epoch 678/700\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2028 - acc: 0.9250\n",
            "Epoch 679/700\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.2037 - acc: 0.9167\n",
            "Epoch 680/700\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2041 - acc: 0.9167\n",
            "Epoch 681/700\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2027 - acc: 0.9167\n",
            "Epoch 682/700\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2019 - acc: 0.9250\n",
            "Epoch 683/700\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2018 - acc: 0.9167\n",
            "Epoch 684/700\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2018 - acc: 0.9167\n",
            "Epoch 685/700\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2012 - acc: 0.9250\n",
            "Epoch 686/700\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2013 - acc: 0.9167\n",
            "Epoch 687/700\n",
            "120/120 [==============================] - 0s 71us/step - loss: 0.2015 - acc: 0.9167\n",
            "Epoch 688/700\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2016 - acc: 0.9250\n",
            "Epoch 689/700\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2031 - acc: 0.9250\n",
            "Epoch 690/700\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2052 - acc: 0.9083\n",
            "Epoch 691/700\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2055 - acc: 0.9083\n",
            "Epoch 692/700\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2034 - acc: 0.9167\n",
            "Epoch 693/700\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2013 - acc: 0.9167\n",
            "Epoch 694/700\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2012 - acc: 0.9250\n",
            "Epoch 695/700\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2016 - acc: 0.9167\n",
            "Epoch 696/700\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2011 - acc: 0.9250\n",
            "Epoch 697/700\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2012 - acc: 0.9167\n",
            "Epoch 698/700\n",
            "120/120 [==============================] - 0s 136us/step - loss: 0.2002 - acc: 0.9333\n",
            "Epoch 699/700\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2003 - acc: 0.9333\n",
            "Epoch 700/700\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2005 - acc: 0.9333\n",
            "60/60 [==============================] - 1s 10ms/step\n",
            "\n",
            "acc: 85.00%\n",
            "[[18  3  2]\n",
            " [ 3 22  0]\n",
            " [ 0  1 11]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82        23\n",
            "           1       0.85      0.88      0.86        25\n",
            "           2       0.85      0.92      0.88        12\n",
            "\n",
            "    accuracy                           0.85        60\n",
            "   macro avg       0.85      0.86      0.85        60\n",
            "weighted avg       0.85      0.85      0.85        60\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_164 (Dense)            (None, 10)                30        \n",
            "_________________________________________________________________\n",
            "dense_165 (Dense)            (None, 20)                220       \n",
            "_________________________________________________________________\n",
            "dense_166 (Dense)            (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_167 (Dense)            (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_168 (Dense)            (None, 3)                 63        \n",
            "=================================================================\n",
            "Total params: 1,153\n",
            "Trainable params: 1,153\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/800\n",
            "120/120 [==============================] - 2s 13ms/step - loss: 1.0817 - acc: 0.3333\n",
            "Epoch 2/800\n",
            "120/120 [==============================] - 0s 113us/step - loss: 1.0749 - acc: 0.3333\n",
            "Epoch 3/800\n",
            "120/120 [==============================] - 0s 85us/step - loss: 1.0680 - acc: 0.3333\n",
            "Epoch 4/800\n",
            "120/120 [==============================] - 0s 94us/step - loss: 1.0614 - acc: 0.3333\n",
            "Epoch 5/800\n",
            "120/120 [==============================] - 0s 80us/step - loss: 1.0566 - acc: 0.3333\n",
            "Epoch 6/800\n",
            "120/120 [==============================] - 0s 82us/step - loss: 1.0521 - acc: 0.3333\n",
            "Epoch 7/800\n",
            "120/120 [==============================] - 0s 88us/step - loss: 1.0473 - acc: 0.3417\n",
            "Epoch 8/800\n",
            "120/120 [==============================] - 0s 94us/step - loss: 1.0428 - acc: 0.3333\n",
            "Epoch 9/800\n",
            "120/120 [==============================] - 0s 95us/step - loss: 1.0381 - acc: 0.3500\n",
            "Epoch 10/800\n",
            "120/120 [==============================] - 0s 83us/step - loss: 1.0342 - acc: 0.3583\n",
            "Epoch 11/800\n",
            "120/120 [==============================] - 0s 88us/step - loss: 1.0296 - acc: 0.3500\n",
            "Epoch 12/800\n",
            "120/120 [==============================] - 0s 77us/step - loss: 1.0258 - acc: 0.3583\n",
            "Epoch 13/800\n",
            "120/120 [==============================] - 0s 81us/step - loss: 1.0221 - acc: 0.3583\n",
            "Epoch 14/800\n",
            "120/120 [==============================] - 0s 94us/step - loss: 1.0182 - acc: 0.3667\n",
            "Epoch 15/800\n",
            "120/120 [==============================] - 0s 98us/step - loss: 1.0144 - acc: 0.3750\n",
            "Epoch 16/800\n",
            "120/120 [==============================] - 0s 90us/step - loss: 1.0106 - acc: 0.3750\n",
            "Epoch 17/800\n",
            "120/120 [==============================] - 0s 78us/step - loss: 1.0068 - acc: 0.3750\n",
            "Epoch 18/800\n",
            "120/120 [==============================] - 0s 86us/step - loss: 1.0032 - acc: 0.3750\n",
            "Epoch 19/800\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.9999 - acc: 0.3833\n",
            "Epoch 20/800\n",
            "120/120 [==============================] - 0s 115us/step - loss: 0.9968 - acc: 0.3917\n",
            "Epoch 21/800\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.9936 - acc: 0.3917\n",
            "Epoch 22/800\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.9907 - acc: 0.4167\n",
            "Epoch 23/800\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.9878 - acc: 0.4500\n",
            "Epoch 24/800\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.9847 - acc: 0.4750\n",
            "Epoch 25/800\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.9817 - acc: 0.5000\n",
            "Epoch 26/800\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.9790 - acc: 0.6000\n",
            "Epoch 27/800\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.9765 - acc: 0.6417\n",
            "Epoch 28/800\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.9735 - acc: 0.6583\n",
            "Epoch 29/800\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.9706 - acc: 0.6583\n",
            "Epoch 30/800\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.9675 - acc: 0.6750\n",
            "Epoch 31/800\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.9645 - acc: 0.7083\n",
            "Epoch 32/800\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.9614 - acc: 0.7083\n",
            "Epoch 33/800\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.9585 - acc: 0.7167\n",
            "Epoch 34/800\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.9556 - acc: 0.7417\n",
            "Epoch 35/800\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.9523 - acc: 0.7333\n",
            "Epoch 36/800\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.9493 - acc: 0.7333\n",
            "Epoch 37/800\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.9461 - acc: 0.7333\n",
            "Epoch 38/800\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.9431 - acc: 0.7333\n",
            "Epoch 39/800\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.9400 - acc: 0.7333\n",
            "Epoch 40/800\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.9366 - acc: 0.7417\n",
            "Epoch 41/800\n",
            "120/120 [==============================] - 0s 72us/step - loss: 0.9335 - acc: 0.7500\n",
            "Epoch 42/800\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.9305 - acc: 0.7500\n",
            "Epoch 43/800\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.9274 - acc: 0.7417\n",
            "Epoch 44/800\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.9242 - acc: 0.7500\n",
            "Epoch 45/800\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.9209 - acc: 0.7417\n",
            "Epoch 46/800\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.9175 - acc: 0.7500\n",
            "Epoch 47/800\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.9146 - acc: 0.7750\n",
            "Epoch 48/800\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.9111 - acc: 0.7583\n",
            "Epoch 49/800\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.9082 - acc: 0.8083\n",
            "Epoch 50/800\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.9048 - acc: 0.8250\n",
            "Epoch 51/800\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.9013 - acc: 0.8167\n",
            "Epoch 52/800\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.8980 - acc: 0.8167\n",
            "Epoch 53/800\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.8947 - acc: 0.8250\n",
            "Epoch 54/800\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.8910 - acc: 0.8250\n",
            "Epoch 55/800\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.8874 - acc: 0.8250\n",
            "Epoch 56/800\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.8837 - acc: 0.8250\n",
            "Epoch 57/800\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.8802 - acc: 0.8250\n",
            "Epoch 58/800\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.8766 - acc: 0.8250\n",
            "Epoch 59/800\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.8730 - acc: 0.8250\n",
            "Epoch 60/800\n",
            "120/120 [==============================] - 0s 119us/step - loss: 0.8693 - acc: 0.8333\n",
            "Epoch 61/800\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.8658 - acc: 0.8333\n",
            "Epoch 62/800\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.8622 - acc: 0.8250\n",
            "Epoch 63/800\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.8584 - acc: 0.8250\n",
            "Epoch 64/800\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.8552 - acc: 0.8333\n",
            "Epoch 65/800\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.8511 - acc: 0.8333\n",
            "Epoch 66/800\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.8472 - acc: 0.8333\n",
            "Epoch 67/800\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.8431 - acc: 0.8333\n",
            "Epoch 68/800\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.8390 - acc: 0.8333\n",
            "Epoch 69/800\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.8349 - acc: 0.8333\n",
            "Epoch 70/800\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.8309 - acc: 0.8333\n",
            "Epoch 71/800\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.8273 - acc: 0.8333\n",
            "Epoch 72/800\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.8236 - acc: 0.8333\n",
            "Epoch 73/800\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.8194 - acc: 0.8333\n",
            "Epoch 74/800\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.8156 - acc: 0.8333\n",
            "Epoch 75/800\n",
            "120/120 [==============================] - 0s 139us/step - loss: 0.8110 - acc: 0.8333\n",
            "Epoch 76/800\n",
            "120/120 [==============================] - 0s 127us/step - loss: 0.8065 - acc: 0.8333\n",
            "Epoch 77/800\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.8023 - acc: 0.8417\n",
            "Epoch 78/800\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.7983 - acc: 0.8417\n",
            "Epoch 79/800\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.7945 - acc: 0.8417\n",
            "Epoch 80/800\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.7901 - acc: 0.8417\n",
            "Epoch 81/800\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.7862 - acc: 0.8417\n",
            "Epoch 82/800\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.7823 - acc: 0.8417\n",
            "Epoch 83/800\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.7779 - acc: 0.8417\n",
            "Epoch 84/800\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.7735 - acc: 0.8500\n",
            "Epoch 85/800\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.7694 - acc: 0.8500\n",
            "Epoch 86/800\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.7652 - acc: 0.8500\n",
            "Epoch 87/800\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.7610 - acc: 0.8500\n",
            "Epoch 88/800\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.7566 - acc: 0.8500\n",
            "Epoch 89/800\n",
            "120/120 [==============================] - 0s 124us/step - loss: 0.7518 - acc: 0.8500\n",
            "Epoch 90/800\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.7475 - acc: 0.8500\n",
            "Epoch 91/800\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.7432 - acc: 0.8583\n",
            "Epoch 92/800\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.7387 - acc: 0.8583\n",
            "Epoch 93/800\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.7341 - acc: 0.8583\n",
            "Epoch 94/800\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.7295 - acc: 0.8583\n",
            "Epoch 95/800\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.7250 - acc: 0.8583\n",
            "Epoch 96/800\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.7201 - acc: 0.8583\n",
            "Epoch 97/800\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.7148 - acc: 0.8583\n",
            "Epoch 98/800\n",
            "120/120 [==============================] - 0s 129us/step - loss: 0.7103 - acc: 0.8583\n",
            "Epoch 99/800\n",
            "120/120 [==============================] - 0s 77us/step - loss: 0.7063 - acc: 0.8583\n",
            "Epoch 100/800\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.7015 - acc: 0.8583\n",
            "Epoch 101/800\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.6971 - acc: 0.8667\n",
            "Epoch 102/800\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.6929 - acc: 0.8667\n",
            "Epoch 103/800\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.6886 - acc: 0.8667\n",
            "Epoch 104/800\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.6842 - acc: 0.8667\n",
            "Epoch 105/800\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.6801 - acc: 0.8667\n",
            "Epoch 106/800\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.6758 - acc: 0.8667\n",
            "Epoch 107/800\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.6710 - acc: 0.8667\n",
            "Epoch 108/800\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.6673 - acc: 0.8667\n",
            "Epoch 109/800\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.6638 - acc: 0.8667\n",
            "Epoch 110/800\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.6599 - acc: 0.8667\n",
            "Epoch 111/800\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.6558 - acc: 0.8667\n",
            "Epoch 112/800\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.6523 - acc: 0.8667\n",
            "Epoch 113/800\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.6484 - acc: 0.8667\n",
            "Epoch 114/800\n",
            "120/120 [==============================] - 0s 152us/step - loss: 0.6446 - acc: 0.8667\n",
            "Epoch 115/800\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.6411 - acc: 0.8667\n",
            "Epoch 116/800\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.6371 - acc: 0.8667\n",
            "Epoch 117/800\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.6333 - acc: 0.8750\n",
            "Epoch 118/800\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.6297 - acc: 0.8750\n",
            "Epoch 119/800\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.6261 - acc: 0.8750\n",
            "Epoch 120/800\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.6220 - acc: 0.8750\n",
            "Epoch 121/800\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.6186 - acc: 0.8750\n",
            "Epoch 122/800\n",
            "120/120 [==============================] - 0s 75us/step - loss: 0.6151 - acc: 0.8750\n",
            "Epoch 123/800\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.6116 - acc: 0.8833\n",
            "Epoch 124/800\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.6082 - acc: 0.8833\n",
            "Epoch 125/800\n",
            "120/120 [==============================] - 0s 127us/step - loss: 0.6047 - acc: 0.8833\n",
            "Epoch 126/800\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.6013 - acc: 0.8833\n",
            "Epoch 127/800\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.5975 - acc: 0.8833\n",
            "Epoch 128/800\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.5938 - acc: 0.8833\n",
            "Epoch 129/800\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.5905 - acc: 0.8833\n",
            "Epoch 130/800\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.5872 - acc: 0.8833\n",
            "Epoch 131/800\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.5841 - acc: 0.8833\n",
            "Epoch 132/800\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.5811 - acc: 0.8833\n",
            "Epoch 133/800\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.5779 - acc: 0.8833\n",
            "Epoch 134/800\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.5748 - acc: 0.8833\n",
            "Epoch 135/800\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.5719 - acc: 0.8833\n",
            "Epoch 136/800\n",
            "120/120 [==============================] - 0s 152us/step - loss: 0.5686 - acc: 0.8833\n",
            "Epoch 137/800\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.5658 - acc: 0.8833\n",
            "Epoch 138/800\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.5630 - acc: 0.8833\n",
            "Epoch 139/800\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.5599 - acc: 0.8833\n",
            "Epoch 140/800\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.5570 - acc: 0.8833\n",
            "Epoch 141/800\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.5542 - acc: 0.8833\n",
            "Epoch 142/800\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.5514 - acc: 0.8833\n",
            "Epoch 143/800\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.5486 - acc: 0.8833\n",
            "Epoch 144/800\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.5456 - acc: 0.8833\n",
            "Epoch 145/800\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.5429 - acc: 0.8833\n",
            "Epoch 146/800\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.5403 - acc: 0.8833\n",
            "Epoch 147/800\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.5377 - acc: 0.8833\n",
            "Epoch 148/800\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.5351 - acc: 0.8833\n",
            "Epoch 149/800\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.5326 - acc: 0.8833\n",
            "Epoch 150/800\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.5302 - acc: 0.8833\n",
            "Epoch 151/800\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.5278 - acc: 0.8833\n",
            "Epoch 152/800\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.5253 - acc: 0.8833\n",
            "Epoch 153/800\n",
            "120/120 [==============================] - 0s 148us/step - loss: 0.5230 - acc: 0.8833\n",
            "Epoch 154/800\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.5207 - acc: 0.8833\n",
            "Epoch 155/800\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.5186 - acc: 0.8833\n",
            "Epoch 156/800\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.5163 - acc: 0.8833\n",
            "Epoch 157/800\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.5141 - acc: 0.8833\n",
            "Epoch 158/800\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.5118 - acc: 0.8833\n",
            "Epoch 159/800\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.5094 - acc: 0.8833\n",
            "Epoch 160/800\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.5071 - acc: 0.8833\n",
            "Epoch 161/800\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.5051 - acc: 0.8833\n",
            "Epoch 162/800\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.5031 - acc: 0.8833\n",
            "Epoch 163/800\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.5010 - acc: 0.8833\n",
            "Epoch 164/800\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.4986 - acc: 0.8833\n",
            "Epoch 165/800\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.4964 - acc: 0.8833\n",
            "Epoch 166/800\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.4944 - acc: 0.8833\n",
            "Epoch 167/800\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.4924 - acc: 0.8833\n",
            "Epoch 168/800\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.4902 - acc: 0.8833\n",
            "Epoch 169/800\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.4880 - acc: 0.8833\n",
            "Epoch 170/800\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.4860 - acc: 0.8833\n",
            "Epoch 171/800\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.4841 - acc: 0.8833\n",
            "Epoch 172/800\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.4822 - acc: 0.8833\n",
            "Epoch 173/800\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.4803 - acc: 0.8833\n",
            "Epoch 174/800\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.4782 - acc: 0.8833\n",
            "Epoch 175/800\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.4763 - acc: 0.8833\n",
            "Epoch 176/800\n",
            "120/120 [==============================] - 0s 124us/step - loss: 0.4743 - acc: 0.8833\n",
            "Epoch 177/800\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.4724 - acc: 0.8833\n",
            "Epoch 178/800\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.4707 - acc: 0.8833\n",
            "Epoch 179/800\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.4687 - acc: 0.8833\n",
            "Epoch 180/800\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.4667 - acc: 0.8917\n",
            "Epoch 181/800\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.4646 - acc: 0.8917\n",
            "Epoch 182/800\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.4628 - acc: 0.8917\n",
            "Epoch 183/800\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.4610 - acc: 0.8917\n",
            "Epoch 184/800\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.4594 - acc: 0.8917\n",
            "Epoch 185/800\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.4576 - acc: 0.8917\n",
            "Epoch 186/800\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.4558 - acc: 0.8917\n",
            "Epoch 187/800\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.4540 - acc: 0.8917\n",
            "Epoch 188/800\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.4523 - acc: 0.8917\n",
            "Epoch 189/800\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.4504 - acc: 0.8917\n",
            "Epoch 190/800\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.4485 - acc: 0.8917\n",
            "Epoch 191/800\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.4469 - acc: 0.8917\n",
            "Epoch 192/800\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.4452 - acc: 0.8917\n",
            "Epoch 193/800\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.4437 - acc: 0.8917\n",
            "Epoch 194/800\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.4420 - acc: 0.8917\n",
            "Epoch 195/800\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.4404 - acc: 0.8917\n",
            "Epoch 196/800\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.4387 - acc: 0.8917\n",
            "Epoch 197/800\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.4373 - acc: 0.8917\n",
            "Epoch 198/800\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.4358 - acc: 0.8917\n",
            "Epoch 199/800\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.4341 - acc: 0.8917\n",
            "Epoch 200/800\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.4326 - acc: 0.8917\n",
            "Epoch 201/800\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.4309 - acc: 0.8917\n",
            "Epoch 202/800\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.4294 - acc: 0.8917\n",
            "Epoch 203/800\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.4280 - acc: 0.8917\n",
            "Epoch 204/800\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.4265 - acc: 0.8917\n",
            "Epoch 205/800\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.4250 - acc: 0.8917\n",
            "Epoch 206/800\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.4236 - acc: 0.8917\n",
            "Epoch 207/800\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.4222 - acc: 0.8917\n",
            "Epoch 208/800\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.4205 - acc: 0.8917\n",
            "Epoch 209/800\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.4188 - acc: 0.8917\n",
            "Epoch 210/800\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.4177 - acc: 0.8917\n",
            "Epoch 211/800\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.4162 - acc: 0.8917\n",
            "Epoch 212/800\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.4145 - acc: 0.8917\n",
            "Epoch 213/800\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.4130 - acc: 0.8917\n",
            "Epoch 214/800\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.4117 - acc: 0.8917\n",
            "Epoch 215/800\n",
            "120/120 [==============================] - 0s 117us/step - loss: 0.4104 - acc: 0.8917\n",
            "Epoch 216/800\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.4090 - acc: 0.8917\n",
            "Epoch 217/800\n",
            "120/120 [==============================] - 0s 127us/step - loss: 0.4076 - acc: 0.8917\n",
            "Epoch 218/800\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.4061 - acc: 0.8917\n",
            "Epoch 219/800\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.4047 - acc: 0.8917\n",
            "Epoch 220/800\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.4038 - acc: 0.8917\n",
            "Epoch 221/800\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.4025 - acc: 0.8917\n",
            "Epoch 222/800\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.4012 - acc: 0.8917\n",
            "Epoch 223/800\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.3999 - acc: 0.8917\n",
            "Epoch 224/800\n",
            "120/120 [==============================] - 0s 117us/step - loss: 0.3985 - acc: 0.8917\n",
            "Epoch 225/800\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.3974 - acc: 0.8917\n",
            "Epoch 226/800\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.3961 - acc: 0.8917\n",
            "Epoch 227/800\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.3946 - acc: 0.8917\n",
            "Epoch 228/800\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.3932 - acc: 0.8917\n",
            "Epoch 229/800\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.3921 - acc: 0.8917\n",
            "Epoch 230/800\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.3909 - acc: 0.8917\n",
            "Epoch 231/800\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.3898 - acc: 0.8917\n",
            "Epoch 232/800\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.3888 - acc: 0.8917\n",
            "Epoch 233/800\n",
            "120/120 [==============================] - 0s 131us/step - loss: 0.3875 - acc: 0.8917\n",
            "Epoch 234/800\n",
            "120/120 [==============================] - 0s 119us/step - loss: 0.3863 - acc: 0.8917\n",
            "Epoch 235/800\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.3853 - acc: 0.8917\n",
            "Epoch 236/800\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.3837 - acc: 0.8917\n",
            "Epoch 237/800\n",
            "120/120 [==============================] - 0s 122us/step - loss: 0.3826 - acc: 0.8917\n",
            "Epoch 238/800\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.3815 - acc: 0.8917\n",
            "Epoch 239/800\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.3803 - acc: 0.8917\n",
            "Epoch 240/800\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.3794 - acc: 0.8917\n",
            "Epoch 241/800\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.3783 - acc: 0.8917\n",
            "Epoch 242/800\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.3770 - acc: 0.8917\n",
            "Epoch 243/800\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.3760 - acc: 0.8917\n",
            "Epoch 244/800\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.3746 - acc: 0.9000\n",
            "Epoch 245/800\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.3735 - acc: 0.9000\n",
            "Epoch 246/800\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.3727 - acc: 0.8917\n",
            "Epoch 247/800\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.3715 - acc: 0.8917\n",
            "Epoch 248/800\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.3705 - acc: 0.8917\n",
            "Epoch 249/800\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.3694 - acc: 0.8917\n",
            "Epoch 250/800\n",
            "120/120 [==============================] - 0s 130us/step - loss: 0.3684 - acc: 0.8917\n",
            "Epoch 251/800\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.3676 - acc: 0.8917\n",
            "Epoch 252/800\n",
            "120/120 [==============================] - 0s 76us/step - loss: 0.3666 - acc: 0.8917\n",
            "Epoch 253/800\n",
            "120/120 [==============================] - 0s 66us/step - loss: 0.3656 - acc: 0.9000\n",
            "Epoch 254/800\n",
            "120/120 [==============================] - 0s 160us/step - loss: 0.3646 - acc: 0.8917\n",
            "Epoch 255/800\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.3635 - acc: 0.9000\n",
            "Epoch 256/800\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.3626 - acc: 0.9000\n",
            "Epoch 257/800\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.3617 - acc: 0.9000\n",
            "Epoch 258/800\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.3609 - acc: 0.9000\n",
            "Epoch 259/800\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.3600 - acc: 0.9000\n",
            "Epoch 260/800\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.3590 - acc: 0.9000\n",
            "Epoch 261/800\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.3581 - acc: 0.9000\n",
            "Epoch 262/800\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.3571 - acc: 0.9000\n",
            "Epoch 263/800\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.3560 - acc: 0.9000\n",
            "Epoch 264/800\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.3544 - acc: 0.9083\n",
            "Epoch 265/800\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.3533 - acc: 0.9083\n",
            "Epoch 266/800\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.3523 - acc: 0.9083\n",
            "Epoch 267/800\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.3515 - acc: 0.9083\n",
            "Epoch 268/800\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.3505 - acc: 0.9083\n",
            "Epoch 269/800\n",
            "120/120 [==============================] - 0s 121us/step - loss: 0.3493 - acc: 0.9083\n",
            "Epoch 270/800\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.3483 - acc: 0.9083\n",
            "Epoch 271/800\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.3474 - acc: 0.9083\n",
            "Epoch 272/800\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.3462 - acc: 0.9083\n",
            "Epoch 273/800\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.3452 - acc: 0.9083\n",
            "Epoch 274/800\n",
            "120/120 [==============================] - 0s 190us/step - loss: 0.3444 - acc: 0.9083\n",
            "Epoch 275/800\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.3433 - acc: 0.9083\n",
            "Epoch 276/800\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.3425 - acc: 0.9083\n",
            "Epoch 277/800\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.3417 - acc: 0.9083\n",
            "Epoch 278/800\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.3407 - acc: 0.9083\n",
            "Epoch 279/800\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.3398 - acc: 0.9167\n",
            "Epoch 280/800\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.3389 - acc: 0.9167\n",
            "Epoch 281/800\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.3379 - acc: 0.9167\n",
            "Epoch 282/800\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.3371 - acc: 0.9167\n",
            "Epoch 283/800\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.3362 - acc: 0.9167\n",
            "Epoch 284/800\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.3354 - acc: 0.9167\n",
            "Epoch 285/800\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.3345 - acc: 0.9167\n",
            "Epoch 286/800\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.3333 - acc: 0.9167\n",
            "Epoch 287/800\n",
            "120/120 [==============================] - 0s 139us/step - loss: 0.3323 - acc: 0.9167\n",
            "Epoch 288/800\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.3313 - acc: 0.9167\n",
            "Epoch 289/800\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.3304 - acc: 0.9167\n",
            "Epoch 290/800\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.3296 - acc: 0.9167\n",
            "Epoch 291/800\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.3286 - acc: 0.9167\n",
            "Epoch 292/800\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.3278 - acc: 0.9167\n",
            "Epoch 293/800\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.3269 - acc: 0.9167\n",
            "Epoch 294/800\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.3261 - acc: 0.9167\n",
            "Epoch 295/800\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.3251 - acc: 0.9167\n",
            "Epoch 296/800\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.3242 - acc: 0.9167\n",
            "Epoch 297/800\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.3236 - acc: 0.9167\n",
            "Epoch 298/800\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.3227 - acc: 0.9167\n",
            "Epoch 299/800\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.3219 - acc: 0.9167\n",
            "Epoch 300/800\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.3210 - acc: 0.9167\n",
            "Epoch 301/800\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.3203 - acc: 0.9167\n",
            "Epoch 302/800\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.3195 - acc: 0.9167\n",
            "Epoch 303/800\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.3189 - acc: 0.9167\n",
            "Epoch 304/800\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.3182 - acc: 0.9167\n",
            "Epoch 305/800\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.3173 - acc: 0.9167\n",
            "Epoch 306/800\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.3168 - acc: 0.9167\n",
            "Epoch 307/800\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.3158 - acc: 0.9167\n",
            "Epoch 308/800\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.3151 - acc: 0.9167\n",
            "Epoch 309/800\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.3145 - acc: 0.9167\n",
            "Epoch 310/800\n",
            "120/120 [==============================] - 0s 149us/step - loss: 0.3139 - acc: 0.9167\n",
            "Epoch 311/800\n",
            "120/120 [==============================] - 0s 169us/step - loss: 0.3131 - acc: 0.9250\n",
            "Epoch 312/800\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.3124 - acc: 0.9250\n",
            "Epoch 313/800\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.3116 - acc: 0.9250\n",
            "Epoch 314/800\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.3109 - acc: 0.9250\n",
            "Epoch 315/800\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.3103 - acc: 0.9250\n",
            "Epoch 316/800\n",
            "120/120 [==============================] - 0s 126us/step - loss: 0.3096 - acc: 0.9250\n",
            "Epoch 317/800\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.3087 - acc: 0.9250\n",
            "Epoch 318/800\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.3079 - acc: 0.9250\n",
            "Epoch 319/800\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.3071 - acc: 0.9250\n",
            "Epoch 320/800\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.3064 - acc: 0.9250\n",
            "Epoch 321/800\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.3058 - acc: 0.9250\n",
            "Epoch 322/800\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.3053 - acc: 0.9250\n",
            "Epoch 323/800\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.3046 - acc: 0.9250\n",
            "Epoch 324/800\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.3040 - acc: 0.9250\n",
            "Epoch 325/800\n",
            "120/120 [==============================] - 0s 115us/step - loss: 0.3032 - acc: 0.9250\n",
            "Epoch 326/800\n",
            "120/120 [==============================] - 0s 77us/step - loss: 0.3026 - acc: 0.9250\n",
            "Epoch 327/800\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.3018 - acc: 0.9250\n",
            "Epoch 328/800\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.3013 - acc: 0.9250\n",
            "Epoch 329/800\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.3008 - acc: 0.9250\n",
            "Epoch 330/800\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.3002 - acc: 0.9250\n",
            "Epoch 331/800\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2996 - acc: 0.9333\n",
            "Epoch 332/800\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2992 - acc: 0.9333\n",
            "Epoch 333/800\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.2989 - acc: 0.9333\n",
            "Epoch 334/800\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2983 - acc: 0.9333\n",
            "Epoch 335/800\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2976 - acc: 0.9333\n",
            "Epoch 336/800\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2972 - acc: 0.9333\n",
            "Epoch 337/800\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2968 - acc: 0.9333\n",
            "Epoch 338/800\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2960 - acc: 0.9333\n",
            "Epoch 339/800\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2952 - acc: 0.9333\n",
            "Epoch 340/800\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2944 - acc: 0.9333\n",
            "Epoch 341/800\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.2936 - acc: 0.9333\n",
            "Epoch 342/800\n",
            "120/120 [==============================] - 0s 115us/step - loss: 0.2930 - acc: 0.9333\n",
            "Epoch 343/800\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2926 - acc: 0.9333\n",
            "Epoch 344/800\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.2921 - acc: 0.9333\n",
            "Epoch 345/800\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2914 - acc: 0.9333\n",
            "Epoch 346/800\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2909 - acc: 0.9333\n",
            "Epoch 347/800\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2902 - acc: 0.9333\n",
            "Epoch 348/800\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2896 - acc: 0.9333\n",
            "Epoch 349/800\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.2892 - acc: 0.9333\n",
            "Epoch 350/800\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2888 - acc: 0.9333\n",
            "Epoch 351/800\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2883 - acc: 0.9333\n",
            "Epoch 352/800\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2877 - acc: 0.9333\n",
            "Epoch 353/800\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.2872 - acc: 0.9333\n",
            "Epoch 354/800\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2865 - acc: 0.9333\n",
            "Epoch 355/800\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2860 - acc: 0.9333\n",
            "Epoch 356/800\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2858 - acc: 0.9333\n",
            "Epoch 357/800\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.2855 - acc: 0.9333\n",
            "Epoch 358/800\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.2851 - acc: 0.9333\n",
            "Epoch 359/800\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2847 - acc: 0.9333\n",
            "Epoch 360/800\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2839 - acc: 0.9250\n",
            "Epoch 361/800\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.2833 - acc: 0.9333\n",
            "Epoch 362/800\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2830 - acc: 0.9333\n",
            "Epoch 363/800\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2827 - acc: 0.9333\n",
            "Epoch 364/800\n",
            "120/120 [==============================] - 0s 154us/step - loss: 0.2820 - acc: 0.9333\n",
            "Epoch 365/800\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2816 - acc: 0.9333\n",
            "Epoch 366/800\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2811 - acc: 0.9333\n",
            "Epoch 367/800\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.2806 - acc: 0.9333\n",
            "Epoch 368/800\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2801 - acc: 0.9333\n",
            "Epoch 369/800\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2796 - acc: 0.9333\n",
            "Epoch 370/800\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2794 - acc: 0.9333\n",
            "Epoch 371/800\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2789 - acc: 0.9333\n",
            "Epoch 372/800\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.2785 - acc: 0.9333\n",
            "Epoch 373/800\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2779 - acc: 0.9333\n",
            "Epoch 374/800\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2774 - acc: 0.9333\n",
            "Epoch 375/800\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2770 - acc: 0.9333\n",
            "Epoch 376/800\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2765 - acc: 0.9333\n",
            "Epoch 377/800\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2760 - acc: 0.9250\n",
            "Epoch 378/800\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.2758 - acc: 0.9333\n",
            "Epoch 379/800\n",
            "120/120 [==============================] - 0s 115us/step - loss: 0.2754 - acc: 0.9333\n",
            "Epoch 380/800\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.2750 - acc: 0.9333\n",
            "Epoch 381/800\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2749 - acc: 0.9333\n",
            "Epoch 382/800\n",
            "120/120 [==============================] - 0s 122us/step - loss: 0.2746 - acc: 0.9333\n",
            "Epoch 383/800\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2743 - acc: 0.9333\n",
            "Epoch 384/800\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2738 - acc: 0.9333\n",
            "Epoch 385/800\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.2733 - acc: 0.9333\n",
            "Epoch 386/800\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2728 - acc: 0.9333\n",
            "Epoch 387/800\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2722 - acc: 0.9333\n",
            "Epoch 388/800\n",
            "120/120 [==============================] - 0s 153us/step - loss: 0.2717 - acc: 0.9333\n",
            "Epoch 389/800\n",
            "120/120 [==============================] - 0s 115us/step - loss: 0.2713 - acc: 0.9333\n",
            "Epoch 390/800\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2711 - acc: 0.9333\n",
            "Epoch 391/800\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2705 - acc: 0.9250\n",
            "Epoch 392/800\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2705 - acc: 0.9250\n",
            "Epoch 393/800\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2701 - acc: 0.9250\n",
            "Epoch 394/800\n",
            "120/120 [==============================] - 0s 75us/step - loss: 0.2696 - acc: 0.9250\n",
            "Epoch 395/800\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2691 - acc: 0.9250\n",
            "Epoch 396/800\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.2688 - acc: 0.9250\n",
            "Epoch 397/800\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2684 - acc: 0.9250\n",
            "Epoch 398/800\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2680 - acc: 0.9250\n",
            "Epoch 399/800\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2676 - acc: 0.9250\n",
            "Epoch 400/800\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2675 - acc: 0.9250\n",
            "Epoch 401/800\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2672 - acc: 0.9333\n",
            "Epoch 402/800\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.2673 - acc: 0.9250\n",
            "Epoch 403/800\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.2668 - acc: 0.9333\n",
            "Epoch 404/800\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2665 - acc: 0.9333\n",
            "Epoch 405/800\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2660 - acc: 0.9333\n",
            "Epoch 406/800\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2656 - acc: 0.9250\n",
            "Epoch 407/800\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2654 - acc: 0.9250\n",
            "Epoch 408/800\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.2651 - acc: 0.9250\n",
            "Epoch 409/800\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2649 - acc: 0.9250\n",
            "Epoch 410/800\n",
            "120/120 [==============================] - 0s 122us/step - loss: 0.2646 - acc: 0.9250\n",
            "Epoch 411/800\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.2644 - acc: 0.9250\n",
            "Epoch 412/800\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2641 - acc: 0.9250\n",
            "Epoch 413/800\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2638 - acc: 0.9250\n",
            "Epoch 414/800\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2635 - acc: 0.9250\n",
            "Epoch 415/800\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2632 - acc: 0.9250\n",
            "Epoch 416/800\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2629 - acc: 0.9250\n",
            "Epoch 417/800\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2625 - acc: 0.9250\n",
            "Epoch 418/800\n",
            "120/120 [==============================] - 0s 73us/step - loss: 0.2622 - acc: 0.9250\n",
            "Epoch 419/800\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2619 - acc: 0.9250\n",
            "Epoch 420/800\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2617 - acc: 0.9250\n",
            "Epoch 421/800\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2614 - acc: 0.9250\n",
            "Epoch 422/800\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2611 - acc: 0.9250\n",
            "Epoch 423/800\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2609 - acc: 0.9250\n",
            "Epoch 424/800\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2605 - acc: 0.9250\n",
            "Epoch 425/800\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2606 - acc: 0.9250\n",
            "Epoch 426/800\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2603 - acc: 0.9250\n",
            "Epoch 427/800\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2600 - acc: 0.9250\n",
            "Epoch 428/800\n",
            "120/120 [==============================] - 0s 75us/step - loss: 0.2597 - acc: 0.9167\n",
            "Epoch 429/800\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2594 - acc: 0.9167\n",
            "Epoch 430/800\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.2590 - acc: 0.9167\n",
            "Epoch 431/800\n",
            "120/120 [==============================] - 0s 115us/step - loss: 0.2589 - acc: 0.9167\n",
            "Epoch 432/800\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2586 - acc: 0.9167\n",
            "Epoch 433/800\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2584 - acc: 0.9167\n",
            "Epoch 434/800\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2583 - acc: 0.9167\n",
            "Epoch 435/800\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2580 - acc: 0.9250\n",
            "Epoch 436/800\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2577 - acc: 0.9250\n",
            "Epoch 437/800\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2575 - acc: 0.9250\n",
            "Epoch 438/800\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2574 - acc: 0.9167\n",
            "Epoch 439/800\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2571 - acc: 0.9250\n",
            "Epoch 440/800\n",
            "120/120 [==============================] - 0s 133us/step - loss: 0.2568 - acc: 0.9250\n",
            "Epoch 441/800\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.2566 - acc: 0.9250\n",
            "Epoch 442/800\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2565 - acc: 0.9250\n",
            "Epoch 443/800\n",
            "120/120 [==============================] - 0s 71us/step - loss: 0.2562 - acc: 0.9250\n",
            "Epoch 444/800\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2559 - acc: 0.9250\n",
            "Epoch 445/800\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2558 - acc: 0.9250\n",
            "Epoch 446/800\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2557 - acc: 0.9250\n",
            "Epoch 447/800\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2554 - acc: 0.9250\n",
            "Epoch 448/800\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2552 - acc: 0.9250\n",
            "Epoch 449/800\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2549 - acc: 0.9250\n",
            "Epoch 450/800\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.2546 - acc: 0.9250\n",
            "Epoch 451/800\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2545 - acc: 0.9250\n",
            "Epoch 452/800\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.2543 - acc: 0.9250\n",
            "Epoch 453/800\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.2544 - acc: 0.9250\n",
            "Epoch 454/800\n",
            "120/120 [==============================] - 0s 128us/step - loss: 0.2539 - acc: 0.9250\n",
            "Epoch 455/800\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2538 - acc: 0.9250\n",
            "Epoch 456/800\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2537 - acc: 0.9250\n",
            "Epoch 457/800\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2535 - acc: 0.9250\n",
            "Epoch 458/800\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2534 - acc: 0.9250\n",
            "Epoch 459/800\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2531 - acc: 0.9250\n",
            "Epoch 460/800\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2528 - acc: 0.9250\n",
            "Epoch 461/800\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2527 - acc: 0.9250\n",
            "Epoch 462/800\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.2527 - acc: 0.9250\n",
            "Epoch 463/800\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2525 - acc: 0.9250\n",
            "Epoch 464/800\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2523 - acc: 0.9250\n",
            "Epoch 465/800\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2521 - acc: 0.9250\n",
            "Epoch 466/800\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2521 - acc: 0.9250\n",
            "Epoch 467/800\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2520 - acc: 0.9250\n",
            "Epoch 468/800\n",
            "120/120 [==============================] - 0s 130us/step - loss: 0.2519 - acc: 0.9250\n",
            "Epoch 469/800\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2516 - acc: 0.9250\n",
            "Epoch 470/800\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2515 - acc: 0.9250\n",
            "Epoch 471/800\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2513 - acc: 0.9250\n",
            "Epoch 472/800\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2512 - acc: 0.9250\n",
            "Epoch 473/800\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2508 - acc: 0.9250\n",
            "Epoch 474/800\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2507 - acc: 0.9250\n",
            "Epoch 475/800\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2504 - acc: 0.9250\n",
            "Epoch 476/800\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2504 - acc: 0.9250\n",
            "Epoch 477/800\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2502 - acc: 0.9250\n",
            "Epoch 478/800\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2502 - acc: 0.9250\n",
            "Epoch 479/800\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2499 - acc: 0.9250\n",
            "Epoch 480/800\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2498 - acc: 0.9250\n",
            "Epoch 481/800\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2497 - acc: 0.9250\n",
            "Epoch 482/800\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.2494 - acc: 0.9250\n",
            "Epoch 483/800\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2496 - acc: 0.9250\n",
            "Epoch 484/800\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2493 - acc: 0.9167\n",
            "Epoch 485/800\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2493 - acc: 0.9167\n",
            "Epoch 486/800\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2491 - acc: 0.9167\n",
            "Epoch 487/800\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2489 - acc: 0.9167\n",
            "Epoch 488/800\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.2486 - acc: 0.9167\n",
            "Epoch 489/800\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2485 - acc: 0.9167\n",
            "Epoch 490/800\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2482 - acc: 0.9167\n",
            "Epoch 491/800\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2481 - acc: 0.9167\n",
            "Epoch 492/800\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2478 - acc: 0.9167\n",
            "Epoch 493/800\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.2480 - acc: 0.9167\n",
            "Epoch 494/800\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.2478 - acc: 0.9167\n",
            "Epoch 495/800\n",
            "120/120 [==============================] - 0s 151us/step - loss: 0.2479 - acc: 0.9167\n",
            "Epoch 496/800\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2481 - acc: 0.9167\n",
            "Epoch 497/800\n",
            "120/120 [==============================] - 0s 69us/step - loss: 0.2475 - acc: 0.9167\n",
            "Epoch 498/800\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2472 - acc: 0.9167\n",
            "Epoch 499/800\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2469 - acc: 0.9167\n",
            "Epoch 500/800\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2468 - acc: 0.9167\n",
            "Epoch 501/800\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2466 - acc: 0.9250\n",
            "Epoch 502/800\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.2466 - acc: 0.9250\n",
            "Epoch 503/800\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2465 - acc: 0.9250\n",
            "Epoch 504/800\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2465 - acc: 0.9250\n",
            "Epoch 505/800\n",
            "120/120 [==============================] - 0s 76us/step - loss: 0.2462 - acc: 0.9167\n",
            "Epoch 506/800\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2461 - acc: 0.9167\n",
            "Epoch 507/800\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2459 - acc: 0.9167\n",
            "Epoch 508/800\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.2462 - acc: 0.9167\n",
            "Epoch 509/800\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.2461 - acc: 0.9167\n",
            "Epoch 510/800\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2459 - acc: 0.9167\n",
            "Epoch 511/800\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2458 - acc: 0.9167\n",
            "Epoch 512/800\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2456 - acc: 0.9250\n",
            "Epoch 513/800\n",
            "120/120 [==============================] - 0s 119us/step - loss: 0.2455 - acc: 0.9250\n",
            "Epoch 514/800\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2457 - acc: 0.9250\n",
            "Epoch 515/800\n",
            "120/120 [==============================] - 0s 134us/step - loss: 0.2455 - acc: 0.9167\n",
            "Epoch 516/800\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2453 - acc: 0.9167\n",
            "Epoch 517/800\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2452 - acc: 0.9167\n",
            "Epoch 518/800\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.2450 - acc: 0.9250\n",
            "Epoch 519/800\n",
            "120/120 [==============================] - 0s 115us/step - loss: 0.2446 - acc: 0.9250\n",
            "Epoch 520/800\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.2448 - acc: 0.9250\n",
            "Epoch 521/800\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2447 - acc: 0.9250\n",
            "Epoch 522/800\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2449 - acc: 0.9250\n",
            "Epoch 523/800\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2449 - acc: 0.9083\n",
            "Epoch 524/800\n",
            "120/120 [==============================] - 0s 120us/step - loss: 0.2445 - acc: 0.9250\n",
            "Epoch 525/800\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2444 - acc: 0.9250\n",
            "Epoch 526/800\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2440 - acc: 0.9250\n",
            "Epoch 527/800\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2442 - acc: 0.9250\n",
            "Epoch 528/800\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2435 - acc: 0.9250\n",
            "Epoch 529/800\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.2435 - acc: 0.9250\n",
            "Epoch 530/800\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2433 - acc: 0.9167\n",
            "Epoch 531/800\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2431 - acc: 0.9167\n",
            "Epoch 532/800\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2430 - acc: 0.9167\n",
            "Epoch 533/800\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2432 - acc: 0.9167\n",
            "Epoch 534/800\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2430 - acc: 0.9167\n",
            "Epoch 535/800\n",
            "120/120 [==============================] - 0s 77us/step - loss: 0.2430 - acc: 0.9250\n",
            "Epoch 536/800\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2430 - acc: 0.9250\n",
            "Epoch 537/800\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2428 - acc: 0.9167\n",
            "Epoch 538/800\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.2425 - acc: 0.9250\n",
            "Epoch 539/800\n",
            "120/120 [==============================] - 0s 134us/step - loss: 0.2423 - acc: 0.9250\n",
            "Epoch 540/800\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2422 - acc: 0.9250\n",
            "Epoch 541/800\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2421 - acc: 0.9250\n",
            "Epoch 542/800\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2420 - acc: 0.9250\n",
            "Epoch 543/800\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2419 - acc: 0.9250\n",
            "Epoch 544/800\n",
            "120/120 [==============================] - 0s 115us/step - loss: 0.2419 - acc: 0.9250\n",
            "Epoch 545/800\n",
            "120/120 [==============================] - 0s 144us/step - loss: 0.2417 - acc: 0.9250\n",
            "Epoch 546/800\n",
            "120/120 [==============================] - 0s 135us/step - loss: 0.2417 - acc: 0.9250\n",
            "Epoch 547/800\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2416 - acc: 0.9250\n",
            "Epoch 548/800\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2415 - acc: 0.9250\n",
            "Epoch 549/800\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2415 - acc: 0.9250\n",
            "Epoch 550/800\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2414 - acc: 0.9250\n",
            "Epoch 551/800\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.2413 - acc: 0.9250\n",
            "Epoch 552/800\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.2414 - acc: 0.9250\n",
            "Epoch 553/800\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2414 - acc: 0.9250\n",
            "Epoch 554/800\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.2415 - acc: 0.9250\n",
            "Epoch 555/800\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2410 - acc: 0.9250\n",
            "Epoch 556/800\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2410 - acc: 0.9250\n",
            "Epoch 557/800\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2409 - acc: 0.9250\n",
            "Epoch 558/800\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2406 - acc: 0.9250\n",
            "Epoch 559/800\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2404 - acc: 0.9250\n",
            "Epoch 560/800\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2404 - acc: 0.9250\n",
            "Epoch 561/800\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2403 - acc: 0.9250\n",
            "Epoch 562/800\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2402 - acc: 0.9250\n",
            "Epoch 563/800\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2403 - acc: 0.9250\n",
            "Epoch 564/800\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2401 - acc: 0.9250\n",
            "Epoch 565/800\n",
            "120/120 [==============================] - 0s 127us/step - loss: 0.2402 - acc: 0.9250\n",
            "Epoch 566/800\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2400 - acc: 0.9250\n",
            "Epoch 567/800\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2399 - acc: 0.9250\n",
            "Epoch 568/800\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2399 - acc: 0.9250\n",
            "Epoch 569/800\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2397 - acc: 0.9250\n",
            "Epoch 570/800\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2398 - acc: 0.9250\n",
            "Epoch 571/800\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2398 - acc: 0.9250\n",
            "Epoch 572/800\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2398 - acc: 0.9250\n",
            "Epoch 573/800\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.2396 - acc: 0.9250\n",
            "Epoch 574/800\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.2395 - acc: 0.9250\n",
            "Epoch 575/800\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2394 - acc: 0.9250\n",
            "Epoch 576/800\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2394 - acc: 0.9250\n",
            "Epoch 577/800\n",
            "120/120 [==============================] - 0s 123us/step - loss: 0.2394 - acc: 0.9250\n",
            "Epoch 578/800\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2393 - acc: 0.9250\n",
            "Epoch 579/800\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2393 - acc: 0.9250\n",
            "Epoch 580/800\n",
            "120/120 [==============================] - 0s 129us/step - loss: 0.2392 - acc: 0.9250\n",
            "Epoch 581/800\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.2393 - acc: 0.9250\n",
            "Epoch 582/800\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.2389 - acc: 0.9250\n",
            "Epoch 583/800\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2389 - acc: 0.9250\n",
            "Epoch 584/800\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2388 - acc: 0.9250\n",
            "Epoch 585/800\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2389 - acc: 0.9250\n",
            "Epoch 586/800\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.2390 - acc: 0.9250\n",
            "Epoch 587/800\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2391 - acc: 0.9250\n",
            "Epoch 588/800\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2387 - acc: 0.9250\n",
            "Epoch 589/800\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2389 - acc: 0.9250\n",
            "Epoch 590/800\n",
            "120/120 [==============================] - 0s 128us/step - loss: 0.2388 - acc: 0.9250\n",
            "Epoch 591/800\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2387 - acc: 0.9250\n",
            "Epoch 592/800\n",
            "120/120 [==============================] - 0s 70us/step - loss: 0.2392 - acc: 0.9250\n",
            "Epoch 593/800\n",
            "120/120 [==============================] - 0s 77us/step - loss: 0.2382 - acc: 0.9250\n",
            "Epoch 594/800\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.2381 - acc: 0.9250\n",
            "Epoch 595/800\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2380 - acc: 0.9250\n",
            "Epoch 596/800\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2380 - acc: 0.9250\n",
            "Epoch 597/800\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.2379 - acc: 0.9250\n",
            "Epoch 598/800\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2379 - acc: 0.9250\n",
            "Epoch 599/800\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2378 - acc: 0.9250\n",
            "Epoch 600/800\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2377 - acc: 0.9250\n",
            "Epoch 601/800\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.2376 - acc: 0.9250\n",
            "Epoch 602/800\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2377 - acc: 0.9250\n",
            "Epoch 603/800\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2376 - acc: 0.9250\n",
            "Epoch 604/800\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2375 - acc: 0.9250\n",
            "Epoch 605/800\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.2375 - acc: 0.9250\n",
            "Epoch 606/800\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2374 - acc: 0.9250\n",
            "Epoch 607/800\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2373 - acc: 0.9250\n",
            "Epoch 608/800\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.2374 - acc: 0.9250\n",
            "Epoch 609/800\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.2374 - acc: 0.9250\n",
            "Epoch 610/800\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.2374 - acc: 0.9250\n",
            "Epoch 611/800\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2374 - acc: 0.9250\n",
            "Epoch 612/800\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2373 - acc: 0.9250\n",
            "Epoch 613/800\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2373 - acc: 0.9250\n",
            "Epoch 614/800\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.2371 - acc: 0.9250\n",
            "Epoch 615/800\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2368 - acc: 0.9250\n",
            "Epoch 616/800\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2368 - acc: 0.9250\n",
            "Epoch 617/800\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2367 - acc: 0.9250\n",
            "Epoch 618/800\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2367 - acc: 0.9250\n",
            "Epoch 619/800\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2369 - acc: 0.9250\n",
            "Epoch 620/800\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.2368 - acc: 0.9250\n",
            "Epoch 621/800\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.2368 - acc: 0.9250\n",
            "Epoch 622/800\n",
            "120/120 [==============================] - 0s 121us/step - loss: 0.2373 - acc: 0.9250\n",
            "Epoch 623/800\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2371 - acc: 0.9250\n",
            "Epoch 624/800\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.2368 - acc: 0.9250\n",
            "Epoch 625/800\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.2364 - acc: 0.9250\n",
            "Epoch 626/800\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2363 - acc: 0.9250\n",
            "Epoch 627/800\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2362 - acc: 0.9250\n",
            "Epoch 628/800\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2361 - acc: 0.9250\n",
            "Epoch 629/800\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2359 - acc: 0.9250\n",
            "Epoch 630/800\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2360 - acc: 0.9250\n",
            "Epoch 631/800\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2361 - acc: 0.9250\n",
            "Epoch 632/800\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.2363 - acc: 0.9250\n",
            "Epoch 633/800\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2359 - acc: 0.9250\n",
            "Epoch 634/800\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2357 - acc: 0.9250\n",
            "Epoch 635/800\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2357 - acc: 0.9250\n",
            "Epoch 636/800\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2357 - acc: 0.9250\n",
            "Epoch 637/800\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2356 - acc: 0.9250\n",
            "Epoch 638/800\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2356 - acc: 0.9250\n",
            "Epoch 639/800\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2355 - acc: 0.9250\n",
            "Epoch 640/800\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2355 - acc: 0.9250\n",
            "Epoch 641/800\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2354 - acc: 0.9250\n",
            "Epoch 642/800\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2353 - acc: 0.9250\n",
            "Epoch 643/800\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2352 - acc: 0.9250\n",
            "Epoch 644/800\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2350 - acc: 0.9250\n",
            "Epoch 645/800\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.2350 - acc: 0.9250\n",
            "Epoch 646/800\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.2349 - acc: 0.9250\n",
            "Epoch 647/800\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2349 - acc: 0.9250\n",
            "Epoch 648/800\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2348 - acc: 0.9250\n",
            "Epoch 649/800\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2347 - acc: 0.9250\n",
            "Epoch 650/800\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2346 - acc: 0.9250\n",
            "Epoch 651/800\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2348 - acc: 0.9250\n",
            "Epoch 652/800\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2349 - acc: 0.9250\n",
            "Epoch 653/800\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2349 - acc: 0.9250\n",
            "Epoch 654/800\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2348 - acc: 0.9250\n",
            "Epoch 655/800\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2347 - acc: 0.9250\n",
            "Epoch 656/800\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.2346 - acc: 0.9250\n",
            "Epoch 657/800\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2345 - acc: 0.9250\n",
            "Epoch 658/800\n",
            "120/120 [==============================] - 0s 152us/step - loss: 0.2342 - acc: 0.9250\n",
            "Epoch 659/800\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2343 - acc: 0.9250\n",
            "Epoch 660/800\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2340 - acc: 0.9250\n",
            "Epoch 661/800\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2340 - acc: 0.9250\n",
            "Epoch 662/800\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2341 - acc: 0.9250\n",
            "Epoch 663/800\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2339 - acc: 0.9250\n",
            "Epoch 664/800\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2338 - acc: 0.9250\n",
            "Epoch 665/800\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2338 - acc: 0.9250\n",
            "Epoch 666/800\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2339 - acc: 0.9250\n",
            "Epoch 667/800\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2336 - acc: 0.9250\n",
            "Epoch 668/800\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2336 - acc: 0.9250\n",
            "Epoch 669/800\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.2335 - acc: 0.9250\n",
            "Epoch 670/800\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2336 - acc: 0.9250\n",
            "Epoch 671/800\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2334 - acc: 0.9250\n",
            "Epoch 672/800\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2333 - acc: 0.9250\n",
            "Epoch 673/800\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2333 - acc: 0.9250\n",
            "Epoch 674/800\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2335 - acc: 0.9250\n",
            "Epoch 675/800\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2332 - acc: 0.9250\n",
            "Epoch 676/800\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2332 - acc: 0.9250\n",
            "Epoch 677/800\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2331 - acc: 0.9250\n",
            "Epoch 678/800\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2330 - acc: 0.9250\n",
            "Epoch 679/800\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2329 - acc: 0.9250\n",
            "Epoch 680/800\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2329 - acc: 0.9250\n",
            "Epoch 681/800\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2329 - acc: 0.9250\n",
            "Epoch 682/800\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2328 - acc: 0.9250\n",
            "Epoch 683/800\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2330 - acc: 0.9250\n",
            "Epoch 684/800\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2328 - acc: 0.9250\n",
            "Epoch 685/800\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2327 - acc: 0.9250\n",
            "Epoch 686/800\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2328 - acc: 0.9250\n",
            "Epoch 687/800\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.2328 - acc: 0.9250\n",
            "Epoch 688/800\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2328 - acc: 0.9250\n",
            "Epoch 689/800\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2326 - acc: 0.9250\n",
            "Epoch 690/800\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2326 - acc: 0.9250\n",
            "Epoch 691/800\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2326 - acc: 0.9250\n",
            "Epoch 692/800\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2325 - acc: 0.9250\n",
            "Epoch 693/800\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2324 - acc: 0.9250\n",
            "Epoch 694/800\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2323 - acc: 0.9250\n",
            "Epoch 695/800\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2324 - acc: 0.9250\n",
            "Epoch 696/800\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.2323 - acc: 0.9250\n",
            "Epoch 697/800\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2323 - acc: 0.9250\n",
            "Epoch 698/800\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2323 - acc: 0.9250\n",
            "Epoch 699/800\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2323 - acc: 0.9250\n",
            "Epoch 700/800\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2323 - acc: 0.9250\n",
            "Epoch 701/800\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2321 - acc: 0.9250\n",
            "Epoch 702/800\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.2322 - acc: 0.9250\n",
            "Epoch 703/800\n",
            "120/120 [==============================] - 0s 141us/step - loss: 0.2321 - acc: 0.9250\n",
            "Epoch 704/800\n",
            "120/120 [==============================] - 0s 150us/step - loss: 0.2321 - acc: 0.9250\n",
            "Epoch 705/800\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2320 - acc: 0.9250\n",
            "Epoch 706/800\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2321 - acc: 0.9250\n",
            "Epoch 707/800\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2319 - acc: 0.9250\n",
            "Epoch 708/800\n",
            "120/120 [==============================] - 0s 135us/step - loss: 0.2319 - acc: 0.9250\n",
            "Epoch 709/800\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2319 - acc: 0.9250\n",
            "Epoch 710/800\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2317 - acc: 0.9250\n",
            "Epoch 711/800\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2318 - acc: 0.9250\n",
            "Epoch 712/800\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2318 - acc: 0.9250\n",
            "Epoch 713/800\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2316 - acc: 0.9250\n",
            "Epoch 714/800\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.2315 - acc: 0.9250\n",
            "Epoch 715/800\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.2315 - acc: 0.9250\n",
            "Epoch 716/800\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2315 - acc: 0.9250\n",
            "Epoch 717/800\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2315 - acc: 0.9250\n",
            "Epoch 718/800\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2314 - acc: 0.9250\n",
            "Epoch 719/800\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2314 - acc: 0.9250\n",
            "Epoch 720/800\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2312 - acc: 0.9250\n",
            "Epoch 721/800\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.2313 - acc: 0.9250\n",
            "Epoch 722/800\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2312 - acc: 0.9250\n",
            "Epoch 723/800\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.2313 - acc: 0.9250\n",
            "Epoch 724/800\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2310 - acc: 0.9250\n",
            "Epoch 725/800\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2310 - acc: 0.9250\n",
            "Epoch 726/800\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.2311 - acc: 0.9250\n",
            "Epoch 727/800\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.2310 - acc: 0.9250\n",
            "Epoch 728/800\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.2311 - acc: 0.9250\n",
            "Epoch 729/800\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2309 - acc: 0.9250\n",
            "Epoch 730/800\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.2309 - acc: 0.9250\n",
            "Epoch 731/800\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2308 - acc: 0.9250\n",
            "Epoch 732/800\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2307 - acc: 0.9250\n",
            "Epoch 733/800\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2306 - acc: 0.9250\n",
            "Epoch 734/800\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2305 - acc: 0.9250\n",
            "Epoch 735/800\n",
            "120/120 [==============================] - 0s 148us/step - loss: 0.2306 - acc: 0.9250\n",
            "Epoch 736/800\n",
            "120/120 [==============================] - 0s 143us/step - loss: 0.2306 - acc: 0.9250\n",
            "Epoch 737/800\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2313 - acc: 0.9250\n",
            "Epoch 738/800\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2313 - acc: 0.9250\n",
            "Epoch 739/800\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2313 - acc: 0.9250\n",
            "Epoch 740/800\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2310 - acc: 0.9250\n",
            "Epoch 741/800\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2308 - acc: 0.9250\n",
            "Epoch 742/800\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2305 - acc: 0.9250\n",
            "Epoch 743/800\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2304 - acc: 0.9250\n",
            "Epoch 744/800\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2303 - acc: 0.9250\n",
            "Epoch 745/800\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2303 - acc: 0.9250\n",
            "Epoch 746/800\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.2302 - acc: 0.9250\n",
            "Epoch 747/800\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2305 - acc: 0.9250\n",
            "Epoch 748/800\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2304 - acc: 0.9250\n",
            "Epoch 749/800\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.2301 - acc: 0.9250\n",
            "Epoch 750/800\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2300 - acc: 0.9250\n",
            "Epoch 751/800\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.2300 - acc: 0.9250\n",
            "Epoch 752/800\n",
            "120/120 [==============================] - 0s 121us/step - loss: 0.2299 - acc: 0.9250\n",
            "Epoch 753/800\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2299 - acc: 0.9250\n",
            "Epoch 754/800\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2297 - acc: 0.9250\n",
            "Epoch 755/800\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2296 - acc: 0.9250\n",
            "Epoch 756/800\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2296 - acc: 0.9250\n",
            "Epoch 757/800\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2296 - acc: 0.9250\n",
            "Epoch 758/800\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2295 - acc: 0.9250\n",
            "Epoch 759/800\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2298 - acc: 0.9250\n",
            "Epoch 760/800\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.2296 - acc: 0.9250\n",
            "Epoch 761/800\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2296 - acc: 0.9250\n",
            "Epoch 762/800\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2296 - acc: 0.9250\n",
            "Epoch 763/800\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2296 - acc: 0.9250\n",
            "Epoch 764/800\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2296 - acc: 0.9250\n",
            "Epoch 765/800\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2293 - acc: 0.9250\n",
            "Epoch 766/800\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2292 - acc: 0.9250\n",
            "Epoch 767/800\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2292 - acc: 0.9250\n",
            "Epoch 768/800\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2292 - acc: 0.9250\n",
            "Epoch 769/800\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.2292 - acc: 0.9250\n",
            "Epoch 770/800\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2293 - acc: 0.9250\n",
            "Epoch 771/800\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2292 - acc: 0.9250\n",
            "Epoch 772/800\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2291 - acc: 0.9250\n",
            "Epoch 773/800\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2290 - acc: 0.9250\n",
            "Epoch 774/800\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2293 - acc: 0.9250\n",
            "Epoch 775/800\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2291 - acc: 0.9250\n",
            "Epoch 776/800\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2292 - acc: 0.9250\n",
            "Epoch 777/800\n",
            "120/120 [==============================] - 0s 127us/step - loss: 0.2292 - acc: 0.9250\n",
            "Epoch 778/800\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2290 - acc: 0.9250\n",
            "Epoch 779/800\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2288 - acc: 0.9250\n",
            "Epoch 780/800\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.2288 - acc: 0.9250\n",
            "Epoch 781/800\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2289 - acc: 0.9250\n",
            "Epoch 782/800\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2288 - acc: 0.9167\n",
            "Epoch 783/800\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.2289 - acc: 0.9167\n",
            "Epoch 784/800\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2290 - acc: 0.9167\n",
            "Epoch 785/800\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.2291 - acc: 0.9167\n",
            "Epoch 786/800\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2290 - acc: 0.9167\n",
            "Epoch 787/800\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2290 - acc: 0.9167\n",
            "Epoch 788/800\n",
            "120/120 [==============================] - 0s 136us/step - loss: 0.2290 - acc: 0.9250\n",
            "Epoch 789/800\n",
            "120/120 [==============================] - 0s 115us/step - loss: 0.2291 - acc: 0.9250\n",
            "Epoch 790/800\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.2292 - acc: 0.9250\n",
            "Epoch 791/800\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2291 - acc: 0.9250\n",
            "Epoch 792/800\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2287 - acc: 0.9250\n",
            "Epoch 793/800\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2289 - acc: 0.9250\n",
            "Epoch 794/800\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2286 - acc: 0.9250\n",
            "Epoch 795/800\n",
            "120/120 [==============================] - 0s 127us/step - loss: 0.2284 - acc: 0.9250\n",
            "Epoch 796/800\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2284 - acc: 0.9250\n",
            "Epoch 797/800\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2282 - acc: 0.9250\n",
            "Epoch 798/800\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2283 - acc: 0.9250\n",
            "Epoch 799/800\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2283 - acc: 0.9250\n",
            "Epoch 800/800\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2284 - acc: 0.9250\n",
            "60/60 [==============================] - 1s 10ms/step\n",
            "\n",
            "acc: 86.67%\n",
            "[[13  1  1]\n",
            " [ 1 23  0]\n",
            " [ 4  1 16]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.87      0.79        15\n",
            "           1       0.92      0.96      0.94        24\n",
            "           2       0.94      0.76      0.84        21\n",
            "\n",
            "    accuracy                           0.87        60\n",
            "   macro avg       0.86      0.86      0.86        60\n",
            "weighted avg       0.88      0.87      0.87        60\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_169 (Dense)            (None, 10)                30        \n",
            "_________________________________________________________________\n",
            "dense_170 (Dense)            (None, 20)                220       \n",
            "_________________________________________________________________\n",
            "dense_171 (Dense)            (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_172 (Dense)            (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_173 (Dense)            (None, 3)                 63        \n",
            "=================================================================\n",
            "Total params: 1,153\n",
            "Trainable params: 1,153\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/900\n",
            "120/120 [==============================] - 2s 13ms/step - loss: 1.0802 - acc: 0.4083\n",
            "Epoch 2/900\n",
            "120/120 [==============================] - 0s 161us/step - loss: 1.0765 - acc: 0.4583\n",
            "Epoch 3/900\n",
            "120/120 [==============================] - 0s 118us/step - loss: 1.0730 - acc: 0.5000\n",
            "Epoch 4/900\n",
            "120/120 [==============================] - 0s 80us/step - loss: 1.0695 - acc: 0.5333\n",
            "Epoch 5/900\n",
            "120/120 [==============================] - 0s 66us/step - loss: 1.0661 - acc: 0.5583\n",
            "Epoch 6/900\n",
            "120/120 [==============================] - 0s 93us/step - loss: 1.0629 - acc: 0.5833\n",
            "Epoch 7/900\n",
            "120/120 [==============================] - 0s 64us/step - loss: 1.0599 - acc: 0.6000\n",
            "Epoch 8/900\n",
            "120/120 [==============================] - 0s 115us/step - loss: 1.0571 - acc: 0.6000\n",
            "Epoch 9/900\n",
            "120/120 [==============================] - 0s 80us/step - loss: 1.0548 - acc: 0.6000\n",
            "Epoch 10/900\n",
            "120/120 [==============================] - 0s 78us/step - loss: 1.0526 - acc: 0.6000\n",
            "Epoch 11/900\n",
            "120/120 [==============================] - 0s 79us/step - loss: 1.0508 - acc: 0.6000\n",
            "Epoch 12/900\n",
            "120/120 [==============================] - 0s 85us/step - loss: 1.0487 - acc: 0.6083\n",
            "Epoch 13/900\n",
            "120/120 [==============================] - 0s 99us/step - loss: 1.0467 - acc: 0.5917\n",
            "Epoch 14/900\n",
            "120/120 [==============================] - 0s 117us/step - loss: 1.0449 - acc: 0.5917\n",
            "Epoch 15/900\n",
            "120/120 [==============================] - 0s 120us/step - loss: 1.0430 - acc: 0.6000\n",
            "Epoch 16/900\n",
            "120/120 [==============================] - 0s 113us/step - loss: 1.0407 - acc: 0.6000\n",
            "Epoch 17/900\n",
            "120/120 [==============================] - 0s 102us/step - loss: 1.0388 - acc: 0.5917\n",
            "Epoch 18/900\n",
            "120/120 [==============================] - 0s 89us/step - loss: 1.0371 - acc: 0.5917\n",
            "Epoch 19/900\n",
            "120/120 [==============================] - 0s 85us/step - loss: 1.0356 - acc: 0.6000\n",
            "Epoch 20/900\n",
            "120/120 [==============================] - 0s 107us/step - loss: 1.0338 - acc: 0.6000\n",
            "Epoch 21/900\n",
            "120/120 [==============================] - 0s 103us/step - loss: 1.0319 - acc: 0.6000\n",
            "Epoch 22/900\n",
            "120/120 [==============================] - 0s 96us/step - loss: 1.0300 - acc: 0.6083\n",
            "Epoch 23/900\n",
            "120/120 [==============================] - 0s 106us/step - loss: 1.0282 - acc: 0.5917\n",
            "Epoch 24/900\n",
            "120/120 [==============================] - 0s 98us/step - loss: 1.0265 - acc: 0.5917\n",
            "Epoch 25/900\n",
            "120/120 [==============================] - 0s 121us/step - loss: 1.0245 - acc: 0.6000\n",
            "Epoch 26/900\n",
            "120/120 [==============================] - 0s 96us/step - loss: 1.0227 - acc: 0.6000\n",
            "Epoch 27/900\n",
            "120/120 [==============================] - 0s 99us/step - loss: 1.0210 - acc: 0.6083\n",
            "Epoch 28/900\n",
            "120/120 [==============================] - 0s 84us/step - loss: 1.0190 - acc: 0.6000\n",
            "Epoch 29/900\n",
            "120/120 [==============================] - 0s 87us/step - loss: 1.0173 - acc: 0.6083\n",
            "Epoch 30/900\n",
            "120/120 [==============================] - 0s 91us/step - loss: 1.0156 - acc: 0.6083\n",
            "Epoch 31/900\n",
            "120/120 [==============================] - 0s 103us/step - loss: 1.0140 - acc: 0.6083\n",
            "Epoch 32/900\n",
            "120/120 [==============================] - 0s 95us/step - loss: 1.0123 - acc: 0.6083\n",
            "Epoch 33/900\n",
            "120/120 [==============================] - 0s 98us/step - loss: 1.0105 - acc: 0.6167\n",
            "Epoch 34/900\n",
            "120/120 [==============================] - 0s 97us/step - loss: 1.0086 - acc: 0.6250\n",
            "Epoch 35/900\n",
            "120/120 [==============================] - 0s 106us/step - loss: 1.0070 - acc: 0.6250\n",
            "Epoch 36/900\n",
            "120/120 [==============================] - 0s 102us/step - loss: 1.0051 - acc: 0.6250\n",
            "Epoch 37/900\n",
            "120/120 [==============================] - 0s 85us/step - loss: 1.0033 - acc: 0.6333\n",
            "Epoch 38/900\n",
            "120/120 [==============================] - 0s 83us/step - loss: 1.0010 - acc: 0.6250\n",
            "Epoch 39/900\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.9990 - acc: 0.6333\n",
            "Epoch 40/900\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.9971 - acc: 0.6333\n",
            "Epoch 41/900\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.9950 - acc: 0.6250\n",
            "Epoch 42/900\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.9930 - acc: 0.6333\n",
            "Epoch 43/900\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.9909 - acc: 0.6333\n",
            "Epoch 44/900\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.9889 - acc: 0.6333\n",
            "Epoch 45/900\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.9867 - acc: 0.6417\n",
            "Epoch 46/900\n",
            "120/120 [==============================] - 0s 127us/step - loss: 0.9848 - acc: 0.6333\n",
            "Epoch 47/900\n",
            "120/120 [==============================] - 0s 159us/step - loss: 0.9830 - acc: 0.6417\n",
            "Epoch 48/900\n",
            "120/120 [==============================] - 0s 119us/step - loss: 0.9809 - acc: 0.6417\n",
            "Epoch 49/900\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.9787 - acc: 0.6417\n",
            "Epoch 50/900\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.9766 - acc: 0.6417\n",
            "Epoch 51/900\n",
            "120/120 [==============================] - 0s 120us/step - loss: 0.9746 - acc: 0.6417\n",
            "Epoch 52/900\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.9724 - acc: 0.6583\n",
            "Epoch 53/900\n",
            "120/120 [==============================] - 0s 117us/step - loss: 0.9702 - acc: 0.6583\n",
            "Epoch 54/900\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.9680 - acc: 0.6500\n",
            "Epoch 55/900\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.9658 - acc: 0.6500\n",
            "Epoch 56/900\n",
            "120/120 [==============================] - 0s 136us/step - loss: 0.9637 - acc: 0.6583\n",
            "Epoch 57/900\n",
            "120/120 [==============================] - 0s 142us/step - loss: 0.9612 - acc: 0.6583\n",
            "Epoch 58/900\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.9587 - acc: 0.6583\n",
            "Epoch 59/900\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.9563 - acc: 0.6583\n",
            "Epoch 60/900\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.9542 - acc: 0.6583\n",
            "Epoch 61/900\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.9515 - acc: 0.6583\n",
            "Epoch 62/900\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.9493 - acc: 0.6583\n",
            "Epoch 63/900\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.9470 - acc: 0.6583\n",
            "Epoch 64/900\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.9446 - acc: 0.6583\n",
            "Epoch 65/900\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.9423 - acc: 0.6500\n",
            "Epoch 66/900\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.9396 - acc: 0.6583\n",
            "Epoch 67/900\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.9368 - acc: 0.6583\n",
            "Epoch 68/900\n",
            "120/120 [==============================] - 0s 125us/step - loss: 0.9344 - acc: 0.6583\n",
            "Epoch 69/900\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.9316 - acc: 0.6500\n",
            "Epoch 70/900\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.9290 - acc: 0.6500\n",
            "Epoch 71/900\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.9263 - acc: 0.6500\n",
            "Epoch 72/900\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.9235 - acc: 0.6500\n",
            "Epoch 73/900\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.9207 - acc: 0.6500\n",
            "Epoch 74/900\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.9181 - acc: 0.6583\n",
            "Epoch 75/900\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.9151 - acc: 0.6583\n",
            "Epoch 76/900\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.9125 - acc: 0.6583\n",
            "Epoch 77/900\n",
            "120/120 [==============================] - 0s 77us/step - loss: 0.9097 - acc: 0.6583\n",
            "Epoch 78/900\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.9068 - acc: 0.6667\n",
            "Epoch 79/900\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.9038 - acc: 0.6583\n",
            "Epoch 80/900\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.9006 - acc: 0.6583\n",
            "Epoch 81/900\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.8976 - acc: 0.6583\n",
            "Epoch 82/900\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.8942 - acc: 0.6583\n",
            "Epoch 83/900\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.8911 - acc: 0.6583\n",
            "Epoch 84/900\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.8883 - acc: 0.6583\n",
            "Epoch 85/900\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.8852 - acc: 0.6583\n",
            "Epoch 86/900\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.8819 - acc: 0.6583\n",
            "Epoch 87/900\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.8785 - acc: 0.6750\n",
            "Epoch 88/900\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.8751 - acc: 0.6750\n",
            "Epoch 89/900\n",
            "120/120 [==============================] - 0s 128us/step - loss: 0.8715 - acc: 0.6750\n",
            "Epoch 90/900\n",
            "120/120 [==============================] - 0s 133us/step - loss: 0.8679 - acc: 0.6750\n",
            "Epoch 91/900\n",
            "120/120 [==============================] - 0s 140us/step - loss: 0.8643 - acc: 0.6833\n",
            "Epoch 92/900\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.8606 - acc: 0.6833\n",
            "Epoch 93/900\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.8571 - acc: 0.6833\n",
            "Epoch 94/900\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.8538 - acc: 0.6917\n",
            "Epoch 95/900\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.8501 - acc: 0.6833\n",
            "Epoch 96/900\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.8462 - acc: 0.6917\n",
            "Epoch 97/900\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.8426 - acc: 0.6833\n",
            "Epoch 98/900\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.8386 - acc: 0.6833\n",
            "Epoch 99/900\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.8343 - acc: 0.6833\n",
            "Epoch 100/900\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.8307 - acc: 0.6833\n",
            "Epoch 101/900\n",
            "120/120 [==============================] - 0s 131us/step - loss: 0.8272 - acc: 0.6833\n",
            "Epoch 102/900\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.8237 - acc: 0.6833\n",
            "Epoch 103/900\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.8199 - acc: 0.6833\n",
            "Epoch 104/900\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.8160 - acc: 0.6833\n",
            "Epoch 105/900\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.8119 - acc: 0.6833\n",
            "Epoch 106/900\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.8079 - acc: 0.6917\n",
            "Epoch 107/900\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.8040 - acc: 0.6917\n",
            "Epoch 108/900\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.8004 - acc: 0.6917\n",
            "Epoch 109/900\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.7966 - acc: 0.6917\n",
            "Epoch 110/900\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.7923 - acc: 0.6917\n",
            "Epoch 111/900\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.7881 - acc: 0.6917\n",
            "Epoch 112/900\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.7839 - acc: 0.6917\n",
            "Epoch 113/900\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.7799 - acc: 0.6917\n",
            "Epoch 114/900\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.7754 - acc: 0.6917\n",
            "Epoch 115/900\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.7709 - acc: 0.6917\n",
            "Epoch 116/900\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.7667 - acc: 0.6917\n",
            "Epoch 117/900\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.7630 - acc: 0.6917\n",
            "Epoch 118/900\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.7587 - acc: 0.6917\n",
            "Epoch 119/900\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.7548 - acc: 0.6917\n",
            "Epoch 120/900\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.7505 - acc: 0.6917\n",
            "Epoch 121/900\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.7463 - acc: 0.6917\n",
            "Epoch 122/900\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.7421 - acc: 0.6917\n",
            "Epoch 123/900\n",
            "120/120 [==============================] - 0s 134us/step - loss: 0.7381 - acc: 0.6917\n",
            "Epoch 124/900\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.7341 - acc: 0.6917\n",
            "Epoch 125/900\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.7299 - acc: 0.6917\n",
            "Epoch 126/900\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.7258 - acc: 0.6917\n",
            "Epoch 127/900\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.7214 - acc: 0.6917\n",
            "Epoch 128/900\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.7172 - acc: 0.6917\n",
            "Epoch 129/900\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.7129 - acc: 0.6917\n",
            "Epoch 130/900\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.7087 - acc: 0.6917\n",
            "Epoch 131/900\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.7050 - acc: 0.6917\n",
            "Epoch 132/900\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.7008 - acc: 0.6917\n",
            "Epoch 133/900\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.6966 - acc: 0.6917\n",
            "Epoch 134/900\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.6926 - acc: 0.7000\n",
            "Epoch 135/900\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.6885 - acc: 0.7417\n",
            "Epoch 136/900\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.6845 - acc: 0.7417\n",
            "Epoch 137/900\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.6803 - acc: 0.7583\n",
            "Epoch 138/900\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.6762 - acc: 0.7583\n",
            "Epoch 139/900\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.6725 - acc: 0.7750\n",
            "Epoch 140/900\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.6686 - acc: 0.7750\n",
            "Epoch 141/900\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.6649 - acc: 0.8000\n",
            "Epoch 142/900\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.6612 - acc: 0.8000\n",
            "Epoch 143/900\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.6575 - acc: 0.8000\n",
            "Epoch 144/900\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.6537 - acc: 0.8000\n",
            "Epoch 145/900\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.6498 - acc: 0.8000\n",
            "Epoch 146/900\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.6459 - acc: 0.8000\n",
            "Epoch 147/900\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.6421 - acc: 0.8167\n",
            "Epoch 148/900\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.6383 - acc: 0.8167\n",
            "Epoch 149/900\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.6346 - acc: 0.8167\n",
            "Epoch 150/900\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.6308 - acc: 0.8167\n",
            "Epoch 151/900\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.6273 - acc: 0.8167\n",
            "Epoch 152/900\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.6239 - acc: 0.8250\n",
            "Epoch 153/900\n",
            "120/120 [==============================] - 0s 120us/step - loss: 0.6203 - acc: 0.8250\n",
            "Epoch 154/900\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.6168 - acc: 0.8250\n",
            "Epoch 155/900\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.6130 - acc: 0.8250\n",
            "Epoch 156/900\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.6095 - acc: 0.8250\n",
            "Epoch 157/900\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.6057 - acc: 0.8417\n",
            "Epoch 158/900\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.6023 - acc: 0.8417\n",
            "Epoch 159/900\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.5985 - acc: 0.8417\n",
            "Epoch 160/900\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.5949 - acc: 0.8417\n",
            "Epoch 161/900\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.5916 - acc: 0.8500\n",
            "Epoch 162/900\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.5887 - acc: 0.8583\n",
            "Epoch 163/900\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.5855 - acc: 0.8583\n",
            "Epoch 164/900\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.5826 - acc: 0.8583\n",
            "Epoch 165/900\n",
            "120/120 [==============================] - 0s 151us/step - loss: 0.5793 - acc: 0.8583\n",
            "Epoch 166/900\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.5761 - acc: 0.8583\n",
            "Epoch 167/900\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.5729 - acc: 0.8583\n",
            "Epoch 168/900\n",
            "120/120 [==============================] - 0s 123us/step - loss: 0.5700 - acc: 0.8583\n",
            "Epoch 169/900\n",
            "120/120 [==============================] - 0s 129us/step - loss: 0.5668 - acc: 0.8583\n",
            "Epoch 170/900\n",
            "120/120 [==============================] - 0s 134us/step - loss: 0.5638 - acc: 0.8583\n",
            "Epoch 171/900\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.5607 - acc: 0.8583\n",
            "Epoch 172/900\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.5579 - acc: 0.8667\n",
            "Epoch 173/900\n",
            "120/120 [==============================] - 0s 77us/step - loss: 0.5553 - acc: 0.8583\n",
            "Epoch 174/900\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.5522 - acc: 0.8583\n",
            "Epoch 175/900\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.5493 - acc: 0.8583\n",
            "Epoch 176/900\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.5461 - acc: 0.8667\n",
            "Epoch 177/900\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.5433 - acc: 0.8667\n",
            "Epoch 178/900\n",
            "120/120 [==============================] - 0s 115us/step - loss: 0.5407 - acc: 0.8667\n",
            "Epoch 179/900\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.5379 - acc: 0.8667\n",
            "Epoch 180/900\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.5353 - acc: 0.8667\n",
            "Epoch 181/900\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.5326 - acc: 0.8667\n",
            "Epoch 182/900\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.5298 - acc: 0.8750\n",
            "Epoch 183/900\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.5271 - acc: 0.8750\n",
            "Epoch 184/900\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.5246 - acc: 0.8750\n",
            "Epoch 185/900\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.5222 - acc: 0.8750\n",
            "Epoch 186/900\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.5197 - acc: 0.8750\n",
            "Epoch 187/900\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.5171 - acc: 0.8750\n",
            "Epoch 188/900\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.5148 - acc: 0.8750\n",
            "Epoch 189/900\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.5122 - acc: 0.8750\n",
            "Epoch 190/900\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.5102 - acc: 0.8750\n",
            "Epoch 191/900\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.5079 - acc: 0.8833\n",
            "Epoch 192/900\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.5053 - acc: 0.8833\n",
            "Epoch 193/900\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.5027 - acc: 0.8833\n",
            "Epoch 194/900\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.5004 - acc: 0.8833\n",
            "Epoch 195/900\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.4981 - acc: 0.8833\n",
            "Epoch 196/900\n",
            "120/120 [==============================] - 0s 75us/step - loss: 0.4958 - acc: 0.8833\n",
            "Epoch 197/900\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.4937 - acc: 0.8833\n",
            "Epoch 198/900\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.4910 - acc: 0.8833\n",
            "Epoch 199/900\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.4886 - acc: 0.8917\n",
            "Epoch 200/900\n",
            "120/120 [==============================] - 0s 74us/step - loss: 0.4863 - acc: 0.8917\n",
            "Epoch 201/900\n",
            "120/120 [==============================] - 0s 145us/step - loss: 0.4840 - acc: 0.8917\n",
            "Epoch 202/900\n",
            "120/120 [==============================] - 0s 146us/step - loss: 0.4817 - acc: 0.9000\n",
            "Epoch 203/900\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.4796 - acc: 0.9000\n",
            "Epoch 204/900\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.4775 - acc: 0.9000\n",
            "Epoch 205/900\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.4752 - acc: 0.9000\n",
            "Epoch 206/900\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.4730 - acc: 0.9000\n",
            "Epoch 207/900\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.4709 - acc: 0.9000\n",
            "Epoch 208/900\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.4689 - acc: 0.9000\n",
            "Epoch 209/900\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.4666 - acc: 0.9000\n",
            "Epoch 210/900\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.4646 - acc: 0.8917\n",
            "Epoch 211/900\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.4626 - acc: 0.8917\n",
            "Epoch 212/900\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.4608 - acc: 0.8917\n",
            "Epoch 213/900\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.4589 - acc: 0.9000\n",
            "Epoch 214/900\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.4570 - acc: 0.8917\n",
            "Epoch 215/900\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.4554 - acc: 0.9000\n",
            "Epoch 216/900\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.4536 - acc: 0.9000\n",
            "Epoch 217/900\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.4518 - acc: 0.9000\n",
            "Epoch 218/900\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.4498 - acc: 0.9083\n",
            "Epoch 219/900\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.4480 - acc: 0.9000\n",
            "Epoch 220/900\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.4465 - acc: 0.9000\n",
            "Epoch 221/900\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.4449 - acc: 0.9083\n",
            "Epoch 222/900\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.4433 - acc: 0.9083\n",
            "Epoch 223/900\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.4413 - acc: 0.9083\n",
            "Epoch 224/900\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.4394 - acc: 0.9083\n",
            "Epoch 225/900\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.4378 - acc: 0.9083\n",
            "Epoch 226/900\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.4361 - acc: 0.9083\n",
            "Epoch 227/900\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.4343 - acc: 0.9083\n",
            "Epoch 228/900\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.4327 - acc: 0.9083\n",
            "Epoch 229/900\n",
            "120/120 [==============================] - 0s 129us/step - loss: 0.4310 - acc: 0.9083\n",
            "Epoch 230/900\n",
            "120/120 [==============================] - 0s 128us/step - loss: 0.4289 - acc: 0.9000\n",
            "Epoch 231/900\n",
            "120/120 [==============================] - 0s 120us/step - loss: 0.4273 - acc: 0.9083\n",
            "Epoch 232/900\n",
            "120/120 [==============================] - 0s 164us/step - loss: 0.4256 - acc: 0.9083\n",
            "Epoch 233/900\n",
            "120/120 [==============================] - 0s 117us/step - loss: 0.4238 - acc: 0.9083\n",
            "Epoch 234/900\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.4219 - acc: 0.9167\n",
            "Epoch 235/900\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.4203 - acc: 0.9167\n",
            "Epoch 236/900\n",
            "120/120 [==============================] - 0s 132us/step - loss: 0.4187 - acc: 0.9167\n",
            "Epoch 237/900\n",
            "120/120 [==============================] - 0s 125us/step - loss: 0.4170 - acc: 0.9167\n",
            "Epoch 238/900\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.4154 - acc: 0.9167\n",
            "Epoch 239/900\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.4137 - acc: 0.9167\n",
            "Epoch 240/900\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.4122 - acc: 0.9167\n",
            "Epoch 241/900\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.4105 - acc: 0.9167\n",
            "Epoch 242/900\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.4087 - acc: 0.9167\n",
            "Epoch 243/900\n",
            "120/120 [==============================] - 0s 120us/step - loss: 0.4071 - acc: 0.9167\n",
            "Epoch 244/900\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.4056 - acc: 0.9167\n",
            "Epoch 245/900\n",
            "120/120 [==============================] - 0s 117us/step - loss: 0.4039 - acc: 0.9167\n",
            "Epoch 246/900\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.4024 - acc: 0.9167\n",
            "Epoch 247/900\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.4009 - acc: 0.9167\n",
            "Epoch 248/900\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.3993 - acc: 0.9167\n",
            "Epoch 249/900\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.3978 - acc: 0.9167\n",
            "Epoch 250/900\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.3962 - acc: 0.9167\n",
            "Epoch 251/900\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.3946 - acc: 0.9167\n",
            "Epoch 252/900\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.3931 - acc: 0.9167\n",
            "Epoch 253/900\n",
            "120/120 [==============================] - 0s 135us/step - loss: 0.3915 - acc: 0.9167\n",
            "Epoch 254/900\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.3901 - acc: 0.9167\n",
            "Epoch 255/900\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.3886 - acc: 0.9167\n",
            "Epoch 256/900\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.3871 - acc: 0.9167\n",
            "Epoch 257/900\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.3860 - acc: 0.9167\n",
            "Epoch 258/900\n",
            "120/120 [==============================] - 0s 126us/step - loss: 0.3847 - acc: 0.9167\n",
            "Epoch 259/900\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.3834 - acc: 0.9167\n",
            "Epoch 260/900\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.3818 - acc: 0.9167\n",
            "Epoch 261/900\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.3804 - acc: 0.9167\n",
            "Epoch 262/900\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.3791 - acc: 0.9167\n",
            "Epoch 263/900\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.3777 - acc: 0.9167\n",
            "Epoch 264/900\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.3764 - acc: 0.9167\n",
            "Epoch 265/900\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.3752 - acc: 0.9167\n",
            "Epoch 266/900\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.3741 - acc: 0.9167\n",
            "Epoch 267/900\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.3728 - acc: 0.9167\n",
            "Epoch 268/900\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.3715 - acc: 0.9167\n",
            "Epoch 269/900\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.3703 - acc: 0.9167\n",
            "Epoch 270/900\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.3691 - acc: 0.9167\n",
            "Epoch 271/900\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.3678 - acc: 0.9167\n",
            "Epoch 272/900\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.3668 - acc: 0.9167\n",
            "Epoch 273/900\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.3655 - acc: 0.9167\n",
            "Epoch 274/900\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.3642 - acc: 0.9167\n",
            "Epoch 275/900\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.3630 - acc: 0.9167\n",
            "Epoch 276/900\n",
            "120/120 [==============================] - 0s 195us/step - loss: 0.3618 - acc: 0.9167\n",
            "Epoch 277/900\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.3605 - acc: 0.9167\n",
            "Epoch 278/900\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.3594 - acc: 0.9167\n",
            "Epoch 279/900\n",
            "120/120 [==============================] - 0s 142us/step - loss: 0.3584 - acc: 0.9167\n",
            "Epoch 280/900\n",
            "120/120 [==============================] - 0s 126us/step - loss: 0.3571 - acc: 0.9167\n",
            "Epoch 281/900\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.3556 - acc: 0.9167\n",
            "Epoch 282/900\n",
            "120/120 [==============================] - 0s 122us/step - loss: 0.3543 - acc: 0.9167\n",
            "Epoch 283/900\n",
            "120/120 [==============================] - 0s 131us/step - loss: 0.3530 - acc: 0.9167\n",
            "Epoch 284/900\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.3519 - acc: 0.9167\n",
            "Epoch 285/900\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.3507 - acc: 0.9167\n",
            "Epoch 286/900\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.3493 - acc: 0.9167\n",
            "Epoch 287/900\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.3478 - acc: 0.9167\n",
            "Epoch 288/900\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.3467 - acc: 0.9167\n",
            "Epoch 289/900\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.3456 - acc: 0.9167\n",
            "Epoch 290/900\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.3445 - acc: 0.9167\n",
            "Epoch 291/900\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.3436 - acc: 0.9167\n",
            "Epoch 292/900\n",
            "120/120 [==============================] - 0s 120us/step - loss: 0.3422 - acc: 0.9167\n",
            "Epoch 293/900\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.3411 - acc: 0.9167\n",
            "Epoch 294/900\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.3399 - acc: 0.9167\n",
            "Epoch 295/900\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.3388 - acc: 0.9250\n",
            "Epoch 296/900\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.3377 - acc: 0.9250\n",
            "Epoch 297/900\n",
            "120/120 [==============================] - 0s 70us/step - loss: 0.3368 - acc: 0.9250\n",
            "Epoch 298/900\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.3360 - acc: 0.9250\n",
            "Epoch 299/900\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.3348 - acc: 0.9167\n",
            "Epoch 300/900\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.3338 - acc: 0.9167\n",
            "Epoch 301/900\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.3329 - acc: 0.9167\n",
            "Epoch 302/900\n",
            "120/120 [==============================] - 0s 117us/step - loss: 0.3318 - acc: 0.9250\n",
            "Epoch 303/900\n",
            "120/120 [==============================] - 0s 126us/step - loss: 0.3307 - acc: 0.9250\n",
            "Epoch 304/900\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.3296 - acc: 0.9250\n",
            "Epoch 305/900\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.3286 - acc: 0.9250\n",
            "Epoch 306/900\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.3278 - acc: 0.9250\n",
            "Epoch 307/900\n",
            "120/120 [==============================] - 0s 117us/step - loss: 0.3268 - acc: 0.9250\n",
            "Epoch 308/900\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.3256 - acc: 0.9250\n",
            "Epoch 309/900\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.3246 - acc: 0.9250\n",
            "Epoch 310/900\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.3238 - acc: 0.9250\n",
            "Epoch 311/900\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.3230 - acc: 0.9250\n",
            "Epoch 312/900\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.3215 - acc: 0.9167\n",
            "Epoch 313/900\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.3207 - acc: 0.9250\n",
            "Epoch 314/900\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.3195 - acc: 0.9250\n",
            "Epoch 315/900\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.3187 - acc: 0.9250\n",
            "Epoch 316/900\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.3177 - acc: 0.9250\n",
            "Epoch 317/900\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.3168 - acc: 0.9250\n",
            "Epoch 318/900\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.3161 - acc: 0.9250\n",
            "Epoch 319/900\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.3156 - acc: 0.9250\n",
            "Epoch 320/900\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.3146 - acc: 0.9167\n",
            "Epoch 321/900\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.3136 - acc: 0.9167\n",
            "Epoch 322/900\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.3127 - acc: 0.9167\n",
            "Epoch 323/900\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.3118 - acc: 0.9167\n",
            "Epoch 324/900\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.3109 - acc: 0.9167\n",
            "Epoch 325/900\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.3100 - acc: 0.9167\n",
            "Epoch 326/900\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.3093 - acc: 0.9167\n",
            "Epoch 327/900\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.3084 - acc: 0.9167\n",
            "Epoch 328/900\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.3076 - acc: 0.9167\n",
            "Epoch 329/900\n",
            "120/120 [==============================] - 0s 144us/step - loss: 0.3068 - acc: 0.9167\n",
            "Epoch 330/900\n",
            "120/120 [==============================] - 0s 115us/step - loss: 0.3061 - acc: 0.9250\n",
            "Epoch 331/900\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.3053 - acc: 0.9250\n",
            "Epoch 332/900\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.3045 - acc: 0.9250\n",
            "Epoch 333/900\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.3035 - acc: 0.9250\n",
            "Epoch 334/900\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.3027 - acc: 0.9250\n",
            "Epoch 335/900\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.3019 - acc: 0.9250\n",
            "Epoch 336/900\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.3008 - acc: 0.9167\n",
            "Epoch 337/900\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.3000 - acc: 0.9167\n",
            "Epoch 338/900\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2993 - acc: 0.9167\n",
            "Epoch 339/900\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2986 - acc: 0.9167\n",
            "Epoch 340/900\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2978 - acc: 0.9167\n",
            "Epoch 341/900\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2971 - acc: 0.9167\n",
            "Epoch 342/900\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2964 - acc: 0.9167\n",
            "Epoch 343/900\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2956 - acc: 0.9167\n",
            "Epoch 344/900\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2949 - acc: 0.9167\n",
            "Epoch 345/900\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.2942 - acc: 0.9167\n",
            "Epoch 346/900\n",
            "120/120 [==============================] - 0s 121us/step - loss: 0.2935 - acc: 0.9167\n",
            "Epoch 347/900\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2927 - acc: 0.9167\n",
            "Epoch 348/900\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2921 - acc: 0.9167\n",
            "Epoch 349/900\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.2914 - acc: 0.9167\n",
            "Epoch 350/900\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.2909 - acc: 0.9167\n",
            "Epoch 351/900\n",
            "120/120 [==============================] - 0s 137us/step - loss: 0.2903 - acc: 0.9167\n",
            "Epoch 352/900\n",
            "120/120 [==============================] - 0s 141us/step - loss: 0.2899 - acc: 0.9167\n",
            "Epoch 353/900\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.2890 - acc: 0.9167\n",
            "Epoch 354/900\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2883 - acc: 0.9250\n",
            "Epoch 355/900\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2876 - acc: 0.9167\n",
            "Epoch 356/900\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2870 - acc: 0.9167\n",
            "Epoch 357/900\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2864 - acc: 0.9167\n",
            "Epoch 358/900\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2856 - acc: 0.9167\n",
            "Epoch 359/900\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.2850 - acc: 0.9167\n",
            "Epoch 360/900\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.2847 - acc: 0.9083\n",
            "Epoch 361/900\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.2838 - acc: 0.9167\n",
            "Epoch 362/900\n",
            "120/120 [==============================] - 0s 122us/step - loss: 0.2832 - acc: 0.9083\n",
            "Epoch 363/900\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.2825 - acc: 0.9167\n",
            "Epoch 364/900\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2818 - acc: 0.9083\n",
            "Epoch 365/900\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.2811 - acc: 0.9167\n",
            "Epoch 366/900\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.2805 - acc: 0.9083\n",
            "Epoch 367/900\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.2800 - acc: 0.9083\n",
            "Epoch 368/900\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2795 - acc: 0.9083\n",
            "Epoch 369/900\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2790 - acc: 0.9083\n",
            "Epoch 370/900\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2784 - acc: 0.9083\n",
            "Epoch 371/900\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.2778 - acc: 0.9083\n",
            "Epoch 372/900\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2773 - acc: 0.9083\n",
            "Epoch 373/900\n",
            "120/120 [==============================] - 0s 124us/step - loss: 0.2767 - acc: 0.9167\n",
            "Epoch 374/900\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2763 - acc: 0.9083\n",
            "Epoch 375/900\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2757 - acc: 0.9083\n",
            "Epoch 376/900\n",
            "120/120 [==============================] - 0s 142us/step - loss: 0.2751 - acc: 0.9083\n",
            "Epoch 377/900\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.2745 - acc: 0.9083\n",
            "Epoch 378/900\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.2739 - acc: 0.9083\n",
            "Epoch 379/900\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.2734 - acc: 0.9167\n",
            "Epoch 380/900\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.2728 - acc: 0.9167\n",
            "Epoch 381/900\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2723 - acc: 0.9083\n",
            "Epoch 382/900\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.2718 - acc: 0.9083\n",
            "Epoch 383/900\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2713 - acc: 0.9083\n",
            "Epoch 384/900\n",
            "120/120 [==============================] - 0s 130us/step - loss: 0.2708 - acc: 0.9083\n",
            "Epoch 385/900\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2705 - acc: 0.9167\n",
            "Epoch 386/900\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.2700 - acc: 0.9083\n",
            "Epoch 387/900\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2694 - acc: 0.9083\n",
            "Epoch 388/900\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2689 - acc: 0.9083\n",
            "Epoch 389/900\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2684 - acc: 0.9083\n",
            "Epoch 390/900\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2679 - acc: 0.9167\n",
            "Epoch 391/900\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.2674 - acc: 0.9083\n",
            "Epoch 392/900\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2670 - acc: 0.9083\n",
            "Epoch 393/900\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.2662 - acc: 0.9083\n",
            "Epoch 394/900\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.2658 - acc: 0.9083\n",
            "Epoch 395/900\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.2654 - acc: 0.9083\n",
            "Epoch 396/900\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2650 - acc: 0.9083\n",
            "Epoch 397/900\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2646 - acc: 0.9083\n",
            "Epoch 398/900\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2642 - acc: 0.9083\n",
            "Epoch 399/900\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2639 - acc: 0.9083\n",
            "Epoch 400/900\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2633 - acc: 0.9083\n",
            "Epoch 401/900\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.2628 - acc: 0.9083\n",
            "Epoch 402/900\n",
            "120/120 [==============================] - 0s 73us/step - loss: 0.2624 - acc: 0.9083\n",
            "Epoch 403/900\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.2621 - acc: 0.9083\n",
            "Epoch 404/900\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2613 - acc: 0.9083\n",
            "Epoch 405/900\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2610 - acc: 0.9083\n",
            "Epoch 406/900\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2605 - acc: 0.9083\n",
            "Epoch 407/900\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2601 - acc: 0.9167\n",
            "Epoch 408/900\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2596 - acc: 0.9083\n",
            "Epoch 409/900\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2591 - acc: 0.9167\n",
            "Epoch 410/900\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2588 - acc: 0.9083\n",
            "Epoch 411/900\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2583 - acc: 0.9083\n",
            "Epoch 412/900\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2579 - acc: 0.9083\n",
            "Epoch 413/900\n",
            "120/120 [==============================] - 0s 123us/step - loss: 0.2574 - acc: 0.9083\n",
            "Epoch 414/900\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2570 - acc: 0.9083\n",
            "Epoch 415/900\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2567 - acc: 0.9167\n",
            "Epoch 416/900\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2566 - acc: 0.9167\n",
            "Epoch 417/900\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2562 - acc: 0.9083\n",
            "Epoch 418/900\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2558 - acc: 0.9167\n",
            "Epoch 419/900\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2555 - acc: 0.9167\n",
            "Epoch 420/900\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2553 - acc: 0.9167\n",
            "Epoch 421/900\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2548 - acc: 0.9167\n",
            "Epoch 422/900\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2545 - acc: 0.9167\n",
            "Epoch 423/900\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2539 - acc: 0.9167\n",
            "Epoch 424/900\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.2534 - acc: 0.9083\n",
            "Epoch 425/900\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2530 - acc: 0.9083\n",
            "Epoch 426/900\n",
            "120/120 [==============================] - 0s 241us/step - loss: 0.2528 - acc: 0.9083\n",
            "Epoch 427/900\n",
            "120/120 [==============================] - 0s 117us/step - loss: 0.2525 - acc: 0.9250\n",
            "Epoch 428/900\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2522 - acc: 0.9250\n",
            "Epoch 429/900\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2519 - acc: 0.9167\n",
            "Epoch 430/900\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.2515 - acc: 0.9250\n",
            "Epoch 431/900\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.2511 - acc: 0.9250\n",
            "Epoch 432/900\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2506 - acc: 0.9250\n",
            "Epoch 433/900\n",
            "120/120 [==============================] - 0s 123us/step - loss: 0.2503 - acc: 0.9250\n",
            "Epoch 434/900\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.2500 - acc: 0.9250\n",
            "Epoch 435/900\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2497 - acc: 0.9250\n",
            "Epoch 436/900\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.2493 - acc: 0.9250\n",
            "Epoch 437/900\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.2489 - acc: 0.9083\n",
            "Epoch 438/900\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.2485 - acc: 0.9083\n",
            "Epoch 439/900\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2482 - acc: 0.9083\n",
            "Epoch 440/900\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.2479 - acc: 0.9083\n",
            "Epoch 441/900\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.2476 - acc: 0.9083\n",
            "Epoch 442/900\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2472 - acc: 0.9167\n",
            "Epoch 443/900\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2469 - acc: 0.9083\n",
            "Epoch 444/900\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.2467 - acc: 0.9083\n",
            "Epoch 445/900\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.2465 - acc: 0.9083\n",
            "Epoch 446/900\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.2461 - acc: 0.9250\n",
            "Epoch 447/900\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2459 - acc: 0.9167\n",
            "Epoch 448/900\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2456 - acc: 0.9250\n",
            "Epoch 449/900\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.2453 - acc: 0.9250\n",
            "Epoch 450/900\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.2449 - acc: 0.9167\n",
            "Epoch 451/900\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2446 - acc: 0.9167\n",
            "Epoch 452/900\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2443 - acc: 0.9167\n",
            "Epoch 453/900\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.2440 - acc: 0.9167\n",
            "Epoch 454/900\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2440 - acc: 0.9083\n",
            "Epoch 455/900\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2437 - acc: 0.9167\n",
            "Epoch 456/900\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.2436 - acc: 0.9083\n",
            "Epoch 457/900\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.2430 - acc: 0.9167\n",
            "Epoch 458/900\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.2432 - acc: 0.9167\n",
            "Epoch 459/900\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2431 - acc: 0.9083\n",
            "Epoch 460/900\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2429 - acc: 0.9167\n",
            "Epoch 461/900\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2427 - acc: 0.9167\n",
            "Epoch 462/900\n",
            "120/120 [==============================] - 0s 117us/step - loss: 0.2421 - acc: 0.9083\n",
            "Epoch 463/900\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2419 - acc: 0.9083\n",
            "Epoch 464/900\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.2417 - acc: 0.9167\n",
            "Epoch 465/900\n",
            "120/120 [==============================] - 0s 115us/step - loss: 0.2412 - acc: 0.9250\n",
            "Epoch 466/900\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2411 - acc: 0.9250\n",
            "Epoch 467/900\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.2408 - acc: 0.9250\n",
            "Epoch 468/900\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2406 - acc: 0.9250\n",
            "Epoch 469/900\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2401 - acc: 0.9250\n",
            "Epoch 470/900\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2401 - acc: 0.9250\n",
            "Epoch 471/900\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2399 - acc: 0.9167\n",
            "Epoch 472/900\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.2396 - acc: 0.9250\n",
            "Epoch 473/900\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2394 - acc: 0.9250\n",
            "Epoch 474/900\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2392 - acc: 0.9250\n",
            "Epoch 475/900\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2387 - acc: 0.9167\n",
            "Epoch 476/900\n",
            "120/120 [==============================] - 0s 129us/step - loss: 0.2384 - acc: 0.9167\n",
            "Epoch 477/900\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.2382 - acc: 0.9167\n",
            "Epoch 478/900\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2379 - acc: 0.9167\n",
            "Epoch 479/900\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2377 - acc: 0.9167\n",
            "Epoch 480/900\n",
            "120/120 [==============================] - 0s 123us/step - loss: 0.2376 - acc: 0.9250\n",
            "Epoch 481/900\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2371 - acc: 0.9083\n",
            "Epoch 482/900\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2370 - acc: 0.9083\n",
            "Epoch 483/900\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2366 - acc: 0.9083\n",
            "Epoch 484/900\n",
            "120/120 [==============================] - 0s 122us/step - loss: 0.2364 - acc: 0.9083\n",
            "Epoch 485/900\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.2362 - acc: 0.9083\n",
            "Epoch 486/900\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.2361 - acc: 0.9083\n",
            "Epoch 487/900\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2361 - acc: 0.9083\n",
            "Epoch 488/900\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2358 - acc: 0.9083\n",
            "Epoch 489/900\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2356 - acc: 0.9083\n",
            "Epoch 490/900\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2355 - acc: 0.9083\n",
            "Epoch 491/900\n",
            "120/120 [==============================] - 0s 120us/step - loss: 0.2353 - acc: 0.9083\n",
            "Epoch 492/900\n",
            "120/120 [==============================] - 0s 123us/step - loss: 0.2350 - acc: 0.9083\n",
            "Epoch 493/900\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2347 - acc: 0.9083\n",
            "Epoch 494/900\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2345 - acc: 0.9083\n",
            "Epoch 495/900\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.2342 - acc: 0.9083\n",
            "Epoch 496/900\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.2341 - acc: 0.9083\n",
            "Epoch 497/900\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2340 - acc: 0.9083\n",
            "Epoch 498/900\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2339 - acc: 0.9083\n",
            "Epoch 499/900\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2337 - acc: 0.9083\n",
            "Epoch 500/900\n",
            "120/120 [==============================] - 0s 128us/step - loss: 0.2335 - acc: 0.9083\n",
            "Epoch 501/900\n",
            "120/120 [==============================] - 0s 124us/step - loss: 0.2335 - acc: 0.9083\n",
            "Epoch 502/900\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2332 - acc: 0.9083\n",
            "Epoch 503/900\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2332 - acc: 0.9083\n",
            "Epoch 504/900\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2330 - acc: 0.9083\n",
            "Epoch 505/900\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2327 - acc: 0.9083\n",
            "Epoch 506/900\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2324 - acc: 0.9083\n",
            "Epoch 507/900\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2324 - acc: 0.9083\n",
            "Epoch 508/900\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2319 - acc: 0.9083\n",
            "Epoch 509/900\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.2320 - acc: 0.9083\n",
            "Epoch 510/900\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.2318 - acc: 0.9083\n",
            "Epoch 511/900\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2318 - acc: 0.9083\n",
            "Epoch 512/900\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2316 - acc: 0.9083\n",
            "Epoch 513/900\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2311 - acc: 0.9083\n",
            "Epoch 514/900\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2310 - acc: 0.9083\n",
            "Epoch 515/900\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2308 - acc: 0.9083\n",
            "Epoch 516/900\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2304 - acc: 0.9083\n",
            "Epoch 517/900\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2304 - acc: 0.9083\n",
            "Epoch 518/900\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2301 - acc: 0.9083\n",
            "Epoch 519/900\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.2300 - acc: 0.9083\n",
            "Epoch 520/900\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.2300 - acc: 0.9083\n",
            "Epoch 521/900\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2298 - acc: 0.9083\n",
            "Epoch 522/900\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2302 - acc: 0.9083\n",
            "Epoch 523/900\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2297 - acc: 0.9083\n",
            "Epoch 524/900\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2295 - acc: 0.9083\n",
            "Epoch 525/900\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2296 - acc: 0.9083\n",
            "Epoch 526/900\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.2295 - acc: 0.9083\n",
            "Epoch 527/900\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2294 - acc: 0.9083\n",
            "Epoch 528/900\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2293 - acc: 0.9083\n",
            "Epoch 529/900\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.2291 - acc: 0.9083\n",
            "Epoch 530/900\n",
            "120/120 [==============================] - 0s 129us/step - loss: 0.2290 - acc: 0.9083\n",
            "Epoch 531/900\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2288 - acc: 0.9083\n",
            "Epoch 532/900\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2286 - acc: 0.9083\n",
            "Epoch 533/900\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.2284 - acc: 0.9083\n",
            "Epoch 534/900\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.2281 - acc: 0.9083\n",
            "Epoch 535/900\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2280 - acc: 0.9083\n",
            "Epoch 536/900\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2279 - acc: 0.9083\n",
            "Epoch 537/900\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2279 - acc: 0.9083\n",
            "Epoch 538/900\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.2275 - acc: 0.9083\n",
            "Epoch 539/900\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.2272 - acc: 0.9083\n",
            "Epoch 540/900\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2272 - acc: 0.9083\n",
            "Epoch 541/900\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2271 - acc: 0.9083\n",
            "Epoch 542/900\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2272 - acc: 0.9083\n",
            "Epoch 543/900\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2271 - acc: 0.9083\n",
            "Epoch 544/900\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2263 - acc: 0.9083\n",
            "Epoch 545/900\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2260 - acc: 0.9083\n",
            "Epoch 546/900\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.2259 - acc: 0.9083\n",
            "Epoch 547/900\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2258 - acc: 0.9083\n",
            "Epoch 548/900\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.2254 - acc: 0.9083\n",
            "Epoch 549/900\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.2253 - acc: 0.9083\n",
            "Epoch 550/900\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2251 - acc: 0.9083\n",
            "Epoch 551/900\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.2254 - acc: 0.9083\n",
            "Epoch 552/900\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2250 - acc: 0.9083\n",
            "Epoch 553/900\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2250 - acc: 0.9083\n",
            "Epoch 554/900\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2247 - acc: 0.9083\n",
            "Epoch 555/900\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2247 - acc: 0.9083\n",
            "Epoch 556/900\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.2248 - acc: 0.9083\n",
            "Epoch 557/900\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2246 - acc: 0.9167\n",
            "Epoch 558/900\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2243 - acc: 0.9083\n",
            "Epoch 559/900\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2242 - acc: 0.9083\n",
            "Epoch 560/900\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2241 - acc: 0.9083\n",
            "Epoch 561/900\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2239 - acc: 0.9083\n",
            "Epoch 562/900\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2237 - acc: 0.9083\n",
            "Epoch 563/900\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2235 - acc: 0.9083\n",
            "Epoch 564/900\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2233 - acc: 0.9083\n",
            "Epoch 565/900\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2234 - acc: 0.9083\n",
            "Epoch 566/900\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2231 - acc: 0.9083\n",
            "Epoch 567/900\n",
            "120/120 [==============================] - 0s 134us/step - loss: 0.2231 - acc: 0.9083\n",
            "Epoch 568/900\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2230 - acc: 0.9083\n",
            "Epoch 569/900\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2227 - acc: 0.9083\n",
            "Epoch 570/900\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2228 - acc: 0.9083\n",
            "Epoch 571/900\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2227 - acc: 0.9083\n",
            "Epoch 572/900\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2227 - acc: 0.9083\n",
            "Epoch 573/900\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2233 - acc: 0.9083\n",
            "Epoch 574/900\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.2232 - acc: 0.9083\n",
            "Epoch 575/900\n",
            "120/120 [==============================] - 0s 71us/step - loss: 0.2233 - acc: 0.9083\n",
            "Epoch 576/900\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2222 - acc: 0.9083\n",
            "Epoch 577/900\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.2219 - acc: 0.9083\n",
            "Epoch 578/900\n",
            "120/120 [==============================] - 0s 128us/step - loss: 0.2216 - acc: 0.9083\n",
            "Epoch 579/900\n",
            "120/120 [==============================] - 0s 141us/step - loss: 0.2216 - acc: 0.9083\n",
            "Epoch 580/900\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2213 - acc: 0.9083\n",
            "Epoch 581/900\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2212 - acc: 0.9083\n",
            "Epoch 582/900\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2212 - acc: 0.9083\n",
            "Epoch 583/900\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2211 - acc: 0.9083\n",
            "Epoch 584/900\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2208 - acc: 0.9083\n",
            "Epoch 585/900\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2208 - acc: 0.9083\n",
            "Epoch 586/900\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2207 - acc: 0.9167\n",
            "Epoch 587/900\n",
            "120/120 [==============================] - 0s 74us/step - loss: 0.2204 - acc: 0.9083\n",
            "Epoch 588/900\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2202 - acc: 0.9083\n",
            "Epoch 589/900\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2202 - acc: 0.9083\n",
            "Epoch 590/900\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2198 - acc: 0.9083\n",
            "Epoch 591/900\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.2197 - acc: 0.9083\n",
            "Epoch 592/900\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2196 - acc: 0.9083\n",
            "Epoch 593/900\n",
            "120/120 [==============================] - 0s 119us/step - loss: 0.2197 - acc: 0.9083\n",
            "Epoch 594/900\n",
            "120/120 [==============================] - 0s 121us/step - loss: 0.2197 - acc: 0.9083\n",
            "Epoch 595/900\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2197 - acc: 0.9083\n",
            "Epoch 596/900\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2193 - acc: 0.9083\n",
            "Epoch 597/900\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2193 - acc: 0.9083\n",
            "Epoch 598/900\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2191 - acc: 0.9083\n",
            "Epoch 599/900\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2191 - acc: 0.9083\n",
            "Epoch 600/900\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2188 - acc: 0.9083\n",
            "Epoch 601/900\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.2187 - acc: 0.9083\n",
            "Epoch 602/900\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2187 - acc: 0.9083\n",
            "Epoch 603/900\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2184 - acc: 0.9083\n",
            "Epoch 604/900\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2182 - acc: 0.9083\n",
            "Epoch 605/900\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2184 - acc: 0.9083\n",
            "Epoch 606/900\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.2181 - acc: 0.9083\n",
            "Epoch 607/900\n",
            "120/120 [==============================] - 0s 144us/step - loss: 0.2179 - acc: 0.9083\n",
            "Epoch 608/900\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2179 - acc: 0.9083\n",
            "Epoch 609/900\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2177 - acc: 0.9083\n",
            "Epoch 610/900\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2177 - acc: 0.9083\n",
            "Epoch 611/900\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2177 - acc: 0.9083\n",
            "Epoch 612/900\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.2177 - acc: 0.9083\n",
            "Epoch 613/900\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.2177 - acc: 0.9083\n",
            "Epoch 614/900\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2177 - acc: 0.9167\n",
            "Epoch 615/900\n",
            "120/120 [==============================] - 0s 115us/step - loss: 0.2176 - acc: 0.9167\n",
            "Epoch 616/900\n",
            "120/120 [==============================] - 0s 120us/step - loss: 0.2175 - acc: 0.9167\n",
            "Epoch 617/900\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2174 - acc: 0.9167\n",
            "Epoch 618/900\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2173 - acc: 0.9083\n",
            "Epoch 619/900\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2171 - acc: 0.9083\n",
            "Epoch 620/900\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2170 - acc: 0.9083\n",
            "Epoch 621/900\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2168 - acc: 0.9083\n",
            "Epoch 622/900\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2167 - acc: 0.9083\n",
            "Epoch 623/900\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2168 - acc: 0.9083\n",
            "Epoch 624/900\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2166 - acc: 0.9083\n",
            "Epoch 625/900\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2165 - acc: 0.9083\n",
            "Epoch 626/900\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2163 - acc: 0.9083\n",
            "Epoch 627/900\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.2162 - acc: 0.9083\n",
            "Epoch 628/900\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2166 - acc: 0.9083\n",
            "Epoch 629/900\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2163 - acc: 0.9167\n",
            "Epoch 630/900\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2161 - acc: 0.9083\n",
            "Epoch 631/900\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2162 - acc: 0.9083\n",
            "Epoch 632/900\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.2161 - acc: 0.9167\n",
            "Epoch 633/900\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.2160 - acc: 0.9167\n",
            "Epoch 634/900\n",
            "120/120 [==============================] - 0s 122us/step - loss: 0.2159 - acc: 0.9167\n",
            "Epoch 635/900\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.2157 - acc: 0.9167\n",
            "Epoch 636/900\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2156 - acc: 0.9083\n",
            "Epoch 637/900\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2155 - acc: 0.9083\n",
            "Epoch 638/900\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2158 - acc: 0.9083\n",
            "Epoch 639/900\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2158 - acc: 0.9083\n",
            "Epoch 640/900\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.2152 - acc: 0.9083\n",
            "Epoch 641/900\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2150 - acc: 0.9083\n",
            "Epoch 642/900\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2151 - acc: 0.9083\n",
            "Epoch 643/900\n",
            "120/120 [==============================] - 0s 212us/step - loss: 0.2149 - acc: 0.9083\n",
            "Epoch 644/900\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.2149 - acc: 0.9083\n",
            "Epoch 645/900\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2153 - acc: 0.9083\n",
            "Epoch 646/900\n",
            "120/120 [==============================] - 0s 76us/step - loss: 0.2154 - acc: 0.9083\n",
            "Epoch 647/900\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2158 - acc: 0.9083\n",
            "Epoch 648/900\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2162 - acc: 0.9083\n",
            "Epoch 649/900\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2162 - acc: 0.9083\n",
            "Epoch 650/900\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.2156 - acc: 0.9083\n",
            "Epoch 651/900\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2147 - acc: 0.9083\n",
            "Epoch 652/900\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2146 - acc: 0.9083\n",
            "Epoch 653/900\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2146 - acc: 0.9083\n",
            "Epoch 654/900\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2150 - acc: 0.9083\n",
            "Epoch 655/900\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2154 - acc: 0.9083\n",
            "Epoch 656/900\n",
            "120/120 [==============================] - 0s 74us/step - loss: 0.2155 - acc: 0.9083\n",
            "Epoch 657/900\n",
            "120/120 [==============================] - 0s 133us/step - loss: 0.2154 - acc: 0.9083\n",
            "Epoch 658/900\n",
            "120/120 [==============================] - 0s 119us/step - loss: 0.2154 - acc: 0.9083\n",
            "Epoch 659/900\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2149 - acc: 0.9167\n",
            "Epoch 660/900\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.2150 - acc: 0.9167\n",
            "Epoch 661/900\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2145 - acc: 0.9167\n",
            "Epoch 662/900\n",
            "120/120 [==============================] - 0s 134us/step - loss: 0.2143 - acc: 0.9083\n",
            "Epoch 663/900\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2136 - acc: 0.9083\n",
            "Epoch 664/900\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2134 - acc: 0.9083\n",
            "Epoch 665/900\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2132 - acc: 0.9083\n",
            "Epoch 666/900\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2133 - acc: 0.9083\n",
            "Epoch 667/900\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2135 - acc: 0.9083\n",
            "Epoch 668/900\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.2133 - acc: 0.9083\n",
            "Epoch 669/900\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2126 - acc: 0.9083\n",
            "Epoch 670/900\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2127 - acc: 0.9083\n",
            "Epoch 671/900\n",
            "120/120 [==============================] - 0s 77us/step - loss: 0.2132 - acc: 0.9083\n",
            "Epoch 672/900\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.2127 - acc: 0.9083\n",
            "Epoch 673/900\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2125 - acc: 0.9083\n",
            "Epoch 674/900\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2127 - acc: 0.9083\n",
            "Epoch 675/900\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2124 - acc: 0.9083\n",
            "Epoch 676/900\n",
            "120/120 [==============================] - 0s 77us/step - loss: 0.2123 - acc: 0.9083\n",
            "Epoch 677/900\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2120 - acc: 0.9083\n",
            "Epoch 678/900\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.2118 - acc: 0.9083\n",
            "Epoch 679/900\n",
            "120/120 [==============================] - 0s 119us/step - loss: 0.2116 - acc: 0.9083\n",
            "Epoch 680/900\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2116 - acc: 0.9083\n",
            "Epoch 681/900\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2115 - acc: 0.9083\n",
            "Epoch 682/900\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2115 - acc: 0.9083\n",
            "Epoch 683/900\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2114 - acc: 0.9083\n",
            "Epoch 684/900\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.2114 - acc: 0.9083\n",
            "Epoch 685/900\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2113 - acc: 0.9083\n",
            "Epoch 686/900\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.2112 - acc: 0.9083\n",
            "Epoch 687/900\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2111 - acc: 0.9083\n",
            "Epoch 688/900\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.2110 - acc: 0.9083\n",
            "Epoch 689/900\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.2112 - acc: 0.9083\n",
            "Epoch 690/900\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2111 - acc: 0.9083\n",
            "Epoch 691/900\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.2109 - acc: 0.9083\n",
            "Epoch 692/900\n",
            "120/120 [==============================] - 0s 69us/step - loss: 0.2108 - acc: 0.9083\n",
            "Epoch 693/900\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2107 - acc: 0.9083\n",
            "Epoch 694/900\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.2106 - acc: 0.9083\n",
            "Epoch 695/900\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2111 - acc: 0.9083\n",
            "Epoch 696/900\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2110 - acc: 0.9083\n",
            "Epoch 697/900\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2110 - acc: 0.9083\n",
            "Epoch 698/900\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2110 - acc: 0.9083\n",
            "Epoch 699/900\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2109 - acc: 0.9083\n",
            "Epoch 700/900\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.2107 - acc: 0.9083\n",
            "Epoch 701/900\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2104 - acc: 0.9083\n",
            "Epoch 702/900\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2101 - acc: 0.9083\n",
            "Epoch 703/900\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2101 - acc: 0.9083\n",
            "Epoch 704/900\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2101 - acc: 0.9083\n",
            "Epoch 705/900\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2103 - acc: 0.9083\n",
            "Epoch 706/900\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2096 - acc: 0.9083\n",
            "Epoch 707/900\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2102 - acc: 0.9083\n",
            "Epoch 708/900\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2099 - acc: 0.9083\n",
            "Epoch 709/900\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2098 - acc: 0.9083\n",
            "Epoch 710/900\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2094 - acc: 0.9083\n",
            "Epoch 711/900\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2093 - acc: 0.9083\n",
            "Epoch 712/900\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2094 - acc: 0.9083\n",
            "Epoch 713/900\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2094 - acc: 0.9083\n",
            "Epoch 714/900\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.2094 - acc: 0.9083\n",
            "Epoch 715/900\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2094 - acc: 0.9083\n",
            "Epoch 716/900\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2093 - acc: 0.9083\n",
            "Epoch 717/900\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2092 - acc: 0.9083\n",
            "Epoch 718/900\n",
            "120/120 [==============================] - 0s 74us/step - loss: 0.2089 - acc: 0.9083\n",
            "Epoch 719/900\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2091 - acc: 0.9083\n",
            "Epoch 720/900\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.2085 - acc: 0.9083\n",
            "Epoch 721/900\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.2086 - acc: 0.9083\n",
            "Epoch 722/900\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2087 - acc: 0.9083\n",
            "Epoch 723/900\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2084 - acc: 0.9083\n",
            "Epoch 724/900\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2083 - acc: 0.9083\n",
            "Epoch 725/900\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2082 - acc: 0.9083\n",
            "Epoch 726/900\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2082 - acc: 0.9083\n",
            "Epoch 727/900\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2081 - acc: 0.9083\n",
            "Epoch 728/900\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2081 - acc: 0.9083\n",
            "Epoch 729/900\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2082 - acc: 0.9083\n",
            "Epoch 730/900\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2078 - acc: 0.9083\n",
            "Epoch 731/900\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.2078 - acc: 0.9083\n",
            "Epoch 732/900\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2076 - acc: 0.9083\n",
            "Epoch 733/900\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2075 - acc: 0.9083\n",
            "Epoch 734/900\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2078 - acc: 0.9083\n",
            "Epoch 735/900\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2075 - acc: 0.9083\n",
            "Epoch 736/900\n",
            "120/120 [==============================] - 0s 129us/step - loss: 0.2074 - acc: 0.9083\n",
            "Epoch 737/900\n",
            "120/120 [==============================] - 0s 165us/step - loss: 0.2075 - acc: 0.9083\n",
            "Epoch 738/900\n",
            "120/120 [==============================] - 0s 124us/step - loss: 0.2074 - acc: 0.9083\n",
            "Epoch 739/900\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2074 - acc: 0.9083\n",
            "Epoch 740/900\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2072 - acc: 0.9083\n",
            "Epoch 741/900\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.2072 - acc: 0.9083\n",
            "Epoch 742/900\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.2073 - acc: 0.9083\n",
            "Epoch 743/900\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2073 - acc: 0.9083\n",
            "Epoch 744/900\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.2076 - acc: 0.9083\n",
            "Epoch 745/900\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2077 - acc: 0.9167\n",
            "Epoch 746/900\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2072 - acc: 0.9083\n",
            "Epoch 747/900\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2074 - acc: 0.9167\n",
            "Epoch 748/900\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2074 - acc: 0.9083\n",
            "Epoch 749/900\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.2073 - acc: 0.9083\n",
            "Epoch 750/900\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.2072 - acc: 0.9167\n",
            "Epoch 751/900\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2072 - acc: 0.9167\n",
            "Epoch 752/900\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2072 - acc: 0.9083\n",
            "Epoch 753/900\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2070 - acc: 0.9167\n",
            "Epoch 754/900\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2069 - acc: 0.9083\n",
            "Epoch 755/900\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2068 - acc: 0.9167\n",
            "Epoch 756/900\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2069 - acc: 0.9167\n",
            "Epoch 757/900\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2069 - acc: 0.9083\n",
            "Epoch 758/900\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2065 - acc: 0.9083\n",
            "Epoch 759/900\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.2066 - acc: 0.9167\n",
            "Epoch 760/900\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.2065 - acc: 0.9167\n",
            "Epoch 761/900\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2064 - acc: 0.9083\n",
            "Epoch 762/900\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2062 - acc: 0.9083\n",
            "Epoch 763/900\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2062 - acc: 0.9167\n",
            "Epoch 764/900\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2062 - acc: 0.9083\n",
            "Epoch 765/900\n",
            "120/120 [==============================] - 0s 77us/step - loss: 0.2062 - acc: 0.9167\n",
            "Epoch 766/900\n",
            "120/120 [==============================] - 0s 74us/step - loss: 0.2059 - acc: 0.9083\n",
            "Epoch 767/900\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2059 - acc: 0.9083\n",
            "Epoch 768/900\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2059 - acc: 0.9083\n",
            "Epoch 769/900\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2059 - acc: 0.9167\n",
            "Epoch 770/900\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2064 - acc: 0.9167\n",
            "Epoch 771/900\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2059 - acc: 0.9083\n",
            "Epoch 772/900\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2059 - acc: 0.9167\n",
            "Epoch 773/900\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.2059 - acc: 0.9083\n",
            "Epoch 774/900\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.2058 - acc: 0.9167\n",
            "Epoch 775/900\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2061 - acc: 0.9083\n",
            "Epoch 776/900\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2057 - acc: 0.9083\n",
            "Epoch 777/900\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2055 - acc: 0.9167\n",
            "Epoch 778/900\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.2056 - acc: 0.9167\n",
            "Epoch 779/900\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2057 - acc: 0.9083\n",
            "Epoch 780/900\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2057 - acc: 0.9083\n",
            "Epoch 781/900\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2054 - acc: 0.9167\n",
            "Epoch 782/900\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.2053 - acc: 0.9167\n",
            "Epoch 783/900\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.2055 - acc: 0.9083\n",
            "Epoch 784/900\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2054 - acc: 0.9083\n",
            "Epoch 785/900\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2056 - acc: 0.9083\n",
            "Epoch 786/900\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2056 - acc: 0.9083\n",
            "Epoch 787/900\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.2054 - acc: 0.9083\n",
            "Epoch 788/900\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2051 - acc: 0.9167\n",
            "Epoch 789/900\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2050 - acc: 0.9083\n",
            "Epoch 790/900\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2050 - acc: 0.9167\n",
            "Epoch 791/900\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2051 - acc: 0.9167\n",
            "Epoch 792/900\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.2050 - acc: 0.9167\n",
            "Epoch 793/900\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2051 - acc: 0.9167\n",
            "Epoch 794/900\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2052 - acc: 0.9083\n",
            "Epoch 795/900\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2052 - acc: 0.9167\n",
            "Epoch 796/900\n",
            "120/120 [==============================] - 0s 119us/step - loss: 0.2045 - acc: 0.9083\n",
            "Epoch 797/900\n",
            "120/120 [==============================] - 0s 76us/step - loss: 0.2044 - acc: 0.9083\n",
            "Epoch 798/900\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.2046 - acc: 0.9083\n",
            "Epoch 799/900\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2048 - acc: 0.9167\n",
            "Epoch 800/900\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2042 - acc: 0.9083\n",
            "Epoch 801/900\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2042 - acc: 0.9083\n",
            "Epoch 802/900\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2040 - acc: 0.9083\n",
            "Epoch 803/900\n",
            "120/120 [==============================] - 0s 153us/step - loss: 0.2039 - acc: 0.9083\n",
            "Epoch 804/900\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.2039 - acc: 0.9083\n",
            "Epoch 805/900\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.2040 - acc: 0.9083\n",
            "Epoch 806/900\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2041 - acc: 0.9083\n",
            "Epoch 807/900\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2040 - acc: 0.9083\n",
            "Epoch 808/900\n",
            "120/120 [==============================] - 0s 77us/step - loss: 0.2041 - acc: 0.9083\n",
            "Epoch 809/900\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2040 - acc: 0.9083\n",
            "Epoch 810/900\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.2038 - acc: 0.9083\n",
            "Epoch 811/900\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2043 - acc: 0.9083\n",
            "Epoch 812/900\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2040 - acc: 0.9083\n",
            "Epoch 813/900\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2037 - acc: 0.9083\n",
            "Epoch 814/900\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.2036 - acc: 0.9083\n",
            "Epoch 815/900\n",
            "120/120 [==============================] - 0s 128us/step - loss: 0.2037 - acc: 0.9083\n",
            "Epoch 816/900\n",
            "120/120 [==============================] - 0s 140us/step - loss: 0.2037 - acc: 0.9083\n",
            "Epoch 817/900\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.2038 - acc: 0.9167\n",
            "Epoch 818/900\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2035 - acc: 0.9083\n",
            "Epoch 819/900\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2036 - acc: 0.9083\n",
            "Epoch 820/900\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2034 - acc: 0.9083\n",
            "Epoch 821/900\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2033 - acc: 0.9083\n",
            "Epoch 822/900\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2033 - acc: 0.9083\n",
            "Epoch 823/900\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2032 - acc: 0.9083\n",
            "Epoch 824/900\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2032 - acc: 0.9083\n",
            "Epoch 825/900\n",
            "120/120 [==============================] - 0s 129us/step - loss: 0.2032 - acc: 0.9083\n",
            "Epoch 826/900\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2032 - acc: 0.9083\n",
            "Epoch 827/900\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2030 - acc: 0.9083\n",
            "Epoch 828/900\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2031 - acc: 0.9083\n",
            "Epoch 829/900\n",
            "120/120 [==============================] - 0s 125us/step - loss: 0.2029 - acc: 0.9083\n",
            "Epoch 830/900\n",
            "120/120 [==============================] - 0s 76us/step - loss: 0.2031 - acc: 0.9083\n",
            "Epoch 831/900\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2028 - acc: 0.9083\n",
            "Epoch 832/900\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2028 - acc: 0.9083\n",
            "Epoch 833/900\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.2028 - acc: 0.9083\n",
            "Epoch 834/900\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2028 - acc: 0.9083\n",
            "Epoch 835/900\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2029 - acc: 0.9083\n",
            "Epoch 836/900\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2030 - acc: 0.9083\n",
            "Epoch 837/900\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.2033 - acc: 0.9167\n",
            "Epoch 838/900\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.2028 - acc: 0.9083\n",
            "Epoch 839/900\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.2028 - acc: 0.9083\n",
            "Epoch 840/900\n",
            "120/120 [==============================] - 0s 121us/step - loss: 0.2028 - acc: 0.9083\n",
            "Epoch 841/900\n",
            "120/120 [==============================] - 0s 127us/step - loss: 0.2029 - acc: 0.9083\n",
            "Epoch 842/900\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2026 - acc: 0.9083\n",
            "Epoch 843/900\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2026 - acc: 0.9083\n",
            "Epoch 844/900\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2025 - acc: 0.9083\n",
            "Epoch 845/900\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2025 - acc: 0.9083\n",
            "Epoch 846/900\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2029 - acc: 0.9083\n",
            "Epoch 847/900\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2032 - acc: 0.9167\n",
            "Epoch 848/900\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.2032 - acc: 0.9167\n",
            "Epoch 849/900\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2032 - acc: 0.9167\n",
            "Epoch 850/900\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2030 - acc: 0.9167\n",
            "Epoch 851/900\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2029 - acc: 0.9167\n",
            "Epoch 852/900\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2027 - acc: 0.9167\n",
            "Epoch 853/900\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.2024 - acc: 0.9083\n",
            "Epoch 854/900\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.2023 - acc: 0.9083\n",
            "Epoch 855/900\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2021 - acc: 0.9083\n",
            "Epoch 856/900\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.2024 - acc: 0.9083\n",
            "Epoch 857/900\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.2024 - acc: 0.9083\n",
            "Epoch 858/900\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.2024 - acc: 0.9167\n",
            "Epoch 859/900\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2025 - acc: 0.9083\n",
            "Epoch 860/900\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2025 - acc: 0.9083\n",
            "Epoch 861/900\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2025 - acc: 0.9083\n",
            "Epoch 862/900\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2026 - acc: 0.9083\n",
            "Epoch 863/900\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2023 - acc: 0.9083\n",
            "Epoch 864/900\n",
            "120/120 [==============================] - 0s 126us/step - loss: 0.2020 - acc: 0.9083\n",
            "Epoch 865/900\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2018 - acc: 0.9083\n",
            "Epoch 866/900\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2022 - acc: 0.9083\n",
            "Epoch 867/900\n",
            "120/120 [==============================] - 0s 152us/step - loss: 0.2024 - acc: 0.9167\n",
            "Epoch 868/900\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2026 - acc: 0.9167\n",
            "Epoch 869/900\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2029 - acc: 0.9167\n",
            "Epoch 870/900\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2029 - acc: 0.9167\n",
            "Epoch 871/900\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2025 - acc: 0.9167\n",
            "Epoch 872/900\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.2021 - acc: 0.9083\n",
            "Epoch 873/900\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2021 - acc: 0.9167\n",
            "Epoch 874/900\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2023 - acc: 0.9167\n",
            "Epoch 875/900\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2024 - acc: 0.9167\n",
            "Epoch 876/900\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2023 - acc: 0.9167\n",
            "Epoch 877/900\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.2019 - acc: 0.9167\n",
            "Epoch 878/900\n",
            "120/120 [==============================] - 0s 129us/step - loss: 0.2018 - acc: 0.9167\n",
            "Epoch 879/900\n",
            "120/120 [==============================] - 0s 133us/step - loss: 0.2016 - acc: 0.9083\n",
            "Epoch 880/900\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2016 - acc: 0.9167\n",
            "Epoch 881/900\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2014 - acc: 0.9083\n",
            "Epoch 882/900\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2011 - acc: 0.9083\n",
            "Epoch 883/900\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2010 - acc: 0.9083\n",
            "Epoch 884/900\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2015 - acc: 0.9083\n",
            "Epoch 885/900\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2011 - acc: 0.9083\n",
            "Epoch 886/900\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2011 - acc: 0.9083\n",
            "Epoch 887/900\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2010 - acc: 0.9083\n",
            "Epoch 888/900\n",
            "120/120 [==============================] - 0s 115us/step - loss: 0.2009 - acc: 0.9083\n",
            "Epoch 889/900\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2009 - acc: 0.9083\n",
            "Epoch 890/900\n",
            "120/120 [==============================] - 0s 119us/step - loss: 0.2008 - acc: 0.9083\n",
            "Epoch 891/900\n",
            "120/120 [==============================] - 0s 172us/step - loss: 0.2009 - acc: 0.9083\n",
            "Epoch 892/900\n",
            "120/120 [==============================] - 0s 136us/step - loss: 0.2009 - acc: 0.9083\n",
            "Epoch 893/900\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2010 - acc: 0.9083\n",
            "Epoch 894/900\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.2012 - acc: 0.9083\n",
            "Epoch 895/900\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.2018 - acc: 0.9083\n",
            "Epoch 896/900\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2010 - acc: 0.9167\n",
            "Epoch 897/900\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2013 - acc: 0.9167\n",
            "Epoch 898/900\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.2004 - acc: 0.9083\n",
            "Epoch 899/900\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2003 - acc: 0.9083\n",
            "Epoch 900/900\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2004 - acc: 0.9083\n",
            "60/60 [==============================] - 1s 11ms/step\n",
            "\n",
            "acc: 88.33%\n",
            "[[21  3  1]\n",
            " [ 1 17  1]\n",
            " [ 1  0 15]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.84      0.87        25\n",
            "           1       0.85      0.89      0.87        19\n",
            "           2       0.88      0.94      0.91        16\n",
            "\n",
            "    accuracy                           0.88        60\n",
            "   macro avg       0.88      0.89      0.89        60\n",
            "weighted avg       0.88      0.88      0.88        60\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_174 (Dense)            (None, 10)                30        \n",
            "_________________________________________________________________\n",
            "dense_175 (Dense)            (None, 20)                220       \n",
            "_________________________________________________________________\n",
            "dense_176 (Dense)            (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_177 (Dense)            (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_178 (Dense)            (None, 3)                 63        \n",
            "=================================================================\n",
            "Total params: 1,153\n",
            "Trainable params: 1,153\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/1000\n",
            "120/120 [==============================] - 2s 14ms/step - loss: 1.1528 - acc: 0.3167\n",
            "Epoch 2/1000\n",
            "120/120 [==============================] - 0s 108us/step - loss: 1.1460 - acc: 0.3167\n",
            "Epoch 3/1000\n",
            "120/120 [==============================] - 0s 84us/step - loss: 1.1401 - acc: 0.3167\n",
            "Epoch 4/1000\n",
            "120/120 [==============================] - 0s 95us/step - loss: 1.1340 - acc: 0.3167\n",
            "Epoch 5/1000\n",
            "120/120 [==============================] - 0s 83us/step - loss: 1.1277 - acc: 0.3167\n",
            "Epoch 6/1000\n",
            "120/120 [==============================] - 0s 86us/step - loss: 1.1214 - acc: 0.3417\n",
            "Epoch 7/1000\n",
            "120/120 [==============================] - 0s 83us/step - loss: 1.1159 - acc: 0.3500\n",
            "Epoch 8/1000\n",
            "120/120 [==============================] - 0s 80us/step - loss: 1.1106 - acc: 0.3500\n",
            "Epoch 9/1000\n",
            "120/120 [==============================] - 0s 81us/step - loss: 1.1047 - acc: 0.3583\n",
            "Epoch 10/1000\n",
            "120/120 [==============================] - 0s 81us/step - loss: 1.0990 - acc: 0.3583\n",
            "Epoch 11/1000\n",
            "120/120 [==============================] - 0s 87us/step - loss: 1.0935 - acc: 0.3583\n",
            "Epoch 12/1000\n",
            "120/120 [==============================] - 0s 80us/step - loss: 1.0879 - acc: 0.3583\n",
            "Epoch 13/1000\n",
            "120/120 [==============================] - 0s 81us/step - loss: 1.0822 - acc: 0.3833\n",
            "Epoch 14/1000\n",
            "120/120 [==============================] - 0s 83us/step - loss: 1.0770 - acc: 0.3833\n",
            "Epoch 15/1000\n",
            "120/120 [==============================] - 0s 79us/step - loss: 1.0719 - acc: 0.4333\n",
            "Epoch 16/1000\n",
            "120/120 [==============================] - 0s 93us/step - loss: 1.0666 - acc: 0.4417\n",
            "Epoch 17/1000\n",
            "120/120 [==============================] - 0s 94us/step - loss: 1.0617 - acc: 0.4500\n",
            "Epoch 18/1000\n",
            "120/120 [==============================] - 0s 98us/step - loss: 1.0567 - acc: 0.4750\n",
            "Epoch 19/1000\n",
            "120/120 [==============================] - 0s 116us/step - loss: 1.0520 - acc: 0.5250\n",
            "Epoch 20/1000\n",
            "120/120 [==============================] - 0s 101us/step - loss: 1.0474 - acc: 0.5333\n",
            "Epoch 21/1000\n",
            "120/120 [==============================] - 0s 87us/step - loss: 1.0429 - acc: 0.5583\n",
            "Epoch 22/1000\n",
            "120/120 [==============================] - 0s 102us/step - loss: 1.0389 - acc: 0.6333\n",
            "Epoch 23/1000\n",
            "120/120 [==============================] - 0s 108us/step - loss: 1.0351 - acc: 0.6417\n",
            "Epoch 24/1000\n",
            "120/120 [==============================] - 0s 89us/step - loss: 1.0313 - acc: 0.6583\n",
            "Epoch 25/1000\n",
            "120/120 [==============================] - 0s 95us/step - loss: 1.0275 - acc: 0.6583\n",
            "Epoch 26/1000\n",
            "120/120 [==============================] - 0s 85us/step - loss: 1.0236 - acc: 0.7000\n",
            "Epoch 27/1000\n",
            "120/120 [==============================] - 0s 83us/step - loss: 1.0199 - acc: 0.6917\n",
            "Epoch 28/1000\n",
            "120/120 [==============================] - 0s 87us/step - loss: 1.0162 - acc: 0.7000\n",
            "Epoch 29/1000\n",
            "120/120 [==============================] - 0s 110us/step - loss: 1.0129 - acc: 0.7333\n",
            "Epoch 30/1000\n",
            "120/120 [==============================] - 0s 92us/step - loss: 1.0092 - acc: 0.7583\n",
            "Epoch 31/1000\n",
            "120/120 [==============================] - 0s 99us/step - loss: 1.0052 - acc: 0.7667\n",
            "Epoch 32/1000\n",
            "120/120 [==============================] - 0s 83us/step - loss: 1.0017 - acc: 0.7833\n",
            "Epoch 33/1000\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.9981 - acc: 0.7833\n",
            "Epoch 34/1000\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.9948 - acc: 0.8000\n",
            "Epoch 35/1000\n",
            "120/120 [==============================] - 0s 117us/step - loss: 0.9912 - acc: 0.8167\n",
            "Epoch 36/1000\n",
            "120/120 [==============================] - 0s 115us/step - loss: 0.9875 - acc: 0.8083\n",
            "Epoch 37/1000\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.9840 - acc: 0.8083\n",
            "Epoch 38/1000\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.9804 - acc: 0.8083\n",
            "Epoch 39/1000\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.9768 - acc: 0.8167\n",
            "Epoch 40/1000\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.9733 - acc: 0.8167\n",
            "Epoch 41/1000\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.9697 - acc: 0.8083\n",
            "Epoch 42/1000\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.9660 - acc: 0.8083\n",
            "Epoch 43/1000\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.9626 - acc: 0.8250\n",
            "Epoch 44/1000\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.9592 - acc: 0.8250\n",
            "Epoch 45/1000\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.9556 - acc: 0.8250\n",
            "Epoch 46/1000\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.9522 - acc: 0.8250\n",
            "Epoch 47/1000\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.9489 - acc: 0.8333\n",
            "Epoch 48/1000\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.9452 - acc: 0.8333\n",
            "Epoch 49/1000\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.9420 - acc: 0.8333\n",
            "Epoch 50/1000\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.9388 - acc: 0.8333\n",
            "Epoch 51/1000\n",
            "120/120 [==============================] - 0s 131us/step - loss: 0.9354 - acc: 0.8333\n",
            "Epoch 52/1000\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.9320 - acc: 0.8333\n",
            "Epoch 53/1000\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.9285 - acc: 0.8333\n",
            "Epoch 54/1000\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.9252 - acc: 0.8333\n",
            "Epoch 55/1000\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.9215 - acc: 0.8417\n",
            "Epoch 56/1000\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.9177 - acc: 0.8500\n",
            "Epoch 57/1000\n",
            "120/120 [==============================] - 0s 68us/step - loss: 0.9143 - acc: 0.8417\n",
            "Epoch 58/1000\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.9109 - acc: 0.8500\n",
            "Epoch 59/1000\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.9071 - acc: 0.8500\n",
            "Epoch 60/1000\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.9032 - acc: 0.8500\n",
            "Epoch 61/1000\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.8992 - acc: 0.8500\n",
            "Epoch 62/1000\n",
            "120/120 [==============================] - 0s 122us/step - loss: 0.8959 - acc: 0.8417\n",
            "Epoch 63/1000\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.8922 - acc: 0.8417\n",
            "Epoch 64/1000\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.8883 - acc: 0.8417\n",
            "Epoch 65/1000\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.8847 - acc: 0.8417\n",
            "Epoch 66/1000\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.8811 - acc: 0.8417\n",
            "Epoch 67/1000\n",
            "120/120 [==============================] - 0s 124us/step - loss: 0.8774 - acc: 0.8417\n",
            "Epoch 68/1000\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.8736 - acc: 0.8417\n",
            "Epoch 69/1000\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.8696 - acc: 0.8417\n",
            "Epoch 70/1000\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.8653 - acc: 0.8417\n",
            "Epoch 71/1000\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.8615 - acc: 0.8500\n",
            "Epoch 72/1000\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.8580 - acc: 0.8500\n",
            "Epoch 73/1000\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.8542 - acc: 0.8500\n",
            "Epoch 74/1000\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.8505 - acc: 0.8417\n",
            "Epoch 75/1000\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.8465 - acc: 0.8500\n",
            "Epoch 76/1000\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.8424 - acc: 0.8500\n",
            "Epoch 77/1000\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.8385 - acc: 0.8500\n",
            "Epoch 78/1000\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.8344 - acc: 0.8500\n",
            "Epoch 79/1000\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.8304 - acc: 0.8500\n",
            "Epoch 80/1000\n",
            "120/120 [==============================] - 0s 115us/step - loss: 0.8267 - acc: 0.8500\n",
            "Epoch 81/1000\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.8229 - acc: 0.8500\n",
            "Epoch 82/1000\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.8188 - acc: 0.8500\n",
            "Epoch 83/1000\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.8145 - acc: 0.8500\n",
            "Epoch 84/1000\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.8100 - acc: 0.8500\n",
            "Epoch 85/1000\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.8056 - acc: 0.8500\n",
            "Epoch 86/1000\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.8015 - acc: 0.8500\n",
            "Epoch 87/1000\n",
            "120/120 [==============================] - 0s 76us/step - loss: 0.7972 - acc: 0.8500\n",
            "Epoch 88/1000\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.7933 - acc: 0.8500\n",
            "Epoch 89/1000\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.7892 - acc: 0.8500\n",
            "Epoch 90/1000\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.7849 - acc: 0.8500\n",
            "Epoch 91/1000\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.7806 - acc: 0.8583\n",
            "Epoch 92/1000\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.7762 - acc: 0.8500\n",
            "Epoch 93/1000\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.7722 - acc: 0.8500\n",
            "Epoch 94/1000\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.7682 - acc: 0.8583\n",
            "Epoch 95/1000\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.7640 - acc: 0.8583\n",
            "Epoch 96/1000\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.7593 - acc: 0.8500\n",
            "Epoch 97/1000\n",
            "120/120 [==============================] - 0s 115us/step - loss: 0.7551 - acc: 0.8583\n",
            "Epoch 98/1000\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.7508 - acc: 0.8583\n",
            "Epoch 99/1000\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.7467 - acc: 0.8500\n",
            "Epoch 100/1000\n",
            "120/120 [==============================] - 0s 124us/step - loss: 0.7421 - acc: 0.8583\n",
            "Epoch 101/1000\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.7380 - acc: 0.8583\n",
            "Epoch 102/1000\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.7337 - acc: 0.8583\n",
            "Epoch 103/1000\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.7294 - acc: 0.8667\n",
            "Epoch 104/1000\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.7250 - acc: 0.8583\n",
            "Epoch 105/1000\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.7208 - acc: 0.8583\n",
            "Epoch 106/1000\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.7163 - acc: 0.8583\n",
            "Epoch 107/1000\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.7119 - acc: 0.8583\n",
            "Epoch 108/1000\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.7076 - acc: 0.8583\n",
            "Epoch 109/1000\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.7033 - acc: 0.8583\n",
            "Epoch 110/1000\n",
            "120/120 [==============================] - 0s 73us/step - loss: 0.6988 - acc: 0.8667\n",
            "Epoch 111/1000\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.6945 - acc: 0.8750\n",
            "Epoch 112/1000\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.6901 - acc: 0.8750\n",
            "Epoch 113/1000\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.6855 - acc: 0.8750\n",
            "Epoch 114/1000\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.6812 - acc: 0.8750\n",
            "Epoch 115/1000\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.6770 - acc: 0.8750\n",
            "Epoch 116/1000\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.6727 - acc: 0.8750\n",
            "Epoch 117/1000\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.6681 - acc: 0.8750\n",
            "Epoch 118/1000\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.6638 - acc: 0.8750\n",
            "Epoch 119/1000\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.6592 - acc: 0.8750\n",
            "Epoch 120/1000\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.6552 - acc: 0.8750\n",
            "Epoch 121/1000\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.6511 - acc: 0.8750\n",
            "Epoch 122/1000\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.6469 - acc: 0.8750\n",
            "Epoch 123/1000\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.6425 - acc: 0.8750\n",
            "Epoch 124/1000\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.6386 - acc: 0.8750\n",
            "Epoch 125/1000\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.6345 - acc: 0.8750\n",
            "Epoch 126/1000\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.6300 - acc: 0.8750\n",
            "Epoch 127/1000\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.6258 - acc: 0.8667\n",
            "Epoch 128/1000\n",
            "120/120 [==============================] - 0s 138us/step - loss: 0.6217 - acc: 0.8750\n",
            "Epoch 129/1000\n",
            "120/120 [==============================] - 0s 140us/step - loss: 0.6173 - acc: 0.8750\n",
            "Epoch 130/1000\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.6131 - acc: 0.8750\n",
            "Epoch 131/1000\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.6089 - acc: 0.8750\n",
            "Epoch 132/1000\n",
            "120/120 [==============================] - 0s 115us/step - loss: 0.6050 - acc: 0.8750\n",
            "Epoch 133/1000\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.6011 - acc: 0.8833\n",
            "Epoch 134/1000\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.5968 - acc: 0.8833\n",
            "Epoch 135/1000\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.5926 - acc: 0.8750\n",
            "Epoch 136/1000\n",
            "120/120 [==============================] - 0s 117us/step - loss: 0.5886 - acc: 0.8750\n",
            "Epoch 137/1000\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.5845 - acc: 0.8750\n",
            "Epoch 138/1000\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.5806 - acc: 0.8750\n",
            "Epoch 139/1000\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.5765 - acc: 0.8833\n",
            "Epoch 140/1000\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.5722 - acc: 0.8750\n",
            "Epoch 141/1000\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.5682 - acc: 0.8833\n",
            "Epoch 142/1000\n",
            "120/120 [==============================] - 0s 77us/step - loss: 0.5641 - acc: 0.8833\n",
            "Epoch 143/1000\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.5602 - acc: 0.8833\n",
            "Epoch 144/1000\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.5561 - acc: 0.8750\n",
            "Epoch 145/1000\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.5520 - acc: 0.8750\n",
            "Epoch 146/1000\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.5479 - acc: 0.8750\n",
            "Epoch 147/1000\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.5438 - acc: 0.8750\n",
            "Epoch 148/1000\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.5396 - acc: 0.8750\n",
            "Epoch 149/1000\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.5355 - acc: 0.8833\n",
            "Epoch 150/1000\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.5316 - acc: 0.8917\n",
            "Epoch 151/1000\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.5278 - acc: 0.8917\n",
            "Epoch 152/1000\n",
            "120/120 [==============================] - 0s 134us/step - loss: 0.5241 - acc: 0.8917\n",
            "Epoch 153/1000\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.5205 - acc: 0.9000\n",
            "Epoch 154/1000\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.5165 - acc: 0.9000\n",
            "Epoch 155/1000\n",
            "120/120 [==============================] - 0s 117us/step - loss: 0.5125 - acc: 0.8917\n",
            "Epoch 156/1000\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.5086 - acc: 0.8917\n",
            "Epoch 157/1000\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.5051 - acc: 0.8917\n",
            "Epoch 158/1000\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.5012 - acc: 0.8917\n",
            "Epoch 159/1000\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.4977 - acc: 0.8917\n",
            "Epoch 160/1000\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.4945 - acc: 0.9000\n",
            "Epoch 161/1000\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.4909 - acc: 0.9000\n",
            "Epoch 162/1000\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.4873 - acc: 0.9000\n",
            "Epoch 163/1000\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.4839 - acc: 0.9000\n",
            "Epoch 164/1000\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.4802 - acc: 0.8917\n",
            "Epoch 165/1000\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.4769 - acc: 0.9000\n",
            "Epoch 166/1000\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.4733 - acc: 0.8917\n",
            "Epoch 167/1000\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.4696 - acc: 0.8917\n",
            "Epoch 168/1000\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.4663 - acc: 0.8917\n",
            "Epoch 169/1000\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.4628 - acc: 0.9000\n",
            "Epoch 170/1000\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.4590 - acc: 0.8917\n",
            "Epoch 171/1000\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.4557 - acc: 0.9000\n",
            "Epoch 172/1000\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.4526 - acc: 0.9000\n",
            "Epoch 173/1000\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.4494 - acc: 0.8917\n",
            "Epoch 174/1000\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.4464 - acc: 0.8917\n",
            "Epoch 175/1000\n",
            "120/120 [==============================] - 0s 127us/step - loss: 0.4432 - acc: 0.8917\n",
            "Epoch 176/1000\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.4402 - acc: 0.8917\n",
            "Epoch 177/1000\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.4371 - acc: 0.9000\n",
            "Epoch 178/1000\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.4342 - acc: 0.9000\n",
            "Epoch 179/1000\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.4312 - acc: 0.8917\n",
            "Epoch 180/1000\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.4284 - acc: 0.8917\n",
            "Epoch 181/1000\n",
            "120/120 [==============================] - 0s 155us/step - loss: 0.4253 - acc: 0.8917\n",
            "Epoch 182/1000\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.4225 - acc: 0.8917\n",
            "Epoch 183/1000\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.4196 - acc: 0.8917\n",
            "Epoch 184/1000\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.4167 - acc: 0.8917\n",
            "Epoch 185/1000\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.4141 - acc: 0.8917\n",
            "Epoch 186/1000\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.4112 - acc: 0.8917\n",
            "Epoch 187/1000\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.4083 - acc: 0.8917\n",
            "Epoch 188/1000\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.4056 - acc: 0.8917\n",
            "Epoch 189/1000\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.4029 - acc: 0.8917\n",
            "Epoch 190/1000\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.4003 - acc: 0.8917\n",
            "Epoch 191/1000\n",
            "120/120 [==============================] - 0s 77us/step - loss: 0.3979 - acc: 0.8833\n",
            "Epoch 192/1000\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.3955 - acc: 0.8917\n",
            "Epoch 193/1000\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.3929 - acc: 0.8833\n",
            "Epoch 194/1000\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.3902 - acc: 0.8833\n",
            "Epoch 195/1000\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.3877 - acc: 0.8833\n",
            "Epoch 196/1000\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.3852 - acc: 0.8833\n",
            "Epoch 197/1000\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.3830 - acc: 0.8833\n",
            "Epoch 198/1000\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.3807 - acc: 0.8833\n",
            "Epoch 199/1000\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.3784 - acc: 0.8833\n",
            "Epoch 200/1000\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.3761 - acc: 0.8833\n",
            "Epoch 201/1000\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.3741 - acc: 0.8833\n",
            "Epoch 202/1000\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.3720 - acc: 0.8833\n",
            "Epoch 203/1000\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.3698 - acc: 0.8833\n",
            "Epoch 204/1000\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.3673 - acc: 0.8833\n",
            "Epoch 205/1000\n",
            "120/120 [==============================] - 0s 127us/step - loss: 0.3652 - acc: 0.8833\n",
            "Epoch 206/1000\n",
            "120/120 [==============================] - 0s 124us/step - loss: 0.3629 - acc: 0.8833\n",
            "Epoch 207/1000\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.3610 - acc: 0.8667\n",
            "Epoch 208/1000\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.3588 - acc: 0.8667\n",
            "Epoch 209/1000\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.3568 - acc: 0.8667\n",
            "Epoch 210/1000\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.3548 - acc: 0.8667\n",
            "Epoch 211/1000\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.3531 - acc: 0.8667\n",
            "Epoch 212/1000\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.3516 - acc: 0.8750\n",
            "Epoch 213/1000\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.3501 - acc: 0.8833\n",
            "Epoch 214/1000\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.3484 - acc: 0.8833\n",
            "Epoch 215/1000\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.3465 - acc: 0.8833\n",
            "Epoch 216/1000\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.3447 - acc: 0.8833\n",
            "Epoch 217/1000\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.3429 - acc: 0.8833\n",
            "Epoch 218/1000\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.3411 - acc: 0.8833\n",
            "Epoch 219/1000\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.3392 - acc: 0.8833\n",
            "Epoch 220/1000\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.3376 - acc: 0.8833\n",
            "Epoch 221/1000\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.3360 - acc: 0.8833\n",
            "Epoch 222/1000\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.3343 - acc: 0.8833\n",
            "Epoch 223/1000\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.3327 - acc: 0.8833\n",
            "Epoch 224/1000\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.3313 - acc: 0.8833\n",
            "Epoch 225/1000\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.3298 - acc: 0.8833\n",
            "Epoch 226/1000\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.3282 - acc: 0.8833\n",
            "Epoch 227/1000\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.3269 - acc: 0.8750\n",
            "Epoch 228/1000\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.3255 - acc: 0.8833\n",
            "Epoch 229/1000\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.3242 - acc: 0.8833\n",
            "Epoch 230/1000\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.3230 - acc: 0.8833\n",
            "Epoch 231/1000\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.3217 - acc: 0.8833\n",
            "Epoch 232/1000\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.3204 - acc: 0.8833\n",
            "Epoch 233/1000\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.3188 - acc: 0.8833\n",
            "Epoch 234/1000\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.3175 - acc: 0.8833\n",
            "Epoch 235/1000\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.3161 - acc: 0.8750\n",
            "Epoch 236/1000\n",
            "120/120 [==============================] - 0s 117us/step - loss: 0.3151 - acc: 0.8833\n",
            "Epoch 237/1000\n",
            "120/120 [==============================] - 0s 128us/step - loss: 0.3140 - acc: 0.8833\n",
            "Epoch 238/1000\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.3126 - acc: 0.8833\n",
            "Epoch 239/1000\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.3115 - acc: 0.8833\n",
            "Epoch 240/1000\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.3104 - acc: 0.8750\n",
            "Epoch 241/1000\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.3097 - acc: 0.8833\n",
            "Epoch 242/1000\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.3086 - acc: 0.8833\n",
            "Epoch 243/1000\n",
            "120/120 [==============================] - 0s 129us/step - loss: 0.3073 - acc: 0.8833\n",
            "Epoch 244/1000\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.3063 - acc: 0.8833\n",
            "Epoch 245/1000\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.3050 - acc: 0.8750\n",
            "Epoch 246/1000\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.3041 - acc: 0.8750\n",
            "Epoch 247/1000\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.3032 - acc: 0.8750\n",
            "Epoch 248/1000\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.3021 - acc: 0.8750\n",
            "Epoch 249/1000\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.3010 - acc: 0.8750\n",
            "Epoch 250/1000\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2999 - acc: 0.8750\n",
            "Epoch 251/1000\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2988 - acc: 0.8750\n",
            "Epoch 252/1000\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.2980 - acc: 0.8750\n",
            "Epoch 253/1000\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2973 - acc: 0.8750\n",
            "Epoch 254/1000\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2965 - acc: 0.8667\n",
            "Epoch 255/1000\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2955 - acc: 0.8750\n",
            "Epoch 256/1000\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2950 - acc: 0.8833\n",
            "Epoch 257/1000\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2945 - acc: 0.8833\n",
            "Epoch 258/1000\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.2935 - acc: 0.8750\n",
            "Epoch 259/1000\n",
            "120/120 [==============================] - 0s 73us/step - loss: 0.2927 - acc: 0.8750\n",
            "Epoch 260/1000\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2919 - acc: 0.8833\n",
            "Epoch 261/1000\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2912 - acc: 0.8833\n",
            "Epoch 262/1000\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2907 - acc: 0.8833\n",
            "Epoch 263/1000\n",
            "120/120 [==============================] - 0s 121us/step - loss: 0.2900 - acc: 0.8833\n",
            "Epoch 264/1000\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2893 - acc: 0.8833\n",
            "Epoch 265/1000\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2888 - acc: 0.8833\n",
            "Epoch 266/1000\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2880 - acc: 0.8833\n",
            "Epoch 267/1000\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2873 - acc: 0.8833\n",
            "Epoch 268/1000\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2866 - acc: 0.8833\n",
            "Epoch 269/1000\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2859 - acc: 0.8833\n",
            "Epoch 270/1000\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.2852 - acc: 0.8750\n",
            "Epoch 271/1000\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2850 - acc: 0.8750\n",
            "Epoch 272/1000\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2840 - acc: 0.8750\n",
            "Epoch 273/1000\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2833 - acc: 0.8667\n",
            "Epoch 274/1000\n",
            "120/120 [==============================] - 0s 125us/step - loss: 0.2826 - acc: 0.8750\n",
            "Epoch 275/1000\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2822 - acc: 0.8667\n",
            "Epoch 276/1000\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2816 - acc: 0.8750\n",
            "Epoch 277/1000\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2813 - acc: 0.8750\n",
            "Epoch 278/1000\n",
            "120/120 [==============================] - 0s 77us/step - loss: 0.2808 - acc: 0.8833\n",
            "Epoch 279/1000\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2800 - acc: 0.8750\n",
            "Epoch 280/1000\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2794 - acc: 0.8750\n",
            "Epoch 281/1000\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2785 - acc: 0.8750\n",
            "Epoch 282/1000\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2779 - acc: 0.8750\n",
            "Epoch 283/1000\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.2775 - acc: 0.8750\n",
            "Epoch 284/1000\n",
            "120/120 [==============================] - 0s 151us/step - loss: 0.2775 - acc: 0.8750\n",
            "Epoch 285/1000\n",
            "120/120 [==============================] - 0s 145us/step - loss: 0.2768 - acc: 0.8583\n",
            "Epoch 286/1000\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2762 - acc: 0.8667\n",
            "Epoch 287/1000\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2758 - acc: 0.8667\n",
            "Epoch 288/1000\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2755 - acc: 0.8583\n",
            "Epoch 289/1000\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2748 - acc: 0.8500\n",
            "Epoch 290/1000\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2742 - acc: 0.8583\n",
            "Epoch 291/1000\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2737 - acc: 0.8667\n",
            "Epoch 292/1000\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2730 - acc: 0.8667\n",
            "Epoch 293/1000\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2724 - acc: 0.8750\n",
            "Epoch 294/1000\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2720 - acc: 0.8667\n",
            "Epoch 295/1000\n",
            "120/120 [==============================] - 0s 168us/step - loss: 0.2716 - acc: 0.8750\n",
            "Epoch 296/1000\n",
            "120/120 [==============================] - 0s 215us/step - loss: 0.2711 - acc: 0.8667\n",
            "Epoch 297/1000\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2709 - acc: 0.8667\n",
            "Epoch 298/1000\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2701 - acc: 0.8833\n",
            "Epoch 299/1000\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2699 - acc: 0.8833\n",
            "Epoch 300/1000\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2695 - acc: 0.8833\n",
            "Epoch 301/1000\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.2691 - acc: 0.8833\n",
            "Epoch 302/1000\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2686 - acc: 0.8833\n",
            "Epoch 303/1000\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2684 - acc: 0.8833\n",
            "Epoch 304/1000\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2682 - acc: 0.8833\n",
            "Epoch 305/1000\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2679 - acc: 0.8833\n",
            "Epoch 306/1000\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2675 - acc: 0.8750\n",
            "Epoch 307/1000\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2675 - acc: 0.8750\n",
            "Epoch 308/1000\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2673 - acc: 0.8750\n",
            "Epoch 309/1000\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2675 - acc: 0.8750\n",
            "Epoch 310/1000\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2675 - acc: 0.8917\n",
            "Epoch 311/1000\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2675 - acc: 0.8917\n",
            "Epoch 312/1000\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2675 - acc: 0.8917\n",
            "Epoch 313/1000\n",
            "120/120 [==============================] - 0s 119us/step - loss: 0.2669 - acc: 0.8917\n",
            "Epoch 314/1000\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2657 - acc: 0.8917\n",
            "Epoch 315/1000\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2649 - acc: 0.8833\n",
            "Epoch 316/1000\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.2645 - acc: 0.8833\n",
            "Epoch 317/1000\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.2642 - acc: 0.8833\n",
            "Epoch 318/1000\n",
            "120/120 [==============================] - 0s 77us/step - loss: 0.2636 - acc: 0.8833\n",
            "Epoch 319/1000\n",
            "120/120 [==============================] - 0s 122us/step - loss: 0.2632 - acc: 0.8833\n",
            "Epoch 320/1000\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2629 - acc: 0.8833\n",
            "Epoch 321/1000\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.2623 - acc: 0.8750\n",
            "Epoch 322/1000\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2622 - acc: 0.8750\n",
            "Epoch 323/1000\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2619 - acc: 0.8750\n",
            "Epoch 324/1000\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2617 - acc: 0.8750\n",
            "Epoch 325/1000\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2612 - acc: 0.8833\n",
            "Epoch 326/1000\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.2607 - acc: 0.8833\n",
            "Epoch 327/1000\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2605 - acc: 0.8833\n",
            "Epoch 328/1000\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.2603 - acc: 0.8833\n",
            "Epoch 329/1000\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2602 - acc: 0.8833\n",
            "Epoch 330/1000\n",
            "120/120 [==============================] - 0s 117us/step - loss: 0.2598 - acc: 0.8833\n",
            "Epoch 331/1000\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2592 - acc: 0.8750\n",
            "Epoch 332/1000\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2591 - acc: 0.8750\n",
            "Epoch 333/1000\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2588 - acc: 0.8833\n",
            "Epoch 334/1000\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2586 - acc: 0.8833\n",
            "Epoch 335/1000\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.2582 - acc: 0.8750\n",
            "Epoch 336/1000\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2582 - acc: 0.8750\n",
            "Epoch 337/1000\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2579 - acc: 0.8750\n",
            "Epoch 338/1000\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2578 - acc: 0.8750\n",
            "Epoch 339/1000\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2575 - acc: 0.8750\n",
            "Epoch 340/1000\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2571 - acc: 0.8750\n",
            "Epoch 341/1000\n",
            "120/120 [==============================] - 0s 77us/step - loss: 0.2570 - acc: 0.8750\n",
            "Epoch 342/1000\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2567 - acc: 0.8667\n",
            "Epoch 343/1000\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2565 - acc: 0.8667\n",
            "Epoch 344/1000\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.2563 - acc: 0.8667\n",
            "Epoch 345/1000\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2557 - acc: 0.8750\n",
            "Epoch 346/1000\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2552 - acc: 0.8833\n",
            "Epoch 347/1000\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2551 - acc: 0.8833\n",
            "Epoch 348/1000\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2550 - acc: 0.8833\n",
            "Epoch 349/1000\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2548 - acc: 0.8833\n",
            "Epoch 350/1000\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2545 - acc: 0.8833\n",
            "Epoch 351/1000\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2545 - acc: 0.8833\n",
            "Epoch 352/1000\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2544 - acc: 0.8833\n",
            "Epoch 353/1000\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2542 - acc: 0.8750\n",
            "Epoch 354/1000\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.2539 - acc: 0.8750\n",
            "Epoch 355/1000\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2537 - acc: 0.8750\n",
            "Epoch 356/1000\n",
            "120/120 [==============================] - 0s 122us/step - loss: 0.2538 - acc: 0.8833\n",
            "Epoch 357/1000\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.2538 - acc: 0.8917\n",
            "Epoch 358/1000\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2535 - acc: 0.8833\n",
            "Epoch 359/1000\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.2531 - acc: 0.8750\n",
            "Epoch 360/1000\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2528 - acc: 0.8833\n",
            "Epoch 361/1000\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2524 - acc: 0.8833\n",
            "Epoch 362/1000\n",
            "120/120 [==============================] - 0s 148us/step - loss: 0.2522 - acc: 0.8833\n",
            "Epoch 363/1000\n",
            "120/120 [==============================] - 0s 148us/step - loss: 0.2520 - acc: 0.8833\n",
            "Epoch 364/1000\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2520 - acc: 0.8833\n",
            "Epoch 365/1000\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2521 - acc: 0.8833\n",
            "Epoch 366/1000\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2521 - acc: 0.8917\n",
            "Epoch 367/1000\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2518 - acc: 0.8917\n",
            "Epoch 368/1000\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2512 - acc: 0.8750\n",
            "Epoch 369/1000\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.2508 - acc: 0.8833\n",
            "Epoch 370/1000\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2506 - acc: 0.8833\n",
            "Epoch 371/1000\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2504 - acc: 0.8833\n",
            "Epoch 372/1000\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2502 - acc: 0.8833\n",
            "Epoch 373/1000\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.2501 - acc: 0.8833\n",
            "Epoch 374/1000\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.2499 - acc: 0.8833\n",
            "Epoch 375/1000\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.2497 - acc: 0.8833\n",
            "Epoch 376/1000\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2495 - acc: 0.8833\n",
            "Epoch 377/1000\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.2493 - acc: 0.8833\n",
            "Epoch 378/1000\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2490 - acc: 0.8833\n",
            "Epoch 379/1000\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2488 - acc: 0.8833\n",
            "Epoch 380/1000\n",
            "120/120 [==============================] - 0s 115us/step - loss: 0.2489 - acc: 0.8750\n",
            "Epoch 381/1000\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2487 - acc: 0.8750\n",
            "Epoch 382/1000\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2485 - acc: 0.8750\n",
            "Epoch 383/1000\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2482 - acc: 0.8833\n",
            "Epoch 384/1000\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.2480 - acc: 0.8750\n",
            "Epoch 385/1000\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2478 - acc: 0.8750\n",
            "Epoch 386/1000\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2477 - acc: 0.8750\n",
            "Epoch 387/1000\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2477 - acc: 0.8750\n",
            "Epoch 388/1000\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2478 - acc: 0.8750\n",
            "Epoch 389/1000\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.2478 - acc: 0.8750\n",
            "Epoch 390/1000\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2477 - acc: 0.8750\n",
            "Epoch 391/1000\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2474 - acc: 0.8750\n",
            "Epoch 392/1000\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2468 - acc: 0.8750\n",
            "Epoch 393/1000\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.2469 - acc: 0.8750\n",
            "Epoch 394/1000\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2463 - acc: 0.8833\n",
            "Epoch 395/1000\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2463 - acc: 0.8833\n",
            "Epoch 396/1000\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2462 - acc: 0.8833\n",
            "Epoch 397/1000\n",
            "120/120 [==============================] - 0s 136us/step - loss: 0.2463 - acc: 0.8833\n",
            "Epoch 398/1000\n",
            "120/120 [==============================] - 0s 120us/step - loss: 0.2460 - acc: 0.8833\n",
            "Epoch 399/1000\n",
            "120/120 [==============================] - 0s 120us/step - loss: 0.2459 - acc: 0.8833\n",
            "Epoch 400/1000\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2457 - acc: 0.8833\n",
            "Epoch 401/1000\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2455 - acc: 0.8833\n",
            "Epoch 402/1000\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2453 - acc: 0.8833\n",
            "Epoch 403/1000\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2452 - acc: 0.8833\n",
            "Epoch 404/1000\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2457 - acc: 0.8833\n",
            "Epoch 405/1000\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2453 - acc: 0.8750\n",
            "Epoch 406/1000\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2450 - acc: 0.8833\n",
            "Epoch 407/1000\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.2450 - acc: 0.8750\n",
            "Epoch 408/1000\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.2449 - acc: 0.8750\n",
            "Epoch 409/1000\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2453 - acc: 0.8750\n",
            "Epoch 410/1000\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2457 - acc: 0.8750\n",
            "Epoch 411/1000\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2457 - acc: 0.8750\n",
            "Epoch 412/1000\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2454 - acc: 0.8750\n",
            "Epoch 413/1000\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2451 - acc: 0.8750\n",
            "Epoch 414/1000\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2447 - acc: 0.8667\n",
            "Epoch 415/1000\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2447 - acc: 0.8667\n",
            "Epoch 416/1000\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2446 - acc: 0.8750\n",
            "Epoch 417/1000\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2447 - acc: 0.8750\n",
            "Epoch 418/1000\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.2451 - acc: 0.8750\n",
            "Epoch 419/1000\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2451 - acc: 0.8667\n",
            "Epoch 420/1000\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2450 - acc: 0.8667\n",
            "Epoch 421/1000\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2444 - acc: 0.8750\n",
            "Epoch 422/1000\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2444 - acc: 0.8750\n",
            "Epoch 423/1000\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2439 - acc: 0.8667\n",
            "Epoch 424/1000\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2434 - acc: 0.8667\n",
            "Epoch 425/1000\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2430 - acc: 0.8750\n",
            "Epoch 426/1000\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2430 - acc: 0.8833\n",
            "Epoch 427/1000\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2432 - acc: 0.8750\n",
            "Epoch 428/1000\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2433 - acc: 0.8583\n",
            "Epoch 429/1000\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2434 - acc: 0.8583\n",
            "Epoch 430/1000\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2427 - acc: 0.8750\n",
            "Epoch 431/1000\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2427 - acc: 0.8667\n",
            "Epoch 432/1000\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.2420 - acc: 0.8833\n",
            "Epoch 433/1000\n",
            "120/120 [==============================] - 0s 119us/step - loss: 0.2421 - acc: 0.8750\n",
            "Epoch 434/1000\n",
            "120/120 [==============================] - 0s 120us/step - loss: 0.2419 - acc: 0.8833\n",
            "Epoch 435/1000\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2418 - acc: 0.8833\n",
            "Epoch 436/1000\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2421 - acc: 0.8833\n",
            "Epoch 437/1000\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.2422 - acc: 0.8750\n",
            "Epoch 438/1000\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2422 - acc: 0.8750\n",
            "Epoch 439/1000\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2416 - acc: 0.8833\n",
            "Epoch 440/1000\n",
            "120/120 [==============================] - 0s 141us/step - loss: 0.2415 - acc: 0.8833\n",
            "Epoch 441/1000\n",
            "120/120 [==============================] - 0s 121us/step - loss: 0.2415 - acc: 0.8833\n",
            "Epoch 442/1000\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2415 - acc: 0.8833\n",
            "Epoch 443/1000\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.2411 - acc: 0.8833\n",
            "Epoch 444/1000\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2409 - acc: 0.8833\n",
            "Epoch 445/1000\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2411 - acc: 0.8833\n",
            "Epoch 446/1000\n",
            "120/120 [==============================] - 0s 115us/step - loss: 0.2411 - acc: 0.8833\n",
            "Epoch 447/1000\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.2410 - acc: 0.8833\n",
            "Epoch 448/1000\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.2408 - acc: 0.8833\n",
            "Epoch 449/1000\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2407 - acc: 0.8833\n",
            "Epoch 450/1000\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2408 - acc: 0.8833\n",
            "Epoch 451/1000\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2407 - acc: 0.8833\n",
            "Epoch 452/1000\n",
            "120/120 [==============================] - 0s 119us/step - loss: 0.2407 - acc: 0.8750\n",
            "Epoch 453/1000\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.2407 - acc: 0.8833\n",
            "Epoch 454/1000\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2407 - acc: 0.8750\n",
            "Epoch 455/1000\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2404 - acc: 0.8833\n",
            "Epoch 456/1000\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2409 - acc: 0.8750\n",
            "Epoch 457/1000\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2399 - acc: 0.8917\n",
            "Epoch 458/1000\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.2400 - acc: 0.8917\n",
            "Epoch 459/1000\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.2399 - acc: 0.8917\n",
            "Epoch 460/1000\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.2401 - acc: 0.8917\n",
            "Epoch 461/1000\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2396 - acc: 0.8917\n",
            "Epoch 462/1000\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2398 - acc: 0.8917\n",
            "Epoch 463/1000\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2394 - acc: 0.8833\n",
            "Epoch 464/1000\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2393 - acc: 0.8833\n",
            "Epoch 465/1000\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2393 - acc: 0.8833\n",
            "Epoch 466/1000\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.2394 - acc: 0.8833\n",
            "Epoch 467/1000\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.2394 - acc: 0.8917\n",
            "Epoch 468/1000\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2392 - acc: 0.9000\n",
            "Epoch 469/1000\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2391 - acc: 0.8917\n",
            "Epoch 470/1000\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2391 - acc: 0.9000\n",
            "Epoch 471/1000\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2391 - acc: 0.9000\n",
            "Epoch 472/1000\n",
            "120/120 [==============================] - 0s 120us/step - loss: 0.2389 - acc: 0.8917\n",
            "Epoch 473/1000\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2389 - acc: 0.8917\n",
            "Epoch 474/1000\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2388 - acc: 0.8917\n",
            "Epoch 475/1000\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.2387 - acc: 0.8917\n",
            "Epoch 476/1000\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.2390 - acc: 0.8917\n",
            "Epoch 477/1000\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2390 - acc: 0.8917\n",
            "Epoch 478/1000\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.2385 - acc: 0.8917\n",
            "Epoch 479/1000\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.2385 - acc: 0.8917\n",
            "Epoch 480/1000\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2384 - acc: 0.8917\n",
            "Epoch 481/1000\n",
            "120/120 [==============================] - 0s 126us/step - loss: 0.2379 - acc: 0.8917\n",
            "Epoch 482/1000\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2380 - acc: 0.8917\n",
            "Epoch 483/1000\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2379 - acc: 0.8917\n",
            "Epoch 484/1000\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2378 - acc: 0.8833\n",
            "Epoch 485/1000\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2378 - acc: 0.8833\n",
            "Epoch 486/1000\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2376 - acc: 0.8917\n",
            "Epoch 487/1000\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2378 - acc: 0.8917\n",
            "Epoch 488/1000\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2374 - acc: 0.8833\n",
            "Epoch 489/1000\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2373 - acc: 0.8917\n",
            "Epoch 490/1000\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2373 - acc: 0.8833\n",
            "Epoch 491/1000\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2374 - acc: 0.8917\n",
            "Epoch 492/1000\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2374 - acc: 0.8917\n",
            "Epoch 493/1000\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2376 - acc: 0.8833\n",
            "Epoch 494/1000\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2375 - acc: 0.8917\n",
            "Epoch 495/1000\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2375 - acc: 0.8917\n",
            "Epoch 496/1000\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2377 - acc: 0.8917\n",
            "Epoch 497/1000\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.2376 - acc: 0.8917\n",
            "Epoch 498/1000\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2374 - acc: 0.8917\n",
            "Epoch 499/1000\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2376 - acc: 0.8917\n",
            "Epoch 500/1000\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.2367 - acc: 0.8917\n",
            "Epoch 501/1000\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2367 - acc: 0.8917\n",
            "Epoch 502/1000\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2368 - acc: 0.8917\n",
            "Epoch 503/1000\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2368 - acc: 0.8917\n",
            "Epoch 504/1000\n",
            "120/120 [==============================] - 0s 121us/step - loss: 0.2366 - acc: 0.8917\n",
            "Epoch 505/1000\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.2364 - acc: 0.8917\n",
            "Epoch 506/1000\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.2363 - acc: 0.8917\n",
            "Epoch 507/1000\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.2363 - acc: 0.8917\n",
            "Epoch 508/1000\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2365 - acc: 0.8917\n",
            "Epoch 509/1000\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2362 - acc: 0.8833\n",
            "Epoch 510/1000\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2362 - acc: 0.8833\n",
            "Epoch 511/1000\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2366 - acc: 0.8917\n",
            "Epoch 512/1000\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2363 - acc: 0.8917\n",
            "Epoch 513/1000\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2363 - acc: 0.8917\n",
            "Epoch 514/1000\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2358 - acc: 0.8917\n",
            "Epoch 515/1000\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2358 - acc: 0.8917\n",
            "Epoch 516/1000\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.2359 - acc: 0.8917\n",
            "Epoch 517/1000\n",
            "120/120 [==============================] - 0s 117us/step - loss: 0.2356 - acc: 0.8917\n",
            "Epoch 518/1000\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.2355 - acc: 0.8917\n",
            "Epoch 519/1000\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2362 - acc: 0.8917\n",
            "Epoch 520/1000\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2362 - acc: 0.8833\n",
            "Epoch 521/1000\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2365 - acc: 0.9000\n",
            "Epoch 522/1000\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2365 - acc: 0.9000\n",
            "Epoch 523/1000\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2364 - acc: 0.9083\n",
            "Epoch 524/1000\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2361 - acc: 0.9000\n",
            "Epoch 525/1000\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2356 - acc: 0.8917\n",
            "Epoch 526/1000\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2356 - acc: 0.8917\n",
            "Epoch 527/1000\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2356 - acc: 0.8917\n",
            "Epoch 528/1000\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2359 - acc: 0.8917\n",
            "Epoch 529/1000\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2361 - acc: 0.9000\n",
            "Epoch 530/1000\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.2357 - acc: 0.8917\n",
            "Epoch 531/1000\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.2361 - acc: 0.9000\n",
            "Epoch 532/1000\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.2359 - acc: 0.8917\n",
            "Epoch 533/1000\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.2361 - acc: 0.9167\n",
            "Epoch 534/1000\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.2362 - acc: 0.9000\n",
            "Epoch 535/1000\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2366 - acc: 0.9167\n",
            "Epoch 536/1000\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2370 - acc: 0.9083\n",
            "Epoch 537/1000\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.2372 - acc: 0.9167\n",
            "Epoch 538/1000\n",
            "120/120 [==============================] - 0s 122us/step - loss: 0.2365 - acc: 0.9083\n",
            "Epoch 539/1000\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.2350 - acc: 0.9000\n",
            "Epoch 540/1000\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2347 - acc: 0.9000\n",
            "Epoch 541/1000\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2345 - acc: 0.9083\n",
            "Epoch 542/1000\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2344 - acc: 0.9000\n",
            "Epoch 543/1000\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2343 - acc: 0.9000\n",
            "Epoch 544/1000\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2343 - acc: 0.9000\n",
            "Epoch 545/1000\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2342 - acc: 0.9000\n",
            "Epoch 546/1000\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2343 - acc: 0.8917\n",
            "Epoch 547/1000\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2339 - acc: 0.9000\n",
            "Epoch 548/1000\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2339 - acc: 0.9000\n",
            "Epoch 549/1000\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.2340 - acc: 0.9000\n",
            "Epoch 550/1000\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2339 - acc: 0.9083\n",
            "Epoch 551/1000\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2340 - acc: 0.9083\n",
            "Epoch 552/1000\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2337 - acc: 0.9000\n",
            "Epoch 553/1000\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2337 - acc: 0.9000\n",
            "Epoch 554/1000\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2335 - acc: 0.9000\n",
            "Epoch 555/1000\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.2336 - acc: 0.9000\n",
            "Epoch 556/1000\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.2338 - acc: 0.9000\n",
            "Epoch 557/1000\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2335 - acc: 0.9000\n",
            "Epoch 558/1000\n",
            "120/120 [==============================] - 0s 122us/step - loss: 0.2337 - acc: 0.9000\n",
            "Epoch 559/1000\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2337 - acc: 0.9000\n",
            "Epoch 560/1000\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2336 - acc: 0.9000\n",
            "Epoch 561/1000\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.2339 - acc: 0.9000\n",
            "Epoch 562/1000\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.2340 - acc: 0.9000\n",
            "Epoch 563/1000\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.2338 - acc: 0.9000\n",
            "Epoch 564/1000\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2338 - acc: 0.9000\n",
            "Epoch 565/1000\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2336 - acc: 0.9000\n",
            "Epoch 566/1000\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2335 - acc: 0.9000\n",
            "Epoch 567/1000\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2338 - acc: 0.8917\n",
            "Epoch 568/1000\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2333 - acc: 0.9000\n",
            "Epoch 569/1000\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2332 - acc: 0.9000\n",
            "Epoch 570/1000\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2330 - acc: 0.9000\n",
            "Epoch 571/1000\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2332 - acc: 0.9000\n",
            "Epoch 572/1000\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2330 - acc: 0.9083\n",
            "Epoch 573/1000\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2328 - acc: 0.9000\n",
            "Epoch 574/1000\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2330 - acc: 0.9000\n",
            "Epoch 575/1000\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2330 - acc: 0.9083\n",
            "Epoch 576/1000\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2328 - acc: 0.9000\n",
            "Epoch 577/1000\n",
            "120/120 [==============================] - 0s 136us/step - loss: 0.2326 - acc: 0.9000\n",
            "Epoch 578/1000\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2326 - acc: 0.9083\n",
            "Epoch 579/1000\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.2327 - acc: 0.9000\n",
            "Epoch 580/1000\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2328 - acc: 0.9000\n",
            "Epoch 581/1000\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2327 - acc: 0.9000\n",
            "Epoch 582/1000\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2326 - acc: 0.9000\n",
            "Epoch 583/1000\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2330 - acc: 0.9167\n",
            "Epoch 584/1000\n",
            "120/120 [==============================] - 0s 121us/step - loss: 0.2328 - acc: 0.9000\n",
            "Epoch 585/1000\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2325 - acc: 0.9000\n",
            "Epoch 586/1000\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2324 - acc: 0.8917\n",
            "Epoch 587/1000\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2323 - acc: 0.8917\n",
            "Epoch 588/1000\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2323 - acc: 0.9000\n",
            "Epoch 589/1000\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2327 - acc: 0.9083\n",
            "Epoch 590/1000\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2332 - acc: 0.9167\n",
            "Epoch 591/1000\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.2336 - acc: 0.9083\n",
            "Epoch 592/1000\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.2332 - acc: 0.9167\n",
            "Epoch 593/1000\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.2327 - acc: 0.9167\n",
            "Epoch 594/1000\n",
            "120/120 [==============================] - 0s 141us/step - loss: 0.2329 - acc: 0.9167\n",
            "Epoch 595/1000\n",
            "120/120 [==============================] - 0s 142us/step - loss: 0.2323 - acc: 0.9167\n",
            "Epoch 596/1000\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2322 - acc: 0.9167\n",
            "Epoch 597/1000\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2318 - acc: 0.9083\n",
            "Epoch 598/1000\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2318 - acc: 0.9083\n",
            "Epoch 599/1000\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2317 - acc: 0.9083\n",
            "Epoch 600/1000\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2318 - acc: 0.9083\n",
            "Epoch 601/1000\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2318 - acc: 0.9167\n",
            "Epoch 602/1000\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2318 - acc: 0.9167\n",
            "Epoch 603/1000\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2317 - acc: 0.9083\n",
            "Epoch 604/1000\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2314 - acc: 0.9083\n",
            "Epoch 605/1000\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2314 - acc: 0.9083\n",
            "Epoch 606/1000\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.2314 - acc: 0.9000\n",
            "Epoch 607/1000\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2313 - acc: 0.9000\n",
            "Epoch 608/1000\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2313 - acc: 0.9000\n",
            "Epoch 609/1000\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2314 - acc: 0.9000\n",
            "Epoch 610/1000\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2315 - acc: 0.9000\n",
            "Epoch 611/1000\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2315 - acc: 0.9083\n",
            "Epoch 612/1000\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2312 - acc: 0.9083\n",
            "Epoch 613/1000\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2313 - acc: 0.9083\n",
            "Epoch 614/1000\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.2310 - acc: 0.9000\n",
            "Epoch 615/1000\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2311 - acc: 0.9000\n",
            "Epoch 616/1000\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2310 - acc: 0.9000\n",
            "Epoch 617/1000\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.2309 - acc: 0.9000\n",
            "Epoch 618/1000\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.2308 - acc: 0.9000\n",
            "Epoch 619/1000\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2309 - acc: 0.9000\n",
            "Epoch 620/1000\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.2310 - acc: 0.9000\n",
            "Epoch 621/1000\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2312 - acc: 0.9000\n",
            "Epoch 622/1000\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2309 - acc: 0.9000\n",
            "Epoch 623/1000\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2311 - acc: 0.8917\n",
            "Epoch 624/1000\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2314 - acc: 0.8833\n",
            "Epoch 625/1000\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2315 - acc: 0.8833\n",
            "Epoch 626/1000\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2313 - acc: 0.8833\n",
            "Epoch 627/1000\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2313 - acc: 0.8833\n",
            "Epoch 628/1000\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2321 - acc: 0.8833\n",
            "Epoch 629/1000\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2325 - acc: 0.8750\n",
            "Epoch 630/1000\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2324 - acc: 0.8750\n",
            "Epoch 631/1000\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2325 - acc: 0.8750\n",
            "Epoch 632/1000\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2323 - acc: 0.8750\n",
            "Epoch 633/1000\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2311 - acc: 0.8833\n",
            "Epoch 634/1000\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2307 - acc: 0.8917\n",
            "Epoch 635/1000\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.2309 - acc: 0.8833\n",
            "Epoch 636/1000\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2307 - acc: 0.8917\n",
            "Epoch 637/1000\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2306 - acc: 0.9083\n",
            "Epoch 638/1000\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.2305 - acc: 0.9000\n",
            "Epoch 639/1000\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.2305 - acc: 0.8917\n",
            "Epoch 640/1000\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2306 - acc: 0.8917\n",
            "Epoch 641/1000\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2305 - acc: 0.8833\n",
            "Epoch 642/1000\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2305 - acc: 0.8917\n",
            "Epoch 643/1000\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2304 - acc: 0.9000\n",
            "Epoch 644/1000\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2304 - acc: 0.8917\n",
            "Epoch 645/1000\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2301 - acc: 0.8917\n",
            "Epoch 646/1000\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2301 - acc: 0.9000\n",
            "Epoch 647/1000\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2301 - acc: 0.9000\n",
            "Epoch 648/1000\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2300 - acc: 0.9000\n",
            "Epoch 649/1000\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2301 - acc: 0.9000\n",
            "Epoch 650/1000\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2301 - acc: 0.8917\n",
            "Epoch 651/1000\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2298 - acc: 0.9000\n",
            "Epoch 652/1000\n",
            "120/120 [==============================] - 0s 141us/step - loss: 0.2300 - acc: 0.9000\n",
            "Epoch 653/1000\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.2300 - acc: 0.9083\n",
            "Epoch 654/1000\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2303 - acc: 0.9083\n",
            "Epoch 655/1000\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2302 - acc: 0.9083\n",
            "Epoch 656/1000\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2302 - acc: 0.9083\n",
            "Epoch 657/1000\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2303 - acc: 0.9000\n",
            "Epoch 658/1000\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2301 - acc: 0.9083\n",
            "Epoch 659/1000\n",
            "120/120 [==============================] - 0s 119us/step - loss: 0.2300 - acc: 0.9083\n",
            "Epoch 660/1000\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.2300 - acc: 0.9083\n",
            "Epoch 661/1000\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2302 - acc: 0.9083\n",
            "Epoch 662/1000\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2302 - acc: 0.9083\n",
            "Epoch 663/1000\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2296 - acc: 0.9000\n",
            "Epoch 664/1000\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2297 - acc: 0.8917\n",
            "Epoch 665/1000\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2299 - acc: 0.8917\n",
            "Epoch 666/1000\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2297 - acc: 0.8917\n",
            "Epoch 667/1000\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2309 - acc: 0.8917\n",
            "Epoch 668/1000\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2310 - acc: 0.8750\n",
            "Epoch 669/1000\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2304 - acc: 0.8833\n",
            "Epoch 670/1000\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2301 - acc: 0.8833\n",
            "Epoch 671/1000\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2301 - acc: 0.8833\n",
            "Epoch 672/1000\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2304 - acc: 0.8833\n",
            "Epoch 673/1000\n",
            "120/120 [==============================] - 0s 76us/step - loss: 0.2311 - acc: 0.8917\n",
            "Epoch 674/1000\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2313 - acc: 0.8833\n",
            "Epoch 675/1000\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2302 - acc: 0.9000\n",
            "Epoch 676/1000\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.2302 - acc: 0.9000\n",
            "Epoch 677/1000\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2304 - acc: 0.8750\n",
            "Epoch 678/1000\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2304 - acc: 0.8917\n",
            "Epoch 679/1000\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2301 - acc: 0.9000\n",
            "Epoch 680/1000\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.2299 - acc: 0.9000\n",
            "Epoch 681/1000\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2299 - acc: 0.9167\n",
            "Epoch 682/1000\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2301 - acc: 0.9083\n",
            "Epoch 683/1000\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2302 - acc: 0.9000\n",
            "Epoch 684/1000\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2295 - acc: 0.9000\n",
            "Epoch 685/1000\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.2291 - acc: 0.9083\n",
            "Epoch 686/1000\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2292 - acc: 0.9083\n",
            "Epoch 687/1000\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2293 - acc: 0.9000\n",
            "Epoch 688/1000\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2293 - acc: 0.9000\n",
            "Epoch 689/1000\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2291 - acc: 0.9000\n",
            "Epoch 690/1000\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2292 - acc: 0.9000\n",
            "Epoch 691/1000\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2293 - acc: 0.9000\n",
            "Epoch 692/1000\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2292 - acc: 0.9000\n",
            "Epoch 693/1000\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2294 - acc: 0.8917\n",
            "Epoch 694/1000\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2289 - acc: 0.9000\n",
            "Epoch 695/1000\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2287 - acc: 0.9000\n",
            "Epoch 696/1000\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2289 - acc: 0.8917\n",
            "Epoch 697/1000\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2287 - acc: 0.9000\n",
            "Epoch 698/1000\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2286 - acc: 0.9000\n",
            "Epoch 699/1000\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2286 - acc: 0.9000\n",
            "Epoch 700/1000\n",
            "120/120 [==============================] - 0s 119us/step - loss: 0.2286 - acc: 0.9083\n",
            "Epoch 701/1000\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.2291 - acc: 0.9000\n",
            "Epoch 702/1000\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2289 - acc: 0.9083\n",
            "Epoch 703/1000\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2289 - acc: 0.9083\n",
            "Epoch 704/1000\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2288 - acc: 0.9083\n",
            "Epoch 705/1000\n",
            "120/120 [==============================] - 0s 123us/step - loss: 0.2287 - acc: 0.9167\n",
            "Epoch 706/1000\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2292 - acc: 0.9083\n",
            "Epoch 707/1000\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2296 - acc: 0.9167\n",
            "Epoch 708/1000\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2299 - acc: 0.9083\n",
            "Epoch 709/1000\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2292 - acc: 0.9167\n",
            "Epoch 710/1000\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2292 - acc: 0.9167\n",
            "Epoch 711/1000\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2284 - acc: 0.9167\n",
            "Epoch 712/1000\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2286 - acc: 0.9167\n",
            "Epoch 713/1000\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2286 - acc: 0.9167\n",
            "Epoch 714/1000\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2283 - acc: 0.9167\n",
            "Epoch 715/1000\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2283 - acc: 0.9083\n",
            "Epoch 716/1000\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2286 - acc: 0.9083\n",
            "Epoch 717/1000\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2288 - acc: 0.9083\n",
            "Epoch 718/1000\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2287 - acc: 0.9083\n",
            "Epoch 719/1000\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2285 - acc: 0.8917\n",
            "Epoch 720/1000\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2288 - acc: 0.8833\n",
            "Epoch 721/1000\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2291 - acc: 0.8833\n",
            "Epoch 722/1000\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2285 - acc: 0.9083\n",
            "Epoch 723/1000\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2285 - acc: 0.8917\n",
            "Epoch 724/1000\n",
            "120/120 [==============================] - 0s 121us/step - loss: 0.2286 - acc: 0.9000\n",
            "Epoch 725/1000\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2288 - acc: 0.8917\n",
            "Epoch 726/1000\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2290 - acc: 0.8917\n",
            "Epoch 727/1000\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.2287 - acc: 0.8917\n",
            "Epoch 728/1000\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2286 - acc: 0.8917\n",
            "Epoch 729/1000\n",
            "120/120 [==============================] - 0s 75us/step - loss: 0.2283 - acc: 0.9000\n",
            "Epoch 730/1000\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2280 - acc: 0.9083\n",
            "Epoch 731/1000\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2278 - acc: 0.9083\n",
            "Epoch 732/1000\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.2281 - acc: 0.9083\n",
            "Epoch 733/1000\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2281 - acc: 0.9167\n",
            "Epoch 734/1000\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2282 - acc: 0.9167\n",
            "Epoch 735/1000\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2278 - acc: 0.9000\n",
            "Epoch 736/1000\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2278 - acc: 0.9000\n",
            "Epoch 737/1000\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2279 - acc: 0.9000\n",
            "Epoch 738/1000\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2278 - acc: 0.9083\n",
            "Epoch 739/1000\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2280 - acc: 0.9083\n",
            "Epoch 740/1000\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2277 - acc: 0.8917\n",
            "Epoch 741/1000\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.2276 - acc: 0.9000\n",
            "Epoch 742/1000\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2275 - acc: 0.9083\n",
            "Epoch 743/1000\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2276 - acc: 0.9083\n",
            "Epoch 744/1000\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.2276 - acc: 0.9083\n",
            "Epoch 745/1000\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.2276 - acc: 0.9083\n",
            "Epoch 746/1000\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2275 - acc: 0.9083\n",
            "Epoch 747/1000\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2278 - acc: 0.9083\n",
            "Epoch 748/1000\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2279 - acc: 0.9167\n",
            "Epoch 749/1000\n",
            "120/120 [==============================] - 0s 115us/step - loss: 0.2277 - acc: 0.9167\n",
            "Epoch 750/1000\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2276 - acc: 0.9083\n",
            "Epoch 751/1000\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.2277 - acc: 0.9083\n",
            "Epoch 752/1000\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.2279 - acc: 0.9167\n",
            "Epoch 753/1000\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2281 - acc: 0.9167\n",
            "Epoch 754/1000\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2283 - acc: 0.9250\n",
            "Epoch 755/1000\n",
            "120/120 [==============================] - 0s 138us/step - loss: 0.2283 - acc: 0.9167\n",
            "Epoch 756/1000\n",
            "120/120 [==============================] - 0s 136us/step - loss: 0.2281 - acc: 0.9167\n",
            "Epoch 757/1000\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2284 - acc: 0.9167\n",
            "Epoch 758/1000\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2278 - acc: 0.9167\n",
            "Epoch 759/1000\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2278 - acc: 0.9167\n",
            "Epoch 760/1000\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2275 - acc: 0.9167\n",
            "Epoch 761/1000\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.2274 - acc: 0.9167\n",
            "Epoch 762/1000\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2274 - acc: 0.9167\n",
            "Epoch 763/1000\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2274 - acc: 0.9167\n",
            "Epoch 764/1000\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2275 - acc: 0.9167\n",
            "Epoch 765/1000\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2276 - acc: 0.9167\n",
            "Epoch 766/1000\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2274 - acc: 0.9083\n",
            "Epoch 767/1000\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2274 - acc: 0.9083\n",
            "Epoch 768/1000\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2271 - acc: 0.9167\n",
            "Epoch 769/1000\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.2270 - acc: 0.9083\n",
            "Epoch 770/1000\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2271 - acc: 0.9083\n",
            "Epoch 771/1000\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2273 - acc: 0.9167\n",
            "Epoch 772/1000\n",
            "120/120 [==============================] - 0s 76us/step - loss: 0.2271 - acc: 0.9167\n",
            "Epoch 773/1000\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2279 - acc: 0.9167\n",
            "Epoch 774/1000\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2272 - acc: 0.9083\n",
            "Epoch 775/1000\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2270 - acc: 0.9083\n",
            "Epoch 776/1000\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2273 - acc: 0.9167\n",
            "Epoch 777/1000\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2273 - acc: 0.9167\n",
            "Epoch 778/1000\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2275 - acc: 0.9167\n",
            "Epoch 779/1000\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.2279 - acc: 0.9167\n",
            "Epoch 780/1000\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2282 - acc: 0.9250\n",
            "Epoch 781/1000\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2279 - acc: 0.9250\n",
            "Epoch 782/1000\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2273 - acc: 0.9167\n",
            "Epoch 783/1000\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.2269 - acc: 0.9167\n",
            "Epoch 784/1000\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2270 - acc: 0.9167\n",
            "Epoch 785/1000\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2271 - acc: 0.9167\n",
            "Epoch 786/1000\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.2268 - acc: 0.9167\n",
            "Epoch 787/1000\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2264 - acc: 0.9083\n",
            "Epoch 788/1000\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2265 - acc: 0.9083\n",
            "Epoch 789/1000\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2265 - acc: 0.9083\n",
            "Epoch 790/1000\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.2265 - acc: 0.9167\n",
            "Epoch 791/1000\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.2266 - acc: 0.9167\n",
            "Epoch 792/1000\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.2265 - acc: 0.9167\n",
            "Epoch 793/1000\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2264 - acc: 0.9083\n",
            "Epoch 794/1000\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2264 - acc: 0.9083\n",
            "Epoch 795/1000\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2265 - acc: 0.9083\n",
            "Epoch 796/1000\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2266 - acc: 0.9083\n",
            "Epoch 797/1000\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2264 - acc: 0.9083\n",
            "Epoch 798/1000\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2261 - acc: 0.9083\n",
            "Epoch 799/1000\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2264 - acc: 0.9083\n",
            "Epoch 800/1000\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2265 - acc: 0.9083\n",
            "Epoch 801/1000\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2268 - acc: 0.9083\n",
            "Epoch 802/1000\n",
            "120/120 [==============================] - 0s 75us/step - loss: 0.2273 - acc: 0.9083\n",
            "Epoch 803/1000\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2275 - acc: 0.8917\n",
            "Epoch 804/1000\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2274 - acc: 0.9000\n",
            "Epoch 805/1000\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2270 - acc: 0.9000\n",
            "Epoch 806/1000\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2260 - acc: 0.9083\n",
            "Epoch 807/1000\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2266 - acc: 0.9083\n",
            "Epoch 808/1000\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2267 - acc: 0.9083\n",
            "Epoch 809/1000\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2266 - acc: 0.9000\n",
            "Epoch 810/1000\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2265 - acc: 0.9000\n",
            "Epoch 811/1000\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2265 - acc: 0.9000\n",
            "Epoch 812/1000\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2263 - acc: 0.9083\n",
            "Epoch 813/1000\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2261 - acc: 0.9083\n",
            "Epoch 814/1000\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2259 - acc: 0.9083\n",
            "Epoch 815/1000\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2257 - acc: 0.9000\n",
            "Epoch 816/1000\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2256 - acc: 0.9000\n",
            "Epoch 817/1000\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.2257 - acc: 0.9000\n",
            "Epoch 818/1000\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2260 - acc: 0.9000\n",
            "Epoch 819/1000\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2255 - acc: 0.9083\n",
            "Epoch 820/1000\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2255 - acc: 0.9167\n",
            "Epoch 821/1000\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2255 - acc: 0.9167\n",
            "Epoch 822/1000\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2254 - acc: 0.9167\n",
            "Epoch 823/1000\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2254 - acc: 0.9083\n",
            "Epoch 824/1000\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2254 - acc: 0.9167\n",
            "Epoch 825/1000\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2251 - acc: 0.9167\n",
            "Epoch 826/1000\n",
            "120/120 [==============================] - 0s 71us/step - loss: 0.2253 - acc: 0.9167\n",
            "Epoch 827/1000\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2255 - acc: 0.9167\n",
            "Epoch 828/1000\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2252 - acc: 0.9167\n",
            "Epoch 829/1000\n",
            "120/120 [==============================] - 0s 77us/step - loss: 0.2254 - acc: 0.9167\n",
            "Epoch 830/1000\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2254 - acc: 0.9167\n",
            "Epoch 831/1000\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2251 - acc: 0.9083\n",
            "Epoch 832/1000\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2252 - acc: 0.9083\n",
            "Epoch 833/1000\n",
            "120/120 [==============================] - 0s 73us/step - loss: 0.2251 - acc: 0.9083\n",
            "Epoch 834/1000\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2252 - acc: 0.9167\n",
            "Epoch 835/1000\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2255 - acc: 0.9167\n",
            "Epoch 836/1000\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2251 - acc: 0.9167\n",
            "Epoch 837/1000\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.2251 - acc: 0.9167\n",
            "Epoch 838/1000\n",
            "120/120 [==============================] - 0s 136us/step - loss: 0.2252 - acc: 0.9167\n",
            "Epoch 839/1000\n",
            "120/120 [==============================] - 0s 131us/step - loss: 0.2249 - acc: 0.9167\n",
            "Epoch 840/1000\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2248 - acc: 0.9167\n",
            "Epoch 841/1000\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2247 - acc: 0.9083\n",
            "Epoch 842/1000\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2246 - acc: 0.9083\n",
            "Epoch 843/1000\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2246 - acc: 0.9083\n",
            "Epoch 844/1000\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.2246 - acc: 0.9083\n",
            "Epoch 845/1000\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2246 - acc: 0.8917\n",
            "Epoch 846/1000\n",
            "120/120 [==============================] - 0s 117us/step - loss: 0.2245 - acc: 0.9000\n",
            "Epoch 847/1000\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2246 - acc: 0.9000\n",
            "Epoch 848/1000\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2247 - acc: 0.8917\n",
            "Epoch 849/1000\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2248 - acc: 0.9000\n",
            "Epoch 850/1000\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2247 - acc: 0.9083\n",
            "Epoch 851/1000\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.2245 - acc: 0.9083\n",
            "Epoch 852/1000\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2243 - acc: 0.9083\n",
            "Epoch 853/1000\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2242 - acc: 0.9083\n",
            "Epoch 854/1000\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.2243 - acc: 0.9083\n",
            "Epoch 855/1000\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.2242 - acc: 0.9083\n",
            "Epoch 856/1000\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2242 - acc: 0.9000\n",
            "Epoch 857/1000\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2242 - acc: 0.9000\n",
            "Epoch 858/1000\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2240 - acc: 0.9083\n",
            "Epoch 859/1000\n",
            "120/120 [==============================] - 0s 120us/step - loss: 0.2240 - acc: 0.9083\n",
            "Epoch 860/1000\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2239 - acc: 0.9083\n",
            "Epoch 861/1000\n",
            "120/120 [==============================] - 0s 77us/step - loss: 0.2240 - acc: 0.9083\n",
            "Epoch 862/1000\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2241 - acc: 0.9083\n",
            "Epoch 863/1000\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2243 - acc: 0.9000\n",
            "Epoch 864/1000\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2244 - acc: 0.9000\n",
            "Epoch 865/1000\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.2247 - acc: 0.9083\n",
            "Epoch 866/1000\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.2248 - acc: 0.9083\n",
            "Epoch 867/1000\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2245 - acc: 0.9000\n",
            "Epoch 868/1000\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2241 - acc: 0.9000\n",
            "Epoch 869/1000\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.2242 - acc: 0.9000\n",
            "Epoch 870/1000\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2241 - acc: 0.9083\n",
            "Epoch 871/1000\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2244 - acc: 0.9000\n",
            "Epoch 872/1000\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2239 - acc: 0.9000\n",
            "Epoch 873/1000\n",
            "120/120 [==============================] - 0s 75us/step - loss: 0.2238 - acc: 0.9000\n",
            "Epoch 874/1000\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.2238 - acc: 0.9000\n",
            "Epoch 875/1000\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2238 - acc: 0.9083\n",
            "Epoch 876/1000\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2239 - acc: 0.9083\n",
            "Epoch 877/1000\n",
            "120/120 [==============================] - 0s 76us/step - loss: 0.2240 - acc: 0.9083\n",
            "Epoch 878/1000\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2241 - acc: 0.9167\n",
            "Epoch 879/1000\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2242 - acc: 0.9083\n",
            "Epoch 880/1000\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2235 - acc: 0.9167\n",
            "Epoch 881/1000\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2234 - acc: 0.9167\n",
            "Epoch 882/1000\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2236 - acc: 0.9167\n",
            "Epoch 883/1000\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2236 - acc: 0.9167\n",
            "Epoch 884/1000\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2238 - acc: 0.9167\n",
            "Epoch 885/1000\n",
            "120/120 [==============================] - 0s 122us/step - loss: 0.2239 - acc: 0.9250\n",
            "Epoch 886/1000\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2236 - acc: 0.9167\n",
            "Epoch 887/1000\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2235 - acc: 0.9083\n",
            "Epoch 888/1000\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2237 - acc: 0.9167\n",
            "Epoch 889/1000\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2239 - acc: 0.9000\n",
            "Epoch 890/1000\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.2237 - acc: 0.9167\n",
            "Epoch 891/1000\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2235 - acc: 0.9000\n",
            "Epoch 892/1000\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2231 - acc: 0.9083\n",
            "Epoch 893/1000\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.2230 - acc: 0.9000\n",
            "Epoch 894/1000\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2239 - acc: 0.8917\n",
            "Epoch 895/1000\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2236 - acc: 0.8917\n",
            "Epoch 896/1000\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.2237 - acc: 0.8833\n",
            "Epoch 897/1000\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2231 - acc: 0.9083\n",
            "Epoch 898/1000\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2231 - acc: 0.9083\n",
            "Epoch 899/1000\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2228 - acc: 0.9083\n",
            "Epoch 900/1000\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2229 - acc: 0.9083\n",
            "Epoch 901/1000\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2228 - acc: 0.9000\n",
            "Epoch 902/1000\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2232 - acc: 0.9083\n",
            "Epoch 903/1000\n",
            "120/120 [==============================] - 0s 77us/step - loss: 0.2236 - acc: 0.8917\n",
            "Epoch 904/1000\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2240 - acc: 0.8917\n",
            "Epoch 905/1000\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.2237 - acc: 0.8917\n",
            "Epoch 906/1000\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2232 - acc: 0.8917\n",
            "Epoch 907/1000\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.2232 - acc: 0.8917\n",
            "Epoch 908/1000\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2230 - acc: 0.9000\n",
            "Epoch 909/1000\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2232 - acc: 0.8833\n",
            "Epoch 910/1000\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.2231 - acc: 0.8917\n",
            "Epoch 911/1000\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2230 - acc: 0.8833\n",
            "Epoch 912/1000\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2229 - acc: 0.8833\n",
            "Epoch 913/1000\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2229 - acc: 0.8833\n",
            "Epoch 914/1000\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2228 - acc: 0.8833\n",
            "Epoch 915/1000\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2227 - acc: 0.8833\n",
            "Epoch 916/1000\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2225 - acc: 0.9000\n",
            "Epoch 917/1000\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2226 - acc: 0.8833\n",
            "Epoch 918/1000\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.2225 - acc: 0.8917\n",
            "Epoch 919/1000\n",
            "120/120 [==============================] - 0s 112us/step - loss: 0.2225 - acc: 0.9000\n",
            "Epoch 920/1000\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.2229 - acc: 0.9000\n",
            "Epoch 921/1000\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2228 - acc: 0.9167\n",
            "Epoch 922/1000\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2225 - acc: 0.9167\n",
            "Epoch 923/1000\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2224 - acc: 0.9083\n",
            "Epoch 924/1000\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2227 - acc: 0.9167\n",
            "Epoch 925/1000\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.2225 - acc: 0.9083\n",
            "Epoch 926/1000\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2227 - acc: 0.9083\n",
            "Epoch 927/1000\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2228 - acc: 0.9083\n",
            "Epoch 928/1000\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2226 - acc: 0.9083\n",
            "Epoch 929/1000\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.2225 - acc: 0.9083\n",
            "Epoch 930/1000\n",
            "120/120 [==============================] - 0s 121us/step - loss: 0.2222 - acc: 0.9083\n",
            "Epoch 931/1000\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2223 - acc: 0.9083\n",
            "Epoch 932/1000\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2223 - acc: 0.9167\n",
            "Epoch 933/1000\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.2222 - acc: 0.9083\n",
            "Epoch 934/1000\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2223 - acc: 0.9083\n",
            "Epoch 935/1000\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2225 - acc: 0.9083\n",
            "Epoch 936/1000\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2223 - acc: 0.9000\n",
            "Epoch 937/1000\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2221 - acc: 0.9083\n",
            "Epoch 938/1000\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2224 - acc: 0.8917\n",
            "Epoch 939/1000\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2225 - acc: 0.8917\n",
            "Epoch 940/1000\n",
            "120/120 [==============================] - 0s 117us/step - loss: 0.2226 - acc: 0.8917\n",
            "Epoch 941/1000\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2228 - acc: 0.8833\n",
            "Epoch 942/1000\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2226 - acc: 0.8917\n",
            "Epoch 943/1000\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.2228 - acc: 0.8833\n",
            "Epoch 944/1000\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.2223 - acc: 0.8917\n",
            "Epoch 945/1000\n",
            "120/120 [==============================] - 0s 75us/step - loss: 0.2224 - acc: 0.8917\n",
            "Epoch 946/1000\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2224 - acc: 0.8917\n",
            "Epoch 947/1000\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2228 - acc: 0.8917\n",
            "Epoch 948/1000\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.2229 - acc: 0.8917\n",
            "Epoch 949/1000\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2223 - acc: 0.9083\n",
            "Epoch 950/1000\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2220 - acc: 0.9167\n",
            "Epoch 951/1000\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2219 - acc: 0.9083\n",
            "Epoch 952/1000\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2217 - acc: 0.9167\n",
            "Epoch 953/1000\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2218 - acc: 0.9167\n",
            "Epoch 954/1000\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2217 - acc: 0.9167\n",
            "Epoch 955/1000\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2217 - acc: 0.9167\n",
            "Epoch 956/1000\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2216 - acc: 0.9167\n",
            "Epoch 957/1000\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2215 - acc: 0.9083\n",
            "Epoch 958/1000\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2216 - acc: 0.9083\n",
            "Epoch 959/1000\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2214 - acc: 0.9083\n",
            "Epoch 960/1000\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2215 - acc: 0.9083\n",
            "Epoch 961/1000\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2217 - acc: 0.9083\n",
            "Epoch 962/1000\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2218 - acc: 0.9083\n",
            "Epoch 963/1000\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2216 - acc: 0.9083\n",
            "Epoch 964/1000\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2219 - acc: 0.9083\n",
            "Epoch 965/1000\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2220 - acc: 0.9167\n",
            "Epoch 966/1000\n",
            "120/120 [==============================] - 0s 116us/step - loss: 0.2217 - acc: 0.9083\n",
            "Epoch 967/1000\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2217 - acc: 0.9167\n",
            "Epoch 968/1000\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2219 - acc: 0.9167\n",
            "Epoch 969/1000\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2214 - acc: 0.8917\n",
            "Epoch 970/1000\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2212 - acc: 0.9083\n",
            "Epoch 971/1000\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.2211 - acc: 0.9083\n",
            "Epoch 972/1000\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2212 - acc: 0.9083\n",
            "Epoch 973/1000\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2214 - acc: 0.9083\n",
            "Epoch 974/1000\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.2217 - acc: 0.9083\n",
            "Epoch 975/1000\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2212 - acc: 0.9167\n",
            "Epoch 976/1000\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2211 - acc: 0.9167\n",
            "Epoch 977/1000\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2211 - acc: 0.9167\n",
            "Epoch 978/1000\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2214 - acc: 0.9167\n",
            "Epoch 979/1000\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.2217 - acc: 0.9083\n",
            "Epoch 980/1000\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2226 - acc: 0.9000\n",
            "Epoch 981/1000\n",
            "120/120 [==============================] - 0s 117us/step - loss: 0.2224 - acc: 0.8917\n",
            "Epoch 982/1000\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.2217 - acc: 0.8917\n",
            "Epoch 983/1000\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.2218 - acc: 0.8917\n",
            "Epoch 984/1000\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2213 - acc: 0.8917\n",
            "Epoch 985/1000\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2215 - acc: 0.9083\n",
            "Epoch 986/1000\n",
            "120/120 [==============================] - 0s 125us/step - loss: 0.2217 - acc: 0.8917\n",
            "Epoch 987/1000\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2210 - acc: 0.9000\n",
            "Epoch 988/1000\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2209 - acc: 0.9083\n",
            "Epoch 989/1000\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.2209 - acc: 0.9083\n",
            "Epoch 990/1000\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2208 - acc: 0.9000\n",
            "Epoch 991/1000\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2208 - acc: 0.9083\n",
            "Epoch 992/1000\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.2210 - acc: 0.9000\n",
            "Epoch 993/1000\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2215 - acc: 0.8917\n",
            "Epoch 994/1000\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2217 - acc: 0.8833\n",
            "Epoch 995/1000\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2218 - acc: 0.8917\n",
            "Epoch 996/1000\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2222 - acc: 0.8917\n",
            "Epoch 997/1000\n",
            "120/120 [==============================] - 0s 111us/step - loss: 0.2223 - acc: 0.8917\n",
            "Epoch 998/1000\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2219 - acc: 0.8917\n",
            "Epoch 999/1000\n",
            "120/120 [==============================] - 0s 123us/step - loss: 0.2219 - acc: 0.8917\n",
            "Epoch 1000/1000\n",
            "120/120 [==============================] - 0s 134us/step - loss: 0.2217 - acc: 0.8917\n",
            "60/60 [==============================] - 1s 11ms/step\n",
            "\n",
            "acc: 93.33%\n",
            "[[19  1  2]\n",
            " [ 1 18  0]\n",
            " [ 0  0 19]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.86      0.90        22\n",
            "           1       0.95      0.95      0.95        19\n",
            "           2       0.90      1.00      0.95        19\n",
            "\n",
            "    accuracy                           0.93        60\n",
            "   macro avg       0.93      0.94      0.93        60\n",
            "weighted avg       0.93      0.93      0.93        60\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_B8jrVttNnTZ",
        "colab_type": "code",
        "outputId": "f1d47cb5-0ae6-4b4a-cf1c-ad73035b7079",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "Nh_acc= np.array(Nh_acc)\n",
        "plt.plot(Nh,Nh_acc[:,1])\n",
        "plt.xlabel('Number of hidden layer')  \n",
        "plt.ylabel('Accuracy')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Accuracy')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rXjqkPGTgUk",
        "colab_type": "code",
        "outputId": "f3c38978-effe-4fd6-ed86-7a69c16c8192",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "N_acc= np.array(N_acc)\n",
        "plt.plot(N,N_acc[:,1])\n",
        "plt.xlabel('Number of Training detapoints per categary')  \n",
        "plt.ylabel('Accuracy')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Accuracy')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntrnzJGeUG_X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "9088fbfa-d9aa-40a6-cdbd-ef602927461b"
      },
      "source": [
        "Nepochs_acc= np.array(Nepochs_acc)\n",
        "plt.plot(Nepochs,Nepochs_acc[:,1])\n",
        "plt.xlabel('Number of Nepochs')  \n",
        "plt.ylabel('Accuracy')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Accuracy')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}